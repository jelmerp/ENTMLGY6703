[
  {
    "objectID": "lectures/removed.html",
    "href": "lectures/removed.html",
    "title": "Removed",
    "section": "",
    "text": "Effects of Diplodia pathogen exposure Austrian pine (Pinus nigra) over time.\nAphid biotypes & soybean cultivars under different flood conditions (Michel lab, Entomology)\n\n\n\n\n\nhttps://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost\n\n\n\n\n\n\nhttps://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/blast.html#sequence-alignment-1",
    "href": "lectures/blast.html#sequence-alignment-1",
    "title": "Sequence alignment and BLAST",
    "section": "Sequence alignment",
    "text": "Sequence alignment\nSequence alignment is central to genomics and molecular genetics — and has been since long before the advent of high-throughput sequencing.\n\nWhat gene does a sequence belong to?\nWhich gene is homologous my novel gene? Which functional domains does my gene contain?\nWhat species does a sequence belong to?\nHow similar are two or more sequences and how are they related to each other?\nWhich positions differ among sequences?\nWhere in the genome do my sequence reads map to?\n\nSequence assembly is similar to sequence alignment, as it relies on overlap between sequences, but distinct as it tries to generate a single “consensus” sequence that is much longer than the original sequences/reads."
  },
  {
    "objectID": "lectures/blast.html#sequence-alignment-cont.",
    "href": "lectures/blast.html#sequence-alignment-cont.",
    "title": "Sequence alignment and BLAST",
    "section": "Sequence alignment (cont.)",
    "text": "Sequence alignment (cont.)\nEven though it can be straightforward to align short sequences by eye/hand, it’s important to realize that there are quickly thousands to millions different possible ways of aligning two sequences.\nAnd speed is important, because we often either want to align:\n\n1 (or more) sequence to a database with millions of sequences (e.g., BLAST)\nMillions of sequence reads to a reference genome"
  },
  {
    "objectID": "lectures/blast.html#sequence-alignment-cont.-1",
    "href": "lectures/blast.html#sequence-alignment-cont.-1",
    "title": "Sequence alignment and BLAST",
    "section": "Sequence alignment (cont.)",
    "text": "Sequence alignment (cont.)\n\nAmino acid (protein) vs nucleotide (DNA/RNA) sequence aligment — very similar procedures, but different scoring matrices\nLocal vs. global alignments\nPairwise vs. multiple sequence alignments (MSA). Pairwise is more common (includes BLAST and mapping reads to a genome)."
  },
  {
    "objectID": "lectures/blast.html#developments-in-alignment-approaches",
    "href": "lectures/blast.html#developments-in-alignment-approaches",
    "title": "Sequence alignment and BLAST",
    "section": "Developments in alignment approaches",
    "text": "Developments in alignment approaches\n\nPairwise alignments with … (196X, global alignment) and Smith-Waterman (197X, local alignment)\n\nUse clever algorithms that are guaranteed to find the optimal solution without checking every option.\nAre still way too slow for modern databases sizes and numbers of reads\n\nBLAST: Basic Local Alignment Search Tool (199X) — we’ll go in some detail into this, and run BLAST in our lab tomorrow\nBLAST is still too slow for high-throughput sequencing alignments – new tools were developed for this, like BWA and Bowtie. These have algorithms with more complex database/reference indexing, based on suffix arrays or the Burrows-Wheeler Transform.\nAs we’ll see next week, aligners for RNA-seq (such as STAR) additionally need to be splice-aware."
  },
  {
    "objectID": "lectures/blast.html#homology",
    "href": "lectures/blast.html#homology",
    "title": "Sequence alignment and BLAST",
    "section": "Homology",
    "text": "Homology\n\nOrthologs and paralogs"
  },
  {
    "objectID": "lectures/blast.html#intro-to-blast",
    "href": "lectures/blast.html#intro-to-blast",
    "title": "Sequence alignment and BLAST",
    "section": "Intro to BLAST",
    "text": "Intro to BLAST"
  },
  {
    "objectID": "lectures/blast.html#types-of-blast",
    "href": "lectures/blast.html#types-of-blast",
    "title": "Sequence alignment and BLAST",
    "section": "Types of BLAST",
    "text": "Types of BLAST"
  },
  {
    "objectID": "lectures/blast.html#blast-terminology",
    "href": "lectures/blast.html#blast-terminology",
    "title": "Sequence alignment and BLAST",
    "section": "BLAST: terminology",
    "text": "BLAST: terminology\n\nQuery\nTarget\nSubject\nHSP\nScore\nEvalue"
  },
  {
    "objectID": "lectures/blast.html#general-strategy-of-blast",
    "href": "lectures/blast.html#general-strategy-of-blast",
    "title": "Sequence alignment and BLAST",
    "section": "General strategy of BLAST",
    "text": "General strategy of BLAST\n\nHash-based index: simple kmer lookup"
  },
  {
    "objectID": "lectures/blast.html#scoring-matrices",
    "href": "lectures/blast.html#scoring-matrices",
    "title": "Sequence alignment and BLAST",
    "section": "Scoring matrices",
    "text": "Scoring matrices\n\nMegaBLAST"
  },
  {
    "objectID": "lectures/blast.html#e-values",
    "href": "lectures/blast.html#e-values",
    "title": "Sequence alignment and BLAST",
    "section": "E-values",
    "text": "E-values\n\nDatabase size"
  },
  {
    "objectID": "lectures/blast.html#sequence-databases-1",
    "href": "lectures/blast.html#sequence-databases-1",
    "title": "Sequence alignment and BLAST",
    "section": "Sequence databases",
    "text": "Sequence databases\n\nNCBI Genbank\nNCBI RefSeq\nNCBI SRA\n\nProteins:\n\nUniProt\nProtein Data Bank (3D structures)"
  },
  {
    "objectID": "lectures/blast.html#genbank-sra-growth",
    "href": "lectures/blast.html#genbank-sra-growth",
    "title": "Sequence alignment and BLAST",
    "section": "Genbank & SRA growth",
    "text": "Genbank & SRA growth"
  },
  {
    "objectID": "lectures/blast.html#refseq-sequence-prefixes",
    "href": "lectures/blast.html#refseq-sequence-prefixes",
    "title": "Sequence alignment and BLAST",
    "section": "Refseq sequence prefixes",
    "text": "Refseq sequence prefixes"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this website",
    "section": "",
    "text": "This website contains the lecture slides and lab material for the guest lectures by Jelmer Poelstra (MCIC Wooster, Ohio State University) in the graduate-level ENTMLGY 6703 Spring 2024 course “Molecular Techniques & Data Analysis Syllabus” taught by Peter Piermarini and Larry Phelan at OSU.\n\n\n\n Back to top"
  },
  {
    "objectID": "labs/DE.html",
    "href": "labs/DE.html",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "",
    "text": "Log in to OSC at https://ondemand.osc.edu.\nClick on Interactive Apps (top bar) &gt; RStudio Server\n\nTBA\n\nFill out the form as shown below:\n\nTBA\n\nNow, you should see a box like this:\n\n\n\n\n\nYour job should start running pretty soon, and when it’s ready the box should look like this:\n\n\n\n\n\nClick Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open. You’re ready to go!\n\n\n\n\nTBA\nNow, RStudio will reload with the newly created Project open.\nIf you get the pop-up below, click Don't Save (do this whenever you get that pop-up):\n\n\n\n\n\n\n\nif(! \"pacman\" %in% installed.packages()) install.packages(\"pacman\")\npackages &lt;- c(\"DESeq2\",          # Differential expression analysis\n              \"tidyverse\",       # Misc. data manipulation and plotting\n              \"ggrepel\",         # PCA with sample IDs\n              \"pheatmap\")        # Heatmap plot\npacman::p_load(char = packages)\n\ntheme_set(theme_bw())  # Set ggplot theme\n\n\n\n\nInput files:\n\nGene counts table\nMetadata table – so we can group our samples and make comparisons between these groups.\n\n\ncount_table_file &lt;- here(\"results/count/gene_counts_all.txt\")\nmetadata_file &lt;- here(\"data/meta/metadata.txt\")\n\nOutput directories – and we create them if they don’t already exist:\n\noutdir &lt;- here(\"results/DE/\")\nif (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)\n\n\n\n\nLoad the count table:\n\nraw_counts &lt;- read.table(count_table_file,\n                         sep = \"\\t\", header = TRUE, skip = 1)\n\nLoad the metadata information:\n\nmetadata &lt;- read.table(metadata_file, header = TRUE)\n\nhead(metadata)\n\nThe Treatment column currently has the values Agrobacterium_noexp, Agrobacterium_myb, and mock.\nTo shorten this a bit, we’ll get rid of “Agrobacterium_”:\n\nmetadata$Treatment &lt;- sub(\"Agrobacterium_\", \"\", metadata$Treatment)\n\nunique(metadata$Treatment)"
  },
  {
    "objectID": "labs/FASTQ.html",
    "href": "labs/FASTQ.html",
    "title": "Week 3 lab: Genome and HTS data",
    "section": "",
    "text": "x"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jelmer’s guest lectures in ENTMLGY 6703, SP24",
    "section": "",
    "text": "Schedule\n\n\n\nWeek\nDate\nModule\nTopic & link\n\n\n\n\n3\nJan 25th\nHigh-throughput sequencing (HTS)\nLecture: High-throughput sequencing & genomes\n\n\n3\nJan 26th\nHigh-throughput sequencing (HTS)\n- Lab part 1: Computational infrastructure- Lab part 2: Working with genome and HTS data\n\n\n4\nFeb 1st\nRNA-seq\nLecture: RNA-seq\n\n\n4\nFeb 2nd\nRNA-seq\nLab: Differential expression analysis\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/sequencing.html#dna-sequencing-technologies-overview",
    "href": "lectures/sequencing.html#dna-sequencing-technologies-overview",
    "title": "High-throughput sequencing  and genomes",
    "section": "DNA sequencing technologies: overview",
    "text": "DNA sequencing technologies: overview\n\nSanger sequencing (since 1977)\nSequences a single, typically PCR-amplified, short-ish (≤900 bp) DNA fragment at a time\n\n\n\nHigh-throughput sequencing (HTS)\nSequences 105-109 usually randomly selected DNA fragments (reads) at a time — two types:\n\n\n\n\n\n\nShort-read sequencing\n\nAKA Next-generation Sequencing (NGS)\nProduces up to billions of 50-300 bp “reads”\nMarket dominated by Illumina\nSince 2005 — technology stable"
  },
  {
    "objectID": "lectures/sequencing.html#dna-sequencing-technologies-overview-1",
    "href": "lectures/sequencing.html#dna-sequencing-technologies-overview-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "DNA sequencing technologies: overview",
    "text": "DNA sequencing technologies: overview\n\nSanger sequencing (since 1977)\nSequences a single, typically PCR-amplified, short-ish (≤900 bp) DNA fragment at a time\n\n\nHigh-throughput sequencing (HTS)\nSequences 105-109 usually randomly selected DNA fragments (reads) at a time — two types:\n\n\n\n\nShort-read sequencing\n\nAKA Next-generation Sequencing (NGS)\nProduces up to billions of 50-300 bp “reads”\nMarket dominated by Illumina\nSince 2005 — technology stable\n\n\n\n\nLong-read sequencing\n\nReads much longer than in NGS but fewer, less accurate, and more costly per base\nTwo main companies: Oxford Nanopore Technologies (ONT) and Pacific Biosciences (PacBio)\nSince 2011 — remains under rapid development"
  },
  {
    "objectID": "lectures/sequencing.html#dna-sequencing-technologies-overview-2",
    "href": "lectures/sequencing.html#dna-sequencing-technologies-overview-2",
    "title": "High-throughput sequencing  and genomes",
    "section": "DNA sequencing technologies: overview",
    "text": "DNA sequencing technologies: overview\n\n\n\n\n\n\nWhat about RNA sequencing?\n\n\nThis lecture mostly talks about DNA sequencing, but this includes the indirect sequencing of RNA after reverse transcription to cDNA."
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-technology-development-timeline",
    "href": "lectures/sequencing.html#sequencing-technology-development-timeline",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing technology development timeline",
    "text": "Sequencing technology development timeline\n\nModified after Pereira et al. 2020 (www.ncbi.nlm.nih.gov/pmc/articles/PMC7019349/)"
  },
  {
    "objectID": "lectures/sequencing.html#sanger-sequencing",
    "href": "lectures/sequencing.html#sanger-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sanger sequencing",
    "text": "Sanger sequencing\nSequences a single, typically PCR-amplified, short-ish (≤900 bp) DNA fragment at a time.\nSequencing is performed by synthesizing a new DNA strand in part with fluorescently-labeled nucleotides — a different color for each base (A, C, G, T).1\n\nThe final result is a chromatogram that can be base-called:\n\n\n\n\n\n\n\n\n\n\n\n\n\nA $100 million dollar genome: the entire human genome (3 Gbp) was sequenced with Sanger!\n\n\n\n\n\n\n\nVisualization is not done in real time, but after the fact: sequences of each possible length are produced with a fluorescently labeled last base, and these can be separated by length afterwards."
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-cost-through-time",
    "href": "lectures/sequencing.html#sequencing-cost-through-time",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing cost through time",
    "text": "Sequencing cost through time\n\nhttps://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost"
  },
  {
    "objectID": "lectures/sequencing.html#present-day-sanger-applications",
    "href": "lectures/sequencing.html#present-day-sanger-applications",
    "title": "High-throughput sequencing  and genomes",
    "section": "Present-day Sanger applications",
    "text": "Present-day Sanger applications\nCommon current applications of Sanger sequencing include:\n\nExamining variation among individuals or populations in one or more candidate or marker genes (for population genetics, phylogenetics, functional inferences, etc.)\nTaxonomic identification of a sample\n\n\n\n\n\n\n\n\n\nAmplification of a target DNA fragment is usually done with PCR\n\n\n\nThis means that you need to (approximately) know in advance short flanking sequences to the sequence of interest — primers for your PCR.\nIntrons are good targets to sequence: variable sequences flanked by conserved sequences (exons) in which primers can be designed."
  },
  {
    "objectID": "lectures/sequencing.html#high-throughput-sequencing-applications",
    "href": "lectures/sequencing.html#high-throughput-sequencing-applications",
    "title": "High-throughput sequencing  and genomes",
    "section": "High-throughput sequencing applications",
    "text": "High-throughput sequencing applications\n\nWhole-genome assembly\n\n\n\nVariant analysis (for population genetics/genomics, molecular evolution, GWAS, etc.):\n\nWhole-genome “resequencing”\nReduced-representation libraries (e.g. RADseq, GBS)\n\n\n\n\n\nRNA-seq (transcriptome analysis)\nOther functional sequencing methods like Methyl-seq, ChIP-seq, etc.\n\n\n\n\nMicrobial community characterization\n\nMetabarcoding\nShotgun metagenomics"
  },
  {
    "objectID": "lectures/sequencing.html#two-important-variables-in-high-throughput-sequencing-read-lengths-error-rates",
    "href": "lectures/sequencing.html#two-important-variables-in-high-throughput-sequencing-read-lengths-error-rates",
    "title": "High-throughput sequencing  and genomes",
    "section": "Two important variables in high-throughput sequencing:  read lengths & error rates",
    "text": "Two important variables in high-throughput sequencing:  read lengths & error rates"
  },
  {
    "objectID": "lectures/sequencing.html#read-lengths",
    "href": "lectures/sequencing.html#read-lengths",
    "title": "High-throughput sequencing  and genomes",
    "section": "Read lengths",
    "text": "Read lengths\n\nShort-read (Illumina) HTS: 50-300 bp reads\nLong-read HTS: longer & more variable read lengths (PacBio: 10-50 kbp, ONT: 10-100 kbp)\n\n\n\nWhen are longer reads useful?\n\nGenome assembly\nHaplotype and large structural variant calling\nTranscript isoform identification\nTaxonomic identification of single reads (microbial metabarcoding)\n\n\n\n\nWhen does read length not matter (as much)?\n\nRead-as-a-tag: the goal is just to know a read’s origin in a reference genome, like in counting applications such as RNA-seq\nSNP variant analysis"
  },
  {
    "objectID": "lectures/sequencing.html#error-rates",
    "href": "lectures/sequencing.html#error-rates",
    "title": "High-throughput sequencing  and genomes",
    "section": "Error rates",
    "text": "Error rates\nCurrently, no sequencing technology is error-free, and several types of errors can occur:\n\n\nBase call errors, e.g. a base that was called as an A may instead be a G.\nInsertion or deletion (indel) errors\nWhen the base calling software is not confident at all, it can also return Ns (= undetermined).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuality scores in sequence data\n\n\nWhen you get sequences from a high-throughput sequencer, base calls have typically already been made. Every base is also accompanied by a quality score (inversely related to the estimated error probability)."
  },
  {
    "objectID": "lectures/sequencing.html#overcoming-sequencing-errors",
    "href": "lectures/sequencing.html#overcoming-sequencing-errors",
    "title": "High-throughput sequencing  and genomes",
    "section": "Overcoming sequencing errors",
    "text": "Overcoming sequencing errors\n\nSequencing at a high so-called “depth of coverage”1 generally allows to infer the correct sequence\n\n\n\n\n\n\n\n\nBut made more challenging by natural genetic variation among and within (heterozygosity due to diploid genomes) individuals\nTypical depths of coverage: at least 50-100x for genome assembly; 10-30x for resequencing.\n\n\nOften referred to simply as “depth” or, confusing, “coverage”"
  },
  {
    "objectID": "lectures/sequencing.html#illumina-short-read-hts-ngs",
    "href": "lectures/sequencing.html#illumina-short-read-hts-ngs",
    "title": "High-throughput sequencing  and genomes",
    "section": "Illumina (short-read HTS / NGS)",
    "text": "Illumina (short-read HTS / NGS)\n\n\n100-300 bp reads with 0.1-0.2% error rates\nMore reads, lower per-base cost, and lower error rates than long-read sequencing1.\n\n\n\n\nMachines differ in throughput, cost per Gb, and read length:\n\n\n\n\n\n\n\nBut the error rate difference is disappearing: long-read technologies keep improving and Illumina does not."
  },
  {
    "objectID": "lectures/sequencing.html#libraries-and-library-prep",
    "href": "lectures/sequencing.html#libraries-and-library-prep",
    "title": "High-throughput sequencing  and genomes",
    "section": "Libraries and library prep",
    "text": "Libraries and library prep\nIn a sequencing context, a “library” is a collection of nucleic acid fragments ready for sequencing.\n\nIn Illumina and other HTS libraries, the fragments number in the millions or billions and are often randomly generated from input such as genomic DNA — cf. Sanger sequencing:\n\n\n\nThe procedure that produces a library from a DNA (or RNA) extraction is called library prep.\n\n\n\n\n\n\n\nDifferent library prep procedures are used depending on the type of sequencing (WGS, RAD-seq, RNA-seq, etc.) and HTS technology — and some include more specific fragment generation or selection. We’ll see the specific library prep steps for RNA-seq next week."
  },
  {
    "objectID": "lectures/sequencing.html#libraries-and-library-prep-cont.",
    "href": "lectures/sequencing.html#libraries-and-library-prep-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "Libraries and library prep (cont.)",
    "text": "Libraries and library prep (cont.)\nAfter library prep (here, for Illumina sequencing), each DNA fragment is flanked by several types of short sequences that together make up the “adapters”:\n\n\n\n\nAfter talking about paired-end vs. single-end sequencing and the way Illumina sequencing works, we’ll take a closer look at the adapter components."
  },
  {
    "objectID": "lectures/sequencing.html#paired-end-vs.-single-end-sequencing",
    "href": "lectures/sequencing.html#paired-end-vs.-single-end-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Paired-end vs. single-end sequencing",
    "text": "Paired-end vs. single-end sequencing\nIn Illumina sequencing, DNA fragments can be sequenced from both ends as shown below — this is called “paired-end” (PE) sequencing1:\n\n\n\n\n\n\nWhen sequencing is instead single-end (SE), it simply means that there is no reverse read:\n\n\n\n\n\n\nAs the image suggests, the reverse read is read from the other direction and the other strand (so if the forward and reverse reads fully overlapped, they would be “reverse complements”)."
  },
  {
    "objectID": "lectures/sequencing.html#paired-end-sequencing",
    "href": "lectures/sequencing.html#paired-end-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Paired-end sequencing",
    "text": "Paired-end sequencing\n\nPaired-end sequencing is a way to effectively increase the read length. (In the resulting sequence files, the two reads in each pair are separate, but can be matched thanks to shared read IDs.)\nEarlier, we saw that the maximum read length of Illumina is 300 bp but in paired-end sequencing, this becomes “2 x 300 bp”, etc.\n\n\n\nThe total size of the biological DNA fragment (without adapters) is often called the insert size:"
  },
  {
    "objectID": "lectures/sequencing.html#insert-size-variation",
    "href": "lectures/sequencing.html#insert-size-variation",
    "title": "High-throughput sequencing  and genomes",
    "section": "Insert size variation",
    "text": "Insert size variation\nThe insert size varies — because the library prep protocol can aim for various sizes, and because of variation due to limited precision in size selection. It can be:\n\nShorter than the combined read length, leading to overlapping reads:\n\n\n\n\n\n\n\n\nShorter than the single read length, leading to “adapter read-through”\n(i.e., the ends of the resulting reads will consist of adapter sequence):"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works",
    "text": "How Illumina sequencing works\nFirst, library fragments bind to a surface thanks to the adapters, and the DNA templates (the biological sequences) are then PCR-amplified to form “clusters” of identical fragments:\n\n\n\n\n\n\n\n\nIn the diagram above, for illustrative purposes:\n\n\n\nOnly a few nucleotides are shown (1 block = 1 nucleotide) — in reality, fragments are much longer\nOnly two templates =&gt; clusters are shown — in reality, there are millions"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-cont.",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works (cont.)",
    "text": "How Illumina sequencing works (cont.)\nThen, sequencing is performed by synthesizing a new strand using fluorescently-labeled bases and taking a picture each time a new nucleotide is incorporated:"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-cont.-1",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-cont.-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works (cont.)",
    "text": "How Illumina sequencing works (cont.)"
  },
  {
    "objectID": "lectures/sequencing.html#how-errors-come-about-in-illumina",
    "href": "lectures/sequencing.html#how-errors-come-about-in-illumina",
    "title": "High-throughput sequencing  and genomes",
    "section": "How errors come about in Illumina",
    "text": "How errors come about in Illumina\n\n\n\nThe different templates within a cluster get out of sync because occasionally:\n\nThey miss a base incorporation\nThey incorporate two bases at once\n\nBase incorporation may also terminate before the end of the template is reached\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis error profile is why, for Illumina:\n\n\n\nThere are hard limits on read lengths\nBase quality scores decrease along the read"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works: Zooming out",
    "text": "How Illumina sequencing works: Zooming out"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out-1",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works: Zooming out",
    "text": "How Illumina sequencing works: Zooming out"
  },
  {
    "objectID": "lectures/sequencing.html#a-closer-look-at-the-adapter-components",
    "href": "lectures/sequencing.html#a-closer-look-at-the-adapter-components",
    "title": "High-throughput sequencing  and genomes",
    "section": "A closer look at the adapter components",
    "text": "A closer look at the adapter components\nNow that you have a better idea of how Illumina sequencing works, let’s take a closer look at the different components of the adapters flanking the DNA:\n\n\n\n\n\nModified after http://nextgen.mgh.harvard.edu/IlluminaChemistry.html"
  },
  {
    "objectID": "lectures/sequencing.html#long-read-hts",
    "href": "lectures/sequencing.html#long-read-hts",
    "title": "High-throughput sequencing  and genomes",
    "section": "Long-read HTS",
    "text": "Long-read HTS\nThe technologies underlying the two main long-read HTS technologies are very different, but have some commonalities beyond long reads — they:\n\n\n\nPerform “single-molecule” sequencing (no PCR amplification of library fragments)\nRequire higher quality & quantity DNA\nCan detect some base modifications, like methyl groups\nCan sequence RNA directly\n\n\n\n\n\n\n\n\n\n\nError rates are changing\n\n\nAs a shorthand that was universally true until recently, I mentioned earlier that long-read HTS has higher error rate than short-read (Illumina) HTS.\n\nHowever, error rates in one type of PacBio sequencing where individual fragments are sequenced multiple times (“HiFi”) are now lower than in Illumina."
  },
  {
    "objectID": "lectures/sequencing.html#nanopore-sequencing",
    "href": "lectures/sequencing.html#nanopore-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Nanopore sequencing",
    "text": "Nanopore sequencing\nA single strand of DNA passes through a nanopore —\nwhat is measured is the electrical current, which depends on which combination of bases passes through:\n\nhttps://www.genome.gov/genetics-glossary/Nanopore-DNA-Sequencing"
  },
  {
    "objectID": "lectures/sequencing.html#ont-nanopore-sequencers",
    "href": "lectures/sequencing.html#ont-nanopore-sequencers",
    "title": "High-throughput sequencing  and genomes",
    "section": "ONT (Nanopore) sequencers",
    "text": "ONT (Nanopore) sequencers\n\n\n\n\n\n\n\n\nUnder development!\n\n\nONT constantly releases new flow cells with updated technology, which have led to large decreases in error rates over the past decade and even over the past two or so years.\nAt the same time, there is also a lot of development in the base-calling software. Unlike with Illumina or PacBio, it is common & useful to receive raw, not-basecalled data files: re-basecalling the same data a few years later with new software (versions) can make a substantial difference."
  },
  {
    "objectID": "lectures/sequencing.html#ont-vs.-pacbio",
    "href": "lectures/sequencing.html#ont-vs.-pacbio",
    "title": "High-throughput sequencing  and genomes",
    "section": "ONT vs. PacBIO",
    "text": "ONT vs. PacBIO\nAdvantages of ONT:\n\nLow capital cost, portability (in-the-field sequencing!)\nRead length not inherently limited, some extremely long reads\nLower cost per base\n\n\n\nDisadvantages of ONT:\n\nHigher error rates\nSome systematic errors (e.g. homopolymers)"
  },
  {
    "objectID": "lectures/sequencing.html#overview",
    "href": "lectures/sequencing.html#overview",
    "title": "High-throughput sequencing  and genomes",
    "section": "Overview",
    "text": "Overview\nAll common genetic/genomic data files are plain-text, meaning that they can be opened by any text editor. However, they are often compressed to save space. The main types are:\n\nFASTA\nSimple sequence files, where each entry contains a header and a DNA/AA sequence.\nVersatile, anything from a genome assemblies, proteomes, and single sequence fragments to alignments can be in this format.\n\n\n\n\nFASTQ\nThe standard format for HTS reads — contains a quality score for each nucleotide.\nSAM/BAM\nAn alignment format for HTS reads\n\n\n\n\n\nGTF/GFF\nTables (tab-delimited) with information such as genomic coordinates on “genomic features” such as genes and exons. The files contain reference genome annotations."
  },
  {
    "objectID": "lectures/sequencing.html#fasta-files",
    "href": "lectures/sequencing.html#fasta-files",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTA files",
    "text": "FASTA files\nFASTA files contain one or more (sometimes called multi-FASTA) DNA or amino acid sequences, with no limits on the number of sequences or the sequence lengths.\n\n\nAs mentioned, they are versatile, and are the standard format for:\n\nGenome assembly sequences\nTranscriptomes and proteomes (all of an organism’s transcripts & amino acid sequences, resp.)\nSequence downloads from NCBI such as a single gene/protein or other GenBank entry\nSequence alignments (but not from HTS reads)"
  },
  {
    "objectID": "lectures/sequencing.html#fasta-files-cont.",
    "href": "lectures/sequencing.html#fasta-files-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTA files (cont.)",
    "text": "FASTA files (cont.)\nThe following example FASTA file contains two entries:\n&gt;unique_sequence_ID Optional description\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAAAA\n&gt;unique_sequence_ID2\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAATG\n\n\nEach entry contains a header and the sequence itself, and:\n\nHeader lines start with a &gt; and are otherwise “free form” but usually provide an identifier (and sometimes metadata) for the sequence\nA single sequence is often not on a single line, but spread across multiple lines with a fixed width\n\n\n\n\nFASTA file name extensions are variable:\n\nGeneric extensions are .fasta and .fa\nAlso used are extensions that explicitly indicate whether sequences are nucleotide (.fna) or amino acids (.faa)"
  },
  {
    "objectID": "lectures/sequencing.html#fastq",
    "href": "lectures/sequencing.html#fastq",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ",
    "text": "FASTQ\nFASTQ is the standard format for HTS reads.\nEach read forms one FASTQ entry and is represented by four lines, which contain, respectively:\n\n\nA header that starts with @ and e.g. uniquely identifies the read\nThe sequence itself\nA + (plus sign)\nOne-character quality scores for each base (hence FASTQ as in “Q” for “quality”)"
  },
  {
    "objectID": "lectures/sequencing.html#fastq-quality-scores",
    "href": "lectures/sequencing.html#fastq-quality-scores",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ quality scores",
    "text": "FASTQ quality scores\nThe quality scores we saw in the read on the previous slide represent an estimate of the error probability of the base call.\nSpecifically, they correspond to a numeric “Phred” quality score (Q), which is a function of the estimated probability that a base call is erroneous (P):\n\nQ = -10 * log10(P)\n\n\n\nFor some specific probabilities and their rough qualitative interpretation for Illumina data:\n\n\n\nPhred quality score\nError probability\nRough interpretation\n\n\n\n\n10\n1 in 10\nterrible\n\n\n20\n1 in 100\nbad\n\n\n30\n1 in 1,000\ngood\n\n\n40\n1 in 10,000\nexcellent"
  },
  {
    "objectID": "lectures/sequencing.html#fastq-quality-scores-cont.",
    "href": "lectures/sequencing.html#fastq-quality-scores-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ quality scores (cont.)",
    "text": "FASTQ quality scores (cont.)\nThis numeric quality score is represented in FASTQ files not by the number itself, but by a corresponding “ASCII character”.\nThis allows for a single-character representation of each possible score — as a consequence, each quality score character can conveniently correspond to (& line up with) a base character in the read.\n\n\n\n\nPhred quality score\nError probability\nASCII character\n\n\n\n\n10\n1 in 10\n+\n\n\n20\n1 in 100\n5\n\n\n30\n1 in 1,000\n?\n\n\n40\n1 in 10,000\nI\n\n\n\n\n\n\n\n\n\nA rule of thumb\n\n\nIn practice, you almost never have to manually check the quality scores of bases in FASTQ files, but if you do, a rule of thumb is that letter characters are good (Phred of 32 and up)."
  },
  {
    "objectID": "lectures/sequencing.html#fastq-cont.",
    "href": "lectures/sequencing.html#fastq-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ (cont.)",
    "text": "FASTQ (cont.)\nFASTQ files have no size limit, so you may receive a single file per sample, although:\n\n\nWith paired-end (PE) sequencing, forward and reverse reads are split into two files:\nforward reads contain R1 and reverse reads contain R2 in the file name.\nIf sequencing was done on multiple lanes, you get one (SE) or two (PE) files per lane per sample.1\n\n\n\n\nFASTQ files have the extension .fastq or .fq (but are commonly compressed, leading to fastq.gz etc.). All in all, having paired-end FASTQ files for 2 samples could look like this:\n# A listing of (unusually simple) file names:\nsample1_R1.fastq.gz\nsample1_R2.fastq.gz\nsample2_R1.fastq.gz\nsample2_R1.fastq.gz\n\nNote that libraries usually consist of a mixture of all samples (though standard multiplexing is up to 96 samples). As such, if you need more data than a single Illumina lane can produce, the same library is sequenced on multiple lanes, rather than creating libraries with fewer samples."
  },
  {
    "objectID": "lectures/sequencing.html#gtfgff",
    "href": "lectures/sequencing.html#gtfgff",
    "title": "High-throughput sequencing  and genomes",
    "section": "GTF/GFF",
    "text": "GTF/GFF\nThe GTF and GFF formats are tab-delimited tabular files that contain genome annotations, with:\n\nOne row for each annotated “genomic feature” (gene, exon, etc.)\nOne column for each piece of information about a feature, like its genomic coordinates\n\n\nSee the sample below, with an added header line (not normally present) with column names:\nseqname     source  feature start   end     score  strand  frame    attributes\nNC_000001   RefSeq  gene    11874   14409   .       +       .       gene_id \"DDX11L1\"; transcript_id \"\"; db_xref \"GeneID:100287102\"; db_xref \"HGNC:HGNC:37102\"; description \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; gbkey \"Gene\"; gene \"DDX11L1\"; gene_biotype \"transcribed_pseudogene\"; pseudo \"true\"; \nNC_000001   RefSeq  exon    11874   12227   .       +       .       gene_id \"DDX11L1\"; transcript_id \"NR_046018.2\"; db_xref \"GeneID:100287102\"; gene \"DDX11L1\"; product \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; pseudo \"true\"; \n\n\n\n\n\n\n\n\nSome details on the more important/interesting columns:\n\n\n\nseqname — Name of the chromosome, scaffold, or contig\nfeature — Name of the feature type, e.g. “gene”, “exon”, “intron”, “CDS”\nstart & end— Start & end position of the feature\nstrand — Whether the feature is on the + (forward) or - (reverse) strand\nattribute — A semicolon-separated list of tag-value pairs with additional information"
  },
  {
    "objectID": "lectures/sequencing.html#sambam",
    "href": "lectures/sequencing.html#sambam",
    "title": "High-throughput sequencing  and genomes",
    "section": "SAM/BAM",
    "text": "SAM/BAM\nUsing specialized bioinformatics tools, you can align HTS reads (in FASTQ files) to a reference genome assembly (in a FASTA file).\nThe resulting alignments are stored in the SAM (uncompressed) / BAM (compressed) format.\n\n\nSAM/BAM are tabular files with one line per alignment, each of which includes:\n\nThe position in the genome that the read aligned to\nA mapping score based on the length of the alignment and the number of mismatches\nThe sequence of aligned the read itself\n\n\n\n\n\n\n\n\n\n\nFile conversions\n\n\n\nFASTQ files can be converted to FASTA files (losing quality information) but not vice versa\nSAM/BAM files can be converted to FASTQ files (losing alignment information) but not vice versa\nProteome FASTA files can be produced from the combination of a FASTA genome assembly and a GFF/GTF genome annotation"
  },
  {
    "objectID": "lectures/sequencing.html#genome-sizes",
    "href": "lectures/sequencing.html#genome-sizes",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome sizes",
    "text": "Genome sizes\n\nGenome sizes of different organisms\n& variation in ploidy & genome organization"
  },
  {
    "objectID": "lectures/sequencing.html#genome-assembly-and-annotation",
    "href": "lectures/sequencing.html#genome-assembly-and-annotation",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome assembly and annotation",
    "text": "Genome assembly and annotation\nCreating a reference genome has two main steps: assembly and annotation.\nA few notes on genome assembly:\n\nMost assemblies are not “chromosome-level”, i.e. they don’t have one contiguous sequence for each chromosome. Instead, they consist of contigs and scaffolds, which can number in the thousands.\nEven chromosome-level assemblies are not 100% complete\nWith increasing usage & quality of long-read HTS, we are generating better assemblies\nTo create chromosome-level assemblies, other technologies typically also needed (Hi-C, optical mapping)\n\n\nA few notes on genome annotation:\n\nThe first step is structural annotation: the identification of genes and other genomic features within the genome sequence\nThe second step is functional annotation: giving names and assigning functions to (mostly) genes\n\n\n\n\n\n\n\nNote\n\n\nBoth genome assemblies and annotations are typically saved in a single file — more on that soon."
  },
  {
    "objectID": "lectures/sequencing.html#genome-assemblies-online",
    "href": "lectures/sequencing.html#genome-assemblies-online",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome assemblies online",
    "text": "Genome assemblies online\nTo find out available reference genome information, you should start by checking the NCBI’s databases at https://ncbi.nlm.nih.gov.\nHere you can see if your focal organism has one or more reference genomes, get some summary statistics on the assemblies, and download assembly and annotation files.\nFor example:\n\nGo to https://ncbi.nlm.nih.gov and enter the name of your organism — try “Aedes”"
  },
  {
    "objectID": "lectures/rnaseq.html#recap-central-dogma-omics",
    "href": "lectures/rnaseq.html#recap-central-dogma-omics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Recap: central dogma & omics",
    "text": "Recap: central dogma & omics"
  },
  {
    "objectID": "lectures/rnaseq.html#alternative-splicing-isoforms",
    "href": "lectures/rnaseq.html#alternative-splicing-isoforms",
    "title": "Transcriptomics with RNA-seq",
    "section": "Alternative splicing & isoforms",
    "text": "Alternative splicing & isoforms\n\nhttps://en.wikipedia.org/wiki/Protein_isoform"
  },
  {
    "objectID": "lectures/rnaseq.html#the-transcriptome",
    "href": "lectures/rnaseq.html#the-transcriptome",
    "title": "Transcriptomics with RNA-seq",
    "section": "The transcriptome",
    "text": "The transcriptome\nThe transcriptome is the full set of transcripts expressed by an organism, which:\n\n\nIs not at all stable across time & space in any given organism,\nunlike the genome but much like the proteome\nVaries both qualitatively (which transcripts are expressed) but especially quantitatively (how much of each transcript is expressed)"
  },
  {
    "objectID": "lectures/rnaseq.html#transcriptomics",
    "href": "lectures/rnaseq.html#transcriptomics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Transcriptomics",
    "text": "Transcriptomics\nTranscriptomics is the study of the transcriptome, i.e. the large-scale study of RNA transcripts expressed in an organism.\n\nThere are many approaches & applications — but most commonly, transcriptomics focuses on:\n\n\nmRNA rather than on noncoding RNA types such as rRNA, tRNA, and miRNA\nQuantifying gene expression levels (cf. most genomics approaches)\nStatistically comparing expression levels between groups (treatments, biotypes, tissues, etc.)\n\n\n[TODO: Add count comparison figure]"
  },
  {
    "objectID": "lectures/rnaseq.html#why-do-transcriptomics",
    "href": "lectures/rnaseq.html#why-do-transcriptomics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Why do transcriptomics?",
    "text": "Why do transcriptomics?\nConsidering…\n\nThat protein production gives clues about the activity of specific biological functions, and the molecular mechanisms underlying those functions;\nThat it is much easier to measure protein expression than transcript expression at large scales;\nThe central dogma\n\n\n… we can use gene expression levels as a proxy for protein expression levels and make functional inferences."
  },
  {
    "objectID": "lectures/rnaseq.html#why-do-transcriptomics-cont.",
    "href": "lectures/rnaseq.html#why-do-transcriptomics-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "Why do transcriptomics? (cont.)",
    "text": "Why do transcriptomics? (cont.)\nSpecifically, we can use transcriptomics to:\n\n\nCompare & contrast phenotypic vs. molecular responses/differences\n\n\n\n\nFind the pathways and genes that:\n\nUnderlie phenotypic responses\nExplain differences between groups (treatments, genotypes, sexes, tissues, etc.)\nCan be targeted to enhance or reduce responses for pathogen and pest control"
  },
  {
    "objectID": "lectures/rnaseq.html#what-is-rna-seq",
    "href": "lectures/rnaseq.html#what-is-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "What is RNA-seq?",
    "text": "What is RNA-seq?\nRNA-seq is the current state-of-the-art family of methods to study the transcriptome.\nIt involves the random (“shotgun”) sequencing of millions of transcript fragments per sample.\n\nWe will focus on the most common type of RNA-seq, which:\n\n\nDoes not actually sequence the RNA, but first reverse transcribes RNA to cDNA\nAttempts to sequence only mRNA while avoiding noncoding RNAs (“mRNA-seq”)\nDoes not distinguish between RNA from different cell types (“bulk RNA-seq”)\nUses short reads (up to 150 bp) that do not cover full transcripts but do uniquely identify genes\n\n\n\n\n\n\n\n\n\n\nWhich type of RNA-seq?\n\n\nWhen people say “RNA-seq” without further specifications, you can assume they’re talking about this type."
  },
  {
    "objectID": "lectures/rnaseq.html#other-rna-seq-applications",
    "href": "lectures/rnaseq.html#other-rna-seq-applications",
    "title": "Transcriptomics with RNA-seq",
    "section": "Other RNA-seq applications",
    "text": "Other RNA-seq applications\nRNA-seq data can also be used for applications other than expression quantification, such as to:\n\nIdentify & analyze SNPs (for population genetics, molecular evolution, functional associations, etc)\n\n\n\nFor organisms without a reference genome: characterize the transcriptome, i.e. identify genes present in the organism\nFor organisms with a reference genome: discover new genes & transcripts, and improve genome annotation\n\n\n\n\nAll in all, RNA-seq is a very widely used technique — constitutes the most common usage of high-throughput sequencing!"
  },
  {
    "objectID": "lectures/rnaseq.html#rna-seq-project-examples",
    "href": "lectures/rnaseq.html#rna-seq-project-examples",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA-seq project examples",
    "text": "RNA-seq project examples\nRNA-seq is also the most common data type I assist with as a bioinformatician at the MCIC. Some projects I’ve been involved in used RNA-seq to identify genes & pathways that differ between:\n\nMultiple soybean cultivars in response to Phytophtora sojae inoculation; soybean in response to different Phytophtora species and strains (Dorrance lab, PlantPath)\nWheat exposed to Xanthomonas with a gene knock-out vs. knock-in (Jacobs lab, PlantPath)\n\n\n\n\nMated and unmated mosquitos (Sirot lab, College of Wooster)\nTissues of the ambrosia beetle and its symbiotic fungus (Ranger lab, USDA Wooster)\nDiapause-inducing conditions for two pest stink bug species (Michel lab, Entomology)\n\n\n\n\n\nHuman carcinoma cell lines with vs. without expression manipulation of a gene (Cruz lab, CCC)\nPig coronaviruses with vs. without an experimental insertion (Wang lab, CFAH)\n\n\n\n\nAs well as to improve the genome annotation of a plant-parasitic nematode (Taylor lab, PlantPath)."
  },
  {
    "objectID": "lectures/rnaseq.html#rna-seq-project-examples-cont.",
    "href": "lectures/rnaseq.html#rna-seq-project-examples-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA-seq project examples (cont.)",
    "text": "RNA-seq project examples (cont.)\n[TODO: 1 or 2 figs, e.g. from Tracy]"
  },
  {
    "objectID": "lectures/rnaseq.html#other-ways-of-quantifying-gene-expression",
    "href": "lectures/rnaseq.html#other-ways-of-quantifying-gene-expression",
    "title": "Transcriptomics with RNA-seq",
    "section": "Other ways of quantifying gene expression",
    "text": "Other ways of quantifying gene expression\nRNA-seq is not the only method to quantify gene expression, but often the preferred one:\n\n\nReverse-transcription qPCR (RT-qPCR)\nA low-throughput method that can quantify expression levels for one or a few genes at a time\n\n\n\n\nMicroarrays — hybridization of cDNA to preconstructed probes\nMicroarrays were the transcriptomics method of choice before the advent of high-throughput sequencing, but disadvantages relative to RNA-seq include:\n\nProduce relative measurements only with a much smaller dynamic range than RNA-seq\nCan only capture known features: cannot discover or examine novel features, and do not work for species without a (close) reference genome"
  },
  {
    "objectID": "lectures/rnaseq.html#microarrays",
    "href": "lectures/rnaseq.html#microarrays",
    "title": "Transcriptomics with RNA-seq",
    "section": "Microarrays",
    "text": "Microarrays\n\nBrown & Botstein 1999 (www.nature.com/articles/ng0199supp_33)"
  },
  {
    "objectID": "lectures/rnaseq.html#some-other-types-of-rna-seq",
    "href": "lectures/rnaseq.html#some-other-types-of-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "Some other types of RNA-seq",
    "text": "Some other types of RNA-seq\n\nSmall RNA-seq for small noncoding RNAs such as microRNAs and Piwi-interacting RNAs\nSingle-cell RNA-seq (scRNA-seq) — commonly used in cancer research\nSpatial RNA-seq – TODO add to this\nDirect RNA sequencing\n\n\n\n\n\n\n\n\n\n\n\nThe rest of this lecture and tomorrow’s lab will only focus on bulk RNA-seq of mRNA-derived cDNA."
  },
  {
    "objectID": "lectures/rnaseq.html#overview-of-steps-in-rna-seq",
    "href": "lectures/rnaseq.html#overview-of-steps-in-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "Overview of steps in RNA-seq",
    "text": "Overview of steps in RNA-seq\n\nBerge et al. 2019 (www.annualreviews.org/doi/10.1146/annurev-biodatasci-072018-021255)"
  },
  {
    "objectID": "lectures/rnaseq.html#experimental-design-groups-replicates",
    "href": "lectures/rnaseq.html#experimental-design-groups-replicates",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\nRNA-seq typically compares groups of samples defined by differences in:\n\nTreatments (e.g. different host plant, temperature, diet, mated/unmated) and/or\nOrganismal variants: ages/developmental stages, sexes, or genotypes (lines/biotypes/subspecies/morphs) and/or\nTissues\n\n\n\nTo be able to make statistically supported conclusions about expression differences between such groups of samples, we must have biological replication.\n\nThen, a so-called differential expression analysis compares sample groups and estimates a P-value for every single expressed (measured) gene."
  },
  {
    "objectID": "lectures/rnaseq.html#experimental-design-groups-replicates-1",
    "href": "lectures/rnaseq.html#experimental-design-groups-replicates-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\nWhen designing an RNA-seq experiment, keep the following in mind:\n\n\nNumbers of replicates\nThese are typically quite low: 3 replicates per treatment (x tissue x biotype, etc.) is the most common. Not advisable to go lower — if possible, use 4 or 5 replicates.\n\n\n\n\nStatistical comparison design\nPreferably, keep your design relatively simple with 1-2 independent variables and 2-3 levels for each of them. Specifically, pairwise comparisons are easiest to interpret."
  },
  {
    "objectID": "lectures/rnaseq.html#experimental-design-sidenote-dual-rna-seq",
    "href": "lectures/rnaseq.html#experimental-design-sidenote-dual-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design sidenote: dual RNA-seq",
    "text": "Experimental design sidenote: dual RNA-seq\nIn agricultural research, it is common to study both a plant host and its adversary.\nIf the adversary is a microbial/viral/fungal/oomycete pathogen, it is possible or necessary to collect samples that contain both host and pathogen.\n\n\nWhen these samples are subjected to RNA-seq, they will contain both host and pathogen reads.\nThese reads can be separated bioinformatically and when both host and pathogen reads are analyzed, this is called a dual RNA-seq experiment."
  },
  {
    "objectID": "lectures/rnaseq.html#overview-of-all-steps-in-rna-seq",
    "href": "lectures/rnaseq.html#overview-of-all-steps-in-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "Overview of all steps in RNA-seq",
    "text": "Overview of all steps in RNA-seq\n\nBerge et al. 2019 (www.annualreviews.org/doi/10.1146/annurev-biodatasci-072018-021255)"
  },
  {
    "objectID": "lectures/rnaseq.html#overview-of-library-prep-steps",
    "href": "lectures/rnaseq.html#overview-of-library-prep-steps",
    "title": "Transcriptomics with RNA-seq",
    "section": "Overview of library prep steps",
    "text": "Overview of library prep steps\n\nKukurba & Montgomery 2015 (www.ncbi.nlm.nih.gov/pmc/articles/PMC4863231/)\nBarcoding and multiplexing"
  },
  {
    "objectID": "lectures/rnaseq.html#rna-extraction",
    "href": "lectures/rnaseq.html#rna-extraction",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA extraction",
    "text": "RNA extraction\nThe first step is to extract RNA from tissue samples.\nThis is typically the only step you conduct yourself in the lab, with sequencing facilities taking care of downstream procedures.\n\nSome considerations:\n\n\nThe tissue sample should be collected from an organism that is alive or recently deceased (matter of minutes), and the RNA should be extracted immediately.\nWith the appropriate buffer and temperate, an RNA extraction can be stored long-term.\n\n\n\n\nHighly recommended to include a DNase treatment step to avoid DNA contamination.\nImportant to perform Quality Control (QC) on your extractions: quantity (e.g. with a Nanodrop or Qubit) and quality (degradation; e.g. with a gel)."
  },
  {
    "objectID": "lectures/rnaseq.html#rin-score",
    "href": "lectures/rnaseq.html#rin-score",
    "title": "Transcriptomics with RNA-seq",
    "section": "RIN score?",
    "text": "RIN score?"
  },
  {
    "objectID": "lectures/rnaseq.html#library-prep-options",
    "href": "lectures/rnaseq.html#library-prep-options",
    "title": "Transcriptomics with RNA-seq",
    "section": "Library prep options",
    "text": "Library prep options\n“Library preparation” is the series of lab steps to produce, from one or more RNA extraction, a collection of molecules ready to be sequenced: a sequencing “library”. (A sequencing facility typically does this for you.)\n\nLet’s consider different options you have for library prep:\n\n\nmRNA enrichment\nNeeded because mRNA makes up only a few percent of RNA molecules, and done using either:\n\nPolyA-selection: specifically selects mature (spliced) mRNAs\nRibodepletion: fishes out rRNA — this is suboptimal for mRNA-seq (presence of other RNAs and of pre-mRNAs) but can be a last resort with poor RNA quality\n\n\n\n\n\n\nLibrary strandedness\nLibraries can be “stranded” or “unstranded” —stranded libraries allow you to tell the directionality of a transcript, which in turn allows you to:\n\nDistinguish between overlapping genes\nAssess whether you may have DNA contamination"
  },
  {
    "objectID": "lectures/rnaseq.html#sequencing",
    "href": "lectures/rnaseq.html#sequencing",
    "title": "Transcriptomics with RNA-seq",
    "section": "Sequencing",
    "text": "Sequencing\n\nSequencing technology\n\nIllumina short reads are by far the most common\nPacBio or ONT long reads are an alternative if sequencing full transcripts (isoforms) is key\n\n\n\n\n\nSingle-end vs. paired-end reads (for Illumina)\n\nPaired-end has limited added value for reference-based, gene-level workflows (but can be key in other scenarios) — but it is still common as prices are often similar\n\n\n\n\n\n\nSequencing “depth” — how many reads per sample\n\nGuidelines highly approximate (cf. in genomics) — depends not just on transcriptome size, but also on expression level distribution, expression levels of genes of interest, etc.\nTypical recommendations are 20+ million reads per sample [CHECK]\nFor statistical power, more replicates are better than a higher sequencing depth"
  },
  {
    "objectID": "lectures/rnaseq.html#costs",
    "href": "lectures/rnaseq.html#costs",
    "title": "Transcriptomics with RNA-seq",
    "section": "Costs",
    "text": "Costs\nTODO"
  },
  {
    "objectID": "lectures/rnaseq.html#overview-of-steps",
    "href": "lectures/rnaseq.html#overview-of-steps",
    "title": "Transcriptomics with RNA-seq",
    "section": "Overview of steps",
    "text": "Overview of steps\n\nModified after Kukurba & Montgomery 2015"
  },
  {
    "objectID": "lectures/rnaseq.html#the-data-you-receive-reads-in-fastq-files",
    "href": "lectures/rnaseq.html#the-data-you-receive-reads-in-fastq-files",
    "title": "Transcriptomics with RNA-seq",
    "section": "The data you receive: reads in FASTQ files",
    "text": "The data you receive: reads in FASTQ files\nYou will typically receive a “demultiplexed” (split by sample) set of FASTQ files.\nMost commonly, sequencing for RNA-seq experiments is done on a single lane, so you will receive one (single-end) or two (paired-end) files per sample.\nThese are pretty large even in compressed form (1 or a few Gb each).\n[ADD SCREENSHOT]"
  },
  {
    "objectID": "lectures/rnaseq.html#from-reads-to-counts-overview",
    "href": "lectures/rnaseq.html#from-reads-to-counts-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "From reads to counts: overview",
    "text": "From reads to counts: overview\nOnce you receive your data, the first series of analysis steps involves going from the raw reads to a count table (the count table will have a read count for each gene in each sample).\n\n\nThis part is bioinformatics-heavy with large files, a need for lots of computing power such as with a supercomputer, command-line (Unix shell) programs — it specifically involves:\n\nRead preprocessing: QC, trimming, and optionally rRNA removal\nAligning reads to a reference genome (+ alignment QC)\nQuantifying expression levels (per-gene & per-sample to create a count table)\n\n\n\n\nThis can be run using standardized, one-size-fits-all workflows, and is therefore (relatively) suitable to be outsourced to a company, facility, or collaborator."
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-read-pre-processing",
    "href": "lectures/rnaseq.html#reads-to-counts-read-pre-processing",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: Read pre-processing",
    "text": "Reads to counts: Read pre-processing\nRead pre-processing includes the following steps:\n\n\nChecking the quantity and quality of your reads\n\nDoes not change your data, but helps decide next pre-processing steps / sample exclusion\nAlso useful to check for contamination, library complexity, and adapter content\nTypically done with the tool FastQC (and MultiQC for across-sample summaries)\n\n\n\n\n\nRemoving unwanted sequences\n\nAdapters, low-quality ends, and very short reads — with a tool like TrimGalore or Trimmomatic.\nrRNA-derived reads — with SortMeRNA (optional).\nContaminant sequences — with a taxonomic read classification program like Kraken2 (optional)."
  },
  {
    "objectID": "lectures/rnaseq.html#recap-isoforms-alternative-splicing",
    "href": "lectures/rnaseq.html#recap-isoforms-alternative-splicing",
    "title": "Transcriptomics with RNA-seq",
    "section": "Recap: isoforms & alternative splicing",
    "text": "Recap: isoforms & alternative splicing\n\n\n\n\n\n\nTranscript-level vs. gene-level\n\n\nThe terminology “transcript-level” vs. “gene-level”, e.g. in “transcript-level counts” refers to the distinction between having separate counts for each isoform (AKA transcript) versus a single count for each gene. Gene-level counts may either have been aggregated across isoforms, or reads were never assigned to isoforms in the first place."
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: Alignment to a reference genome",
    "text": "Reads to counts: Alignment to a reference genome\nThe alignment of reads to a reference genome needs to be “splice-aware”.\nAlternatively, you can align to the transcriptome (i.e., all mature transcripts).\n\nBerge et al. 2019 (www.annualreviews.org/doi/10.1146/annurev-biodatasci-072018-021255)"
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome-1",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: Alignment to a reference genome",
    "text": "Reads to counts: Alignment to a reference genome\nThe alignment of reads to a reference genome needs to be “splice-aware”.\nAlternatively, you can align to the transcriptome (i.e., all mature transcripts).\n\nAlignment usually consists of two steps:\n\nOne-time creation of a tool-specific “index” of the reference genome/transcriptome.\nFor each sample independently, alignment of the reads to the reference index.\n\n\n\n\n\n\n\n\nAlignment tools\n\n\nSome of the currently most commonly used alignment tools are HISAT2 & STAR (map to genome), and RSEM & Salmon & Kallisto (map to transcriptome)."
  },
  {
    "objectID": "lectures/rnaseq.html#what-if-i-dont-have-a-reference-genome",
    "href": "lectures/rnaseq.html#what-if-i-dont-have-a-reference-genome",
    "title": "Transcriptomics with RNA-seq",
    "section": "What if I don’t have a reference genome?",
    "text": "What if I don’t have a reference genome?\nWithout a reference genome, an RNA-seq project is considerably more work.\nThese two extra steps are needed:\n\n\nDe novo transcriptome assembly\nFirst, your reads can be used to first assemble a transcriptome from scratch with a tool like Trinity. (This is quite compute-intensive!)\n\n\n\n\nTranscriptome annotation\nThen, your transcriptome will need to be functionally annotated:\n\nThis means you try to assign gene names and functional categories to your transcripts\nA very similar process to genome annotation, and works in part by using BLAST or related tools to find orthologous, already annotated, genes in other organisms.\n\n\n\n\n\nThen, you can align to your newly assembled transcriptome the same way you would align to a reference transcriptome (obviously, you won’t have the option to align to the genome)."
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-qc",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-qc",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment QC",
    "text": "Reads to counts: alignment QC\nThese kind of stats can only be assessed after aligning to the genome (vs. to the transcriptome)1.\n\nAlignment rates\nWhat percentage of reads was successfully aligned?\n\nLow rates (&lt;80%) =&gt; cross-species contamination or poor reference genome quality\nMulti-mapped reads (mapping to multiple locations in the genome) are typically accepted by the mapper but are not or probabilistically quantified — more on this later.\n\n\n\n\n\nAlignment targets\nWhat percentages of aligned reads mapped to exons vs. introns vs. intergenic regions?\n\nHigh intronic mapping rates =&gt; presence of pre-mRNA\nHigh intergenic mapping rates =&gt; DNA contamination or poor genome assembly/annotation quality\n\n\n\nIf you have a genome but you are mapping to the transcriptome to generate counts, you should consider also mapping to the genome to be able to perform this."
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-qc-1",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-qc-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment QC",
    "text": "Reads to counts: alignment QC\n\nAcross-gene coverage distribution\nAn uneven distribution may indicate high levels of RNA degradation\n\n\n\nOutlier samples\nAre patterns consistent across samples or are there outliers that may need to be removed?\n\n\n\n\n\n\n\n\nAlignment QC tools\n\n\nYou can get these stats by checking the aligner’s “log” outputs, and by running tools like QualiMap and RSeQC."
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-quantification",
    "href": "lectures/rnaseq.html#reads-to-counts-quantification",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: quantification",
    "text": "Reads to counts: quantification\nAt heart, a simple counting exercise once you have the alignments in hand.\nBut made more complicated by sequencing biases and multi-mapping reads.\n\n\nSeveral metrics of gene expression levels exist:\n\nAdjusted by gene length and library size\nE.g., FPKM (superseded) and TPM (Transcripts Per Million)\nRaw counts\nThese are used by most downstream approaches (more later).\n\n\n\n\nCurrent best-performing tools (Salmon, Kallisto) do transcript-level quantification — even though this is typically followed by gene-level aggregation prior to downstream analysis.\n\n\n\n\n\n\n\nFast-moving field\n\n\nSeveral very commonly used tools like FeatureCounts (&gt;15k citations) and HTSeq (&lt;18k citation) have become disfavored in the past couple of years, as they e.g. don’t count multi-mapping reads at all."
  },
  {
    "objectID": "lectures/rnaseq.html#a-best-practice-workflow-to-produce-counts",
    "href": "lectures/rnaseq.html#a-best-practice-workflow-to-produce-counts",
    "title": "Transcriptomics with RNA-seq",
    "section": "A best-practice workflow to produce counts",
    "text": "A best-practice workflow to produce counts\nNf-core RNAseq workflow cc"
  },
  {
    "objectID": "lectures/rnaseq.html#count-table-analysis-overview",
    "href": "lectures/rnaseq.html#count-table-analysis-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "Count table analysis: overview",
    "text": "Count table analysis: overview\nThe second part of RNA-seq data analysis involves analyzing the count table.\nIn contrast to the first part, this can be done on a laptop and instead is heavier on statistics, data visualization and biological interpretation.\n\n\n\n\n\n\nDIY!\n\n\nThis part also more custom and iterative and I do not recommend to have this done by a third party.\n\n\n\n\n\nTypically done using the specialized RNA-seq “packages” in the R language. Common steps involve:\n\nPCA\nAssessing overall sample clustering patterns with a Principal Component Analysis (PCA)\nDifferential expression analysis\nFinding genes that differ in expression level between sample groups (DEGs)\nFunctional enrichment analysis\nSee whether certain gene functions are overrepresented among DEGs"
  },
  {
    "objectID": "lectures/rnaseq.html#pca-differential-expression-analysis",
    "href": "lectures/rnaseq.html#pca-differential-expression-analysis",
    "title": "Transcriptomics with RNA-seq",
    "section": "PCA & Differential expression analysis",
    "text": "PCA & Differential expression analysis\nTwo or more groups are typically compared, such as plants exposed to virulent vs. avirulent aphids.\n\nA PCA can tell you whether there’s an overall difference in the plant’s transcriptional response between treatments\n\n[PCA example fig]\n\nA Differential Expression (DE) analysis allows you to quantify the magnitude of this difference, and especially to pinpoint specific genes with statistically significant differences in expression levels (Differentially Expressed Genes, DEGs)."
  },
  {
    "objectID": "lectures/rnaseq.html#de-analysis-1-pairwise-comparison",
    "href": "lectures/rnaseq.html#de-analysis-1-pairwise-comparison",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: >1 pairwise comparison",
    "text": "DE analysis: &gt;1 pairwise comparison\nMore than two groups\n\n\nPlants exposed to:\n\nA virulent pathogen\nAn avirulent pathogen\nA mock inoculation\n\n\nPairwise comparisons:\n\nVirulent vs. avirulent\nMock vs. virulent\nMock vs. avirulent\n\n\n\n\n\nMore than one independent variable\n\n\n\nPlant type: resistant & susceptible\nPathogen type: virulent & avirulent\n\n\n\nResistant plant vs. virulent pathogen\nResistant plant vs. avirulent pathogen\nSusceptible plant vs. virulent pathogen\nSusceptible plant vs. avirulent pathogen"
  },
  {
    "objectID": "lectures/rnaseq.html#de-analysis-other-designs",
    "href": "lectures/rnaseq.html#de-analysis-other-designs",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: other designs",
    "text": "DE analysis: other designs\nStatistical designs other than pairwise comparisons are also possible. For example:\n\nTime series (or other continuous variables; regression analysis)\nWhich genes have monotonous in- or decreases across three or more time points?\n\n\n\n\nControlling for an independent variable (fixed or random effect)\nAssessing the effect of one variable while controlling for another. E.g.:\n\nWhich genes respond similarly to a virulent (vs. avirulent) pathogen in resistant and susceptible plants?\nWhich genes respond similarly to a virulent (vs. avirulent) pathogen regardless of field plot?\n\n\n\n\n\n\nInteraction effects between two independent variables\nE.g.: which genes respond differently to a virulent (vs. avirulent) pathogen in resistant and susceptible plants?"
  },
  {
    "objectID": "lectures/rnaseq.html#de-analysis-general-statistical-considerations",
    "href": "lectures/rnaseq.html#de-analysis-general-statistical-considerations",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: general statistical considerations",
    "text": "DE analysis: general statistical considerations\n\nGene count normalization\nTo be able to fairly compare samples, raw counts need to be adjusted:\n\nBy library size, which is the total number of gene counts per sample\nBy library composition, e.g. to correct for sample-specific extremely abundant genes that “steal” most of that sample’s counts\n\n\n\n\n\n\n\n\nWhat about gene lengths?\n\n\nEven though longer genes are more likely to be samples and gene counts are therefore confounded by gene length, there is no normalization by gene length, because genes are not compared.\n\n\n\n\n\nProbability distribution of the count data\n\nGene counts have higher variance than a Poisson distribution: negative binomial distribution is typically used.\nVariance (“dispersion”) estimates are gene-specific but “borrow” information from other genes (details beyond the scope of this lecture)."
  },
  {
    "objectID": "lectures/rnaseq.html#de-analysis-general-statistical-considerations-cont.",
    "href": "lectures/rnaseq.html#de-analysis-general-statistical-considerations-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: general statistical considerations (cont.)",
    "text": "DE analysis: general statistical considerations (cont.)\n\nMultiple-testing correction\n\n10,000+ genes are independently tested during a DE analysis, so there is a dire need for multiple testing correction.\nThe standard method is not the very strict Bonferroni correction but the Benjamini-Hochberg (BH) method.\n\n\n\n\n\nLog2-fold changes (logFC/LFC) as a measure of expression difference\n\nTODO\n\n\nSpecialized R/Bioconductor packages like DESeq2 and EdgeR make differential expression analysis relatively straightforward and automatically take care of the abovementioned considerations (we will use DESeq2 in the lab)."
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-introduction",
    "href": "lectures/rnaseq.html#functional-enrichment-introduction",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: introduction",
    "text": "Functional enrichment: introduction\nLists of DEGs can be quite long, and it is not always easy to make biological sense of them. Functional enrichment analyses help with this.\n\nThey check whether certain functional categories of genes (e.g., biological processes, or pathways) are statistically overrepresented among up- and/or downregulated genes."
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-database-overview",
    "href": "lectures/rnaseq.html#functional-enrichment-database-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: database overview",
    "text": "Functional enrichment: database overview\nThere are a number of databases that group genes into functional categories, but the two main ones used for enrichment analysis are:\n\nGene Ontology (GO)\nKyoto Encyclopedia of Genes and Genomes (KEGG)\n\n\n\nGenome annotations for a specific organism often but not always include GO or KEGG annotations.\nKEGG annotations are more commonly missing but can also be more easily generated, by uploading a FASTA file with amino acid sequences to KEGG’s GhostKOALA webservice: https://www.kegg.jp/ghostkoala/."
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-go",
    "href": "lectures/rnaseq.html#functional-enrichment-go",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: GO",
    "text": "Functional enrichment: GO\n\nGenes are assigned zero, one or more GO “terms”\nHierarchical structure with more specific terms grouping into more general terms\nConsists of three “ontologies”:\n\nBiological Process\nMolecular Function\nCellular Component"
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-kegg",
    "href": "lectures/rnaseq.html#functional-enrichment-kegg",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: KEGG",
    "text": "Functional enrichment: KEGG\n\nOrthologs, modules and pathways\nContains fewer genes than GO\n\n[Include pathway figure]"
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-statistics",
    "href": "lectures/rnaseq.html#functional-enrichment-statistics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: statistics",
    "text": "Functional enrichment: statistics\nThe two most common statistical approaches are:\n\nOverrepresentation Analysis (ORA)\nWith a list of genes divided in two groups (DE vs. not-DE1), test whether the groups contain different frequencies of each functional gene category, like a Chi-Square/Fisher’s Exact Test:\n\n\n\n\n\nDE\nnot-DE\n\n\n\n\nIn photosynthesis category\n15\n30\n\n\nNot in photosynthesis category\n85\n14,870\n\n\n\n\n\n\nGene Set Enrichment Analysis (GSEA)\nUses the expression level change (log-fold changes, LFC) of each gene and does not take statistical significance into account. It basically asks whether the LFCs of genes in a category are significantly shifted away from zero, either upregulated or downregulated.\n\n\nYou may also choose to separately analyzed upregulated DEGs and downregulated DEGs, i.e. to separate DEGs by the direction of differential expression."
  },
  {
    "objectID": "lectures/sequencing.html#what-about-rna",
    "href": "lectures/sequencing.html#what-about-rna",
    "title": "High-throughput sequencing  and genomes",
    "section": "What about RNA?",
    "text": "What about RNA?\nThis lecture mostly talks about DNA sequencing, but:\n\nThis includes the indirect sequencing of RNA after reverse transcription to cDNA, as in nearly all “RNA-seq”.\nDirect RNA sequencing is possible with some of the sequencing technologies we discuss, as I’ll briefly mention later, but is hard and not (yet) widely used.\n\n\n\nSimilarly, the shorthand “sequencing”, like in “high-throughput sequencing” in the title of this presentation, generally refers to DNA sequencing."
  },
  {
    "objectID": "lectures/sequencing.html#genomes-1",
    "href": "lectures/sequencing.html#genomes-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genomes",
    "text": "Genomes\nAs methods facilitating genomics and transcriptomics research, genomes loom large in HTS. Specifically, most HTS applications either require a “reference genome” or involve its production.\n\n\nWhat exactly does “reference genome” refer to? Three components to this phrase:\n\nAssembly\nIt includes a representation of most of the genome DNA sequence: the genome assembly\n\n\n\n\nAnnotation\nIt (preferably) includes an “annotation” that provides the locations of genes and other genomic features, as well as functional information on these features\n\n\n\n\nTaxonomic identity\nThis is typically considered at the species level, in which case it should involve the focal species. But:\n\nIf necessary, it is often possible to work with reference genomes of closely related species\nConversely, different reference genomes may exist for different subspecies/populations within a species"
  },
  {
    "objectID": "lectures/sequencing.html#genome-size-variation",
    "href": "lectures/sequencing.html#genome-size-variation",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome size variation",
    "text": "Genome size variation\n\nhttps://en.wikipedia.org/wiki/Genome_size"
  },
  {
    "objectID": "lectures/sequencing.html#genome-structure",
    "href": "lectures/sequencing.html#genome-structure",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome structure",
    "text": "Genome structure\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Karyotype\n\n\n\n   \nKey features:\n\nNumber of distinct chromosomes\nPloidy"
  },
  {
    "objectID": "lectures/sequencing.html#genome-size-variations",
    "href": "lectures/sequencing.html#genome-size-variations",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome size variations",
    "text": "Genome size variations\n\nhttps://en.wikipedia.org/wiki/Genome_size"
  },
  {
    "objectID": "lectures/sequencing.html#genome-assembly-annotation",
    "href": "lectures/sequencing.html#genome-assembly-annotation",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome assembly & annotation",
    "text": "Genome assembly & annotation\nCreating a reference genome has two main steps: assembly and annotation.\n\nA few notes on genome assembly:\n\n\nMost assemblies are not “chromosome-level”, i.e. they don’t have one contiguous sequence for each chromosome. Instead, they consist of contigs and scaffolds, which can number in the thousands.\nEven chromosome-level assemblies are not 100% complete\nWith increasing usage & quality of long-read HTS, we are generating better assemblies\nTo create chromosome-level assemblies, other technologies typically also needed (Hi-C, optical mapping)"
  },
  {
    "objectID": "lectures/sequencing.html#genome-assembly-annotation-1",
    "href": "lectures/sequencing.html#genome-assembly-annotation-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome assembly & annotation",
    "text": "Genome assembly & annotation\nA few notes on genome annotation:\n\n\nThe first step is structural annotation: the identification of genes and other genomic features within the genome sequence\nThe second step is functional annotation: giving names and assigning functions to (mostly) genes\nWhereas genome assembly typically does not borrow information from other organisms, genome annotation very heavily relies on that, based on the concept of sequence homology.\n\n\n\n\n\n\n\n\n\n\nHow is this data stored?\n\n\nBoth genome assemblies and annotations are typically saved in a single text file each — more on that soon."
  },
  {
    "objectID": "labs/FASTQ.html#introduction",
    "href": "labs/FASTQ.html#introduction",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "1 Introduction",
    "text": "1 Introduction\nx"
  },
  {
    "objectID": "labs/FASTQ.html#computational-infrastructure",
    "href": "labs/FASTQ.html#computational-infrastructure",
    "title": "Week 3 lab: Genome and HTS data",
    "section": "2 Computational Infrastructure",
    "text": "2 Computational Infrastructure"
  },
  {
    "objectID": "labs/FASTQ.html#computational-infrastructure-overview",
    "href": "labs/FASTQ.html#computational-infrastructure-overview",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "2 Computational infrastructure overview",
    "text": "2 Computational infrastructure overview\nDue in large part to the amount of data involved, you don’t typically use a laptop or desktop computer to work with HTS data, or with genomics and transcriptomics data more generally.\nAdditionally, most of the specialized tools (i.e., programs / software) that help you analyze your data can only be run through a “command-line interface” (CLI).\n\n\n\n\n\n\nAdditional advantages\n\n\n\nAnd even those that have a “graphical user interface” (GUI) are more efficiently and reproducibly run through a CLI:\n\nEfficiency — A CLI allows you to write a simple loop to run it in the same way for many samples. (In combination with the computing power of a supercomputer, this in turn allows you to process those hundreds of samples in parallel.)\nReproducibility — You can easily save all commands and scripts which would allow you to rerun a project rather straightforwardly.\n\n\n\nTherefore, a typical computational infrastructure to do what we may call “command-line genomics” involves:\n\nA supercomputer1 — in our case, the Ohio Supercomputer Center (OSC)\nA text editor — I recommend and will demonstrate VS Code\nThe Unix shell (terminal)\nR (or perhaps Python) for interactive statistical analysis and visualization.\n\nBelow, we will go through the first three of these. In the lab next week, we will cover the fourth.\n\n\n\n\n\n\nNote\n\n\n\n[Often dividable in 2 sections: compute-heavy command-line programs, then not compute-heavy with R.]\nA genomics project usually involves sequentially running an array of bioinformatics programs (or “tools”). For instance, as we’ll discuss next week, an RNA-seq project may include:\n\nraw read QC =&gt; raw read trimming =&gt; read alignment mapping =&gt; gene counting\n\n\n\n\n\n\n\n\n\nCan I avoid all of this?\n\n\n\nIf you will often do genomics projects like the ones mentioned above, it’s hard to avoid using the infrastructure as described. But here are some conditions in which you might reasonably avoid it:\n\nYou’re doing a single genomics project, your main research focus is elsewhere\nYou have data which can be analyzed with a relatively small command-line-based part, such as metabarcoding or RNA-seq.\n\nIn such cases, you might be able to get someone else to do the command-line work, or you could try Galaxy, a cloud-based bioinformatics platform with a web browser interface and no coding."
  },
  {
    "objectID": "labs/FASTQ.html#the-ohio-supercomputer-center-osc",
    "href": "labs/FASTQ.html#the-ohio-supercomputer-center-osc",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "3 The Ohio Supercomputer Center (OSC)",
    "text": "3 The Ohio Supercomputer Center (OSC)\n\n3.1 Introduction to OSC\n\nWhat is a supercomputer?\nA supercomputer is a highly interconnected set of many computer processors and storage units. You can think of it simply as a network of computers.\nSupercomputers are also commonly referred to as High-Performance Computing (HPC) clusters or simply compute clusters. This is what Owens, one of the OSC supercomputers, physically looks like:\n\n\n\n\n\nWhy do I need a supercomputer?\n\nOften, your genomics dataset is too large to be handled efficiently, or even at all, by a laptop or desktop computer.\nTo speed up long-running analyses by using more computing power, and repeated analyses (like the independent alignment of reads for different samples) by running them in parallel.\nIt’s also a great place to store large amounts of data.\n\n\n\nThe Ohio Supercomputer Center (OSC)\n\n\n\nThe Ohio Supercomputer Center (OSC) provides computing resources to researchers (and others) across Ohio.\nOSC has two supercomputers/clusters (named Owens and Pitzer), and lots of infrastructure for their usage. Research usage is charged but at heavily subsidized rates, and most or all OSU colleges absorb these costs at the college level (!).\n\n\nThe Structure of a Supercomputer\nWe can think of a supercomputer as having three main parts:\n\nFile Systems: Where files are stored (these are shared between the two OSC clusters)\nLogin Nodes: The handful of computers everyone shares after logging in\nCompute Nodes: The many computers you can reserve to run your analyses\n\n\n\n\n\n\nWhat is different on a supercomputer like at OSC?\nCompared to command-line computing on a laptop or desktop, the following aspects are different when working on a supercomputer like at OSC?\n\nOperating system\nLogin versus compute nodes (node ≈ computer)\n“Login nodes”, the nodes you end up on after logging in, are not meant for heavy computing and you have to request access to “compute nodes” to run most analyses.\nSoftware\nBecause you don’t have administrator rights, and because the system is shared by so many people, you generally can’t install and use software “the regular way”.\n\nFor system-wide installed software: some programs are directly available, while more specialized programs like for bioinformatics need to be explicitly loaded.\nIf something is not installed, it’s best to ask OSC, or use solutions like Conda or containers that are outside the scope of this introduction.\n\n“Non-interactive” usage is common, using a job scheduler (Slurm)\nYou submit your scripts to the Slurm queue and monitor the resulting jobs. We will …\n\n\n\n\n\n3.2 The OSC OnDemand web portal\nThe OSC OnDemand web portal allows you to use a web browser to access OSC resources such as:\n\nA file browser where you can also create and rename folders and files, etc.\nA Unix shell\nA host of “Interactive Apps”: programs such as RStudio, Jupyter, VS Code and QGIS.\n\nWhen you go to https://ondemand.osc.edu, you first need to log in with your OSC (not OSU!) credentials. After that, you should see a landing page similar to the one below:\n\n\n\nThe main part of the page (below the logo) only contains some general OSC messages and updates — what we will focus on instead are some of the options in the blue bar along the top.\n\nFile System Access\nLet’s start with Files. Hovering over this dropdown menu gives a list of directories you have access to. If your account is brand new, you should only have three:\n\nA Home directory (starts with /users)\n\nTwo directories directly associated with the OSC “project” PAS2250 that I added you to: 2\n\nA “project” directory (starts with /fs/ess) — permanent, backed-up storage\nA “scratch” directory (starts with /fs/scratch) — temporary storage\n\nI’ll select the scratch directory, /fs/scratch/PAS2250:\n\n\n\nOnce there, I can see a list of directories and files inside this Project directory, and I can click on the directories to explore the contents further:\n[IMAGE TBA]\nThis interface is much like the file browser on your own computer, so you can also create, delete, move and copy files and folders, and even upload (from your computer to OSC) and download (from OSC your computer) files3 — see the buttons across the top.\n\n\nOn Your Own: Create your own folder\nTBA\n\n\nUnix Shell Access (under Clusters)\nInteracting with a supercomputer in a point-and-click manner only goes so far. Using a supercomputer effectively requires interacting with the system using a command-line interface (CLI) of a Unix shell.\nUnder the Clusters dropdown menu, you can access a Unix shell either on Owens or Pitzer:\n\n\n\nI’m selecting a shell on the Pitzer supercomputer, which will open a new browser tab looking like this:\n\n\n\nWe most commonly interact with a supercomputer using a Unix shell, and we’ll learn about the basics of doing so soon. However, we’ll mostly be accessing a Unix shell in a different manner, namely inside the VS Code text editor, which also gives us some additional functionality in a user-friendly way.\n\n\nInteractive Apps\nWe can access programs with Graphical User Interfaces (GUIs; point-and-click interfaces) via the Interactive Apps dropdown menu 4 — let’s select VS Code using the “Code Server” button:"
  },
  {
    "objectID": "labs/FASTQ.html#the-unix-shell",
    "href": "labs/FASTQ.html#the-unix-shell",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "5 The Unix shell",
    "text": "5 The Unix shell\n\n5.1 What is the Unix shell?\nA computer’s shell is the interface in a Terminal window that allows you to interact with your computer by typing commands rather than pointing-and-clicking.\nIt is also referred to as the the “command line” — with “command-line tools/programs” being software that is run using shell commands.\nFinally, the Unix shell, then, is the shell of Unix-based computers, which include Mac and Linux (but not Windows) operating systems. 7\n\n\n\n\n\n\nMany bioinformatics programs are basically specialized commands\n\n\n\nIn many ways, as mentioned in the box above, you can think of using a command-line bioinformatics program as using just another command.\nTherefore, our general skills with Unix commands will very much extend to using command-line bioinformatics tools!\n\n\n\n\n5.2 First steps in the Unix shell\n\nThe prompt\nInside your terminal, the “prompt” indicates that the shell is ready for a command. Our prompt at OSC should show the following pieces of information like so:\n[&lt;username&gt;@&lt;node-name&gt; &lt;working-dir&gt;]$\nFor example:\n[jelmer@p0080 jelmer]$ \nWe type our commands after the dollar sign $, and then press Enter to execute the command. When the command has finished executing, we’ll get our prompt back and can type a new command.\n\n\n\n\n\n\nHow shell code is shown on this website (click to expand)\n\n\n\n\n\nThe gray boxes like the ones shown above will be used to show the command line expressions that you should type.\nIn upcoming boxes, the prompt itself ([...]$) will not be shown, but only the command line expressions that you type. This is to save space and to allow you for copy-and-pasting (but I recommend typing!).\nPaler gray boxes below, with italic text, are intended to show the output of commands.\n\n\n\n\n\nA few simple commands: date, whoami, pwd\nThe Unix shell comes with hundreds of commands. Let’s start with a few simple ones.\n\nThe date command prints the current date and time:\n\ndate\nFri Jan 26 14:31:51 EST 2024\n\nThe whoami (who-am-i) command prints your username:\n\nwhoami\njelmer\n\nThe pwd (Print Working Directory) command prints the path to the directory (=folder) you are currently located in:\n\npwd\n/fs/ess/PAS2250/ENT6703/jelmer\nAll 3 of those commands provided us with some output. That output was printed to screen, which is the default behavior for nearly every Unix command.\n\n\n\n\n\n\nWorking directory and paths\n\n\n\n\nWhen working in a Unix shell, you are always “in” a specific directory (“dir” for short) and this is called your working directory.\nIn a path (= specification of the location of a file or directory) such as that output by pwd, directories are separated by forward slashes /.\nA leading forward slash in a path indicates the root directory of the computer.\n\n\n\n\n\n\n\n\n\nGeneral shell and supercomputer tips\n\n\n\n\nEverything in the shell is case-sensitive\nAvoid spaces in file and dir names! Use e.g. underscores or capitalization to distinguish words.\n\n\n\n\n\n\n\n5.3 cd and command actions, defaults, and arguments\nIn the above three command line expressions:\n\nWe merely typed a command and nothing else\nThe command provided some information, which was printed to screen\n\nBut many commands perform an action other than providing information. For example, you can use the command cd to Change Directory (i.e. change your working dir). And like many commands that perform and action, it normally has no output at all.\nLet’s use cd to move to another directory by specifying the path to that directory after the cd command (make sure to leave a space after cd!):\ncd /fs/ess/PAS2250/ENT6703/share/data/fastq\npwd\n/fs/ess/PAS2250/ENT6703/share/data/fastq\n\n\n\n\n\n\nI will demonstrate Tab completion!\n\n\n\n\n\n\nIn more abstract terms, what we did above was to provide cd with an argument, namely the path of the dir to move to. Arguments generally tell commands what file or directory to operate on, and come at the end of a command line expression.\nAs we’ve seen, then, cd gives no output when it succesfully changed the working directory. But let’s also see what happens when it does not succeed — it gives the following error:\ncd /fs/Ess/PAS0471\nbash: cd: /fs/Ess/PAS0471: No such file or directory\n\n\nYour Turn: What was the problem with the path we specified?\n\nWe used a capital E in /Ess/ — this should have been /ess/.\nAs pointed out above, paths (dir and file specifications) are case-sensitive on Unix systems!\n\n\n\n5.4 ls and command options\n\nThe default behavior of ls\nThe ls command, short for “list”, is a command to list files and directories:\nls\ndata  metadata  README.md\n(You should still be in /fs/ess/PAS2250/ENT6703/share. If not, cd there first.)\n\n\n\n\n\n\nls output colors (click to expand)\n\n\n\n\n\nUnfortunately, the ls output shown above does not show the different colors you should see in your shell — here are some of the most common ones:\n\nEntries in blue are directories (like data and metadata above)\nEntries in black are regular files (like README.md above)\nEntries in red are compressed files (we’ll see an example soon).\n\n\n\n\nThe default way that ls shows the output (e.g., non-recursively, all on one line, no details) can be changed by providing ls with options and/or arguments.\n\n\nOptions (to ls)\nIn general, whereas arguments tell a command what to operate on, options will modify its behavior. For example, we can call ls with the option -l (a dash followed by a lowercase L):\nls -l \ntotal 17\ndrwxr-xr-x 3 jelmer PAS0471 4096 Jul 27 11:53 data\ndrwxr-xr-x 2 jelmer PAS0471 4096 Jul 27 11:54 metadata\n-rw-r--r-- 1 jelmer PAS0471  963 Jul 27 16:48 README.md\nNotice that it lists the same three items as our first ls call above, but printed in a different format: one item per line, with additional information included, such as the date and time each file was last modified, and the file sizes (to the left of the date) in bytes.\nLet’s add another option, -h:\nls -l -h\ntotal 17K\ndrwxr-xr-x 3 jelmer PAS0471 4.0K Jul 27 11:53 data\ndrwxr-xr-x 2 jelmer PAS0471 4.0K Jul 27 11:54 metadata\n-rw-r--r-- 1 jelmer PAS0471  964 Jul 27 17:48 README.md\n\n\nYour Turn: What is different about the output, and what does that mean?\n\nThe difference is in the format of the column reporting the sizes of the items listed.\nWe now have “Human-readable filesizes” (hence -h), where sizes on the scale of kilobytes will be shown in Ks, of megabytes in Ms, and of gigabytes in Gs.\n\nConveniently, options can be pasted together as follows:\nls -lh   # Output not shown, same as above\n\n\nCombining options and arguments\nArguments to ls should be dirs or files to operate on. For example, if we wanted to see what’s inside the data dir, instead of inside our working dir, we could type:\nls data\nfastq\nWell, that’s not much information, just another dir — so let’s look inside that:\nls data/fastq  # These will be shown in red in your output, since they are compressed\nASPC1_A178V_R1.fastq.gz  ASPC1_G31V_R2.fastq.gz      Miapaca2_G31V_R1.fastq.gz\nASPC1_A178V_R2.fastq.gz  Miapaca2_A178V_R1.fastq.gz  Miapaca2_G31V_R2.fastq.gz\nASPC1_G31V_R1.fastq.gz   Miapaca2_A178V_R2.fastq.gz\nAh, gzipped FASTQ files! These contain our sequence data, and we’ll go and explore them in a bit.\nFinally, we can combine options and arguments, and let’s do so take a closer look at our dir with FASTQ files — now the -h option is especially useful because it makes it easy to see that the files vary between 4.1 MB and 5.3 MB in size:\nls -lh data/fastq\ntotal 38M\n-rw-r--r-- 1 jelmer PAS0471 4.1M Jul 27 11:53 ASPC1_A178V_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 4.2M Jul 27 11:53 ASPC1_A178V_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 4.1M Jul 27 11:53 ASPC1_G31V_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 4.3M Jul 27 11:53 ASPC1_G31V_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 5.1M Jul 27 11:53 Miapaca2_A178V_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 5.3M Jul 27 11:53 Miapaca2_A178V_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 5.1M Jul 27 11:53 Miapaca2_G31V_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 5.3M Jul 27 11:53 Miapaca2_G31V_R2.fastq.gz\n\n\n\n5.5 Unix shell recap\nWe’ve learned about structure of command line expressions in the Unix shell, which include: the command itself, options, arguments, and output (including, in some cases, error messages).\nA few general points to remember are that:\n\nCommands that take actions like changing directory will by default not print output.\nUsing options (ls -l), we can modify the behavior of a command, and using arguments (ls data), we can modify what it operates on in the first place.\n\n\n\n\n\n\n\nGeneral shell tips\n\n\n\n\nIf you hit the ⇧ (up arrow) once, you’ll retrieve your most recent command, and if you keep hitting it, you’ll go further back. The⇩ (down arrow) will go the other way: towards the present.\nTo execute a command, you can press Enter regardless of where your cursor is on the line; it does not need to be at the end of the line.\nIf your prompt is missing, the shell is either still busy executing your command, or you typed an incomplete command. To abort in either of these two scenarios, press Ctrl+C and you’ll get your prompt back.\n\n\n\n\n\nOn your own: practice with the above tips (click to expand)\n\nA somewhat silly example is the sleep command, which you can use to make the computer wait between successive commands:\n# This will \"run\" for 60 seconds, after which you get your prompt back \nsleep 60s\n# Press Ctrl + C to get your prompt back sooner!"
  },
  {
    "objectID": "labs/FASTQ.html#footnotes",
    "href": "labs/FASTQ.html#footnotes",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCloud computing is an alternative, but won’t be covered here.↩︎\nYou can be associated with multiple projects and for each one, a scratch and a project directory is added.↩︎\nThough this is not meant for large (&gt;1 GB) transfers. Different methods are available for those but are outside the scope of this introductions.↩︎\nThe menu item next to that, My Interactive Sessions, will list the currently active and finished Interactive App sessions.↩︎\nwe’ll be kicked off as soon as that amount of time has passed!↩︎\nIf you’ve closed the Welcome document but want it back, click\n   =&gt;   Help   =&gt;   Welcome.↩︎\nAnd the most common Unix shell is the Bash shell, which runs the Bash language.↩︎\nfull list of installed software: https://www.osc.edu/resources/available_software/software_list↩︎"
  },
  {
    "objectID": "labs/FASTQ.html#the-vs-code-text-editor",
    "href": "labs/FASTQ.html#the-vs-code-text-editor",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "4 The VS Code text editor",
    "text": "4 The VS Code text editor\n\n4.1 What is VS Code?\nVS Code (in full, Visual Studio Code) is basically a fancy text editor.\nTo emphasize the additional functionality relative to basic text editors like Notepad and TextEdit, editors like VS Code are also referred to as “IDEs”: Integrated Development Environments. The RStudio program is another good example of an IDE. For our purposes:\n\nVS code will be our IDE for Unix shell code (this week)\nRStudio will be our IDE for R (in the differential expression lab next week)\n\nConveniently, we can use a version of this editor (sometimes referred to as Code Server, like in the Interactive Apps menu) in our browser via the OSC OnDemand website.\n\n\n4.2 Connecting to VS Code\nBecause “Interactive Apps” like VS Code and RStudio run on compute nodes, we need to fill out a form and specify the following details (as shown in the image below) to reserve such a node:\n\nThe OSC Project that should be billed for the compute resource usage\nThe amount of time we want to make a reservation for 5\nThe “working directory” (starting location in the file system) for the program\nThe version of VS Code\n\n[TBA - form with correct values filled out]\nClick on Launch at the bottom and this will send your request to the compute job scheduler. First, your job will be “Queued” — that is, waiting for the job scheduler to allocate resources on the compute nodes to it:\n\n\n\nIn general, it should be granted resources within a few seconds (the card will then say “Starting”), and be ready for usage (“Running”) in another couple of seconds:\n\n\n\nThen, you can click on the blue Connect to VS Code button to open a new browser tab that runs VS Code. When VS Code opens, you may get these two pop-ups — click “Yes” and “Don’t Show Again”, respectively:\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 The VS Code User Interface\n\n\n\n\nSide bars\nThe Activity Bar (narrow side bar) on the far left has:\n\nA      (“hamburger menu”), which has menu items like File that you often find in a top bar.\nA      (cog wheel icon) in the bottom, through which you can mainly access settings.\nIcons that serve to switch between different options for the (wide) Side Bar — we’ll only use:\n\nExplorer: File browser (and, e.g., an outline for the active file)\nExtensions: To install extensions (we’ll install one later)\n\n\n\n\nEditor pane and Welcome document\nThe main part of the VS Code is the editor pane. Whenever you open VS Code, a tab with a Welcome document is automatically opened. This provides some help and e.g. a handy overview of recently opened folders.\nWe can also use the Welcome document 6 to open a new text file by clicking New file below Start (alternatively, click      =&gt;   File   =&gt;   New File), which opens as a second “tab” in the editor pane.\n\n\nTerminal (with a Unix shell)\n Open a terminal by clicking      =&gt; Terminal =&gt; New Terminal.\n\n\nOn Your Own: Try a few color themes\nOpen the Command Palette and start typing “color theme”, and you’ll see the relevant option pop up.\nThen, try out a few themes and see what you like!\n(You can also access the Color Themes option via      =&gt; Color Theme.)"
  },
  {
    "objectID": "labs/FASTQ.html#a-folder-as-a-starting-point",
    "href": "labs/FASTQ.html#a-folder-as-a-starting-point",
    "title": "Week 3 lab: Genome and HTS data",
    "section": "5 A folder as a starting point",
    "text": "5 A folder as a starting point\nConveniently, VS Code takes a specific folder (directory) as a starting point in all parts of the program:\n\nIn the file explorer in the side bar\nIn the terminal\nWhen saving files in the editor pane.\n\nBy default, VS Code via OnDemand will open your Home directory.\nHere, we’ll change to the project dir for OSC project PAS0471, which is /fs/ess/PAS0471.\n Let’s open that folder. Click Open folder... in the Welcome tab (or     =&gt;   File   =&gt;   Open Folder).\nYou’ll notice that the program completely reloads. And You might also see a pop-up like this – you can check the box and click Yes:\n\n\n\n\n\n\n\n\n\n\n\nTaking off where you were\n\n\n\nWhen you reopen a folder you’ve had open before, VS Code will resume where you were before in terms of:\n\nReopening any files you had open\nIf you had an active terminal, it will re-open a terminal.\n\nThis is quite convenient, especially when you start working on multiple projects (different folders) in VS Code and frequently switch between those."
  },
  {
    "objectID": "labs/FASTQ.html#some-vs-code-tips-and-tricks",
    "href": "labs/FASTQ.html#some-vs-code-tips-and-tricks",
    "title": "Week 3 lab: Genome and HTS data",
    "section": "6 Some VS Code tips and tricks",
    "text": "6 Some VS Code tips and tricks\n\n6.1 Making use of your screen’s real estate\nSince we are using VS Code inside a browser window, we are unfortunately losing some screen space. Make sure to maximize the browser window and if you have a bookmarks bar, you should consider hiding it (for Chrome: Ctrl/⌘+Shift+B).\nYou may also opt to hide the side bars using the   =&gt;   View   =&gt;   Appearance menu (or Ctrl/⌘+B for the (wide) Side Bar).\n\n\n6.2 Resizing panes\nYou can resize panes (the terminal, editor, and side bar) by hovering your cursor over the borders and then dragging it.\n\n\n6.3 The Command Palette / Color themes\nTo access all the menu options that are available in VS Code, the so-called “Command Palette” can be handy, especially if you know what you are looking for.\nTo access the Command Palette, click      and then Command Palette (or press F1 or Ctrl/⌘+Shift+P).\n\nOn Your Own: Try a few color themes\nOpen the Command Palette and start typing “color theme”, and you’ll see the relevant option pop up.\nThen, try out a few themes and see what you like!\n(You can also access the Color Themes option via      =&gt; Color Theme.)"
  },
  {
    "objectID": "labs/FASTQ.html#addendum",
    "href": "labs/FASTQ.html#addendum",
    "title": "Week 3 lab: Working with genome and HTS data",
    "section": "10 Addendum",
    "text": "10 Addendum\n\n10.1 Learning roadmap\nI’ve shown you the main pieces of the computational infrastructure for\n“command-line genomics”. We’ve seen a very basic example of loading and running a command-line tool at OSC.\nThe missing pieces for a fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\n(This used the same language (Bash) as the commands you’d type interactively, so at its most basic this involves pasting those commands into a text file.)\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\n(At its most basic, this involves putting sbatch in front of the script name.)\nTo make use of the capabilities of the supercomputer and speeding up our analysis, we can submit multiple jobs in parallel using a loop.\n\n\nSo what computational skills should I learn?\n\nThe core skills:\n\nUnix shell basics – the commonly used commands\nSome shell scripting basics\nSLURM basics to submit and manage your batch jobs\nR for “downstream”, statistical and visualization tasks\n\nWhen you start doing genomics projects more often:\n\nUsing conda or containers for software\nUnix data tools (grep, sed, awk, etc)\n\nWhen you want to become proficient in applied bioinformatics:\n\nVersion control with git\nMore advanced: formal workflow/pipeline management tools (e.g. Nextflow)\nMore advanced: Python (or advanced R) for custom data processing\n\n\n\n\nResources for further learning\n\nOSC\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A01_osc.html\nOSC’s online asynchronous courses\nOSC’s new User Resource Guide\n\nVS Code: https://mcic-osu.github.io/rnaseq-intro/modules/A02_vscode.html\nOnline Unix shell resources\n\nOSC’s UNIX Basics\nhttps://www.learnenough.com/command-line-tutorial\nhttps://cvw.cac.cornell.edu/Linux/\nhttp://www.ee.surrey.ac.uk/Teaching/Unix/\nhttps://www.udacity.com/course/linux-command-line-basics--ud595\nhttp://moo.nac.uci.edu/~hjm/How_Programs_Work_On_Linux.html\n\nOSU courses and workshops\n\nJonathan Fresnedo Ramirez’s “Genome Analytics” course (HCS 7004)\nMicrobiome Informatics (MICRBIO 8161)\nThe online materials for the workshop “Command line basics for genomic analysis at OSC” that myself and Mike Sovic gave last August:\nhttps://mcic-osu.github.io/cl-workshop-22/\nI have a course “Practical Computing Skills for Omics Data” (PLNTPTH 5006) that I am planning to teach in in Spring 2024. All materials for the 2021 version of this course (“Practical Computing Skills for Biologists”) are at: https://mcic-osu.github.io/pracs-sp21/\nhttps://mcic-osu.github.io/rnaseq-intro\n\nSome particularly useful books\n\nThe Linux Command Line (William Shotts, 2019)\nBioinformatics Data Skills (Vince Buffalo, 2015)\nComputing Skills for Biologists: A Toolbox (Wilmes & Allesino, 2019)\nA Primer for Computational Biology (Shawn T. O’ Neil, 2019) https://open.oregonstate.education/computationalbiology/"
  },
  {
    "objectID": "labs/FASTQ.html#running-fastqc",
    "href": "labs/FASTQ.html#running-fastqc",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "7 Running FastQC",
    "text": "7 Running FastQC\n\n7.1 What is FastQC?\nA useful example of a genomics tool with a CLI is FastQC, for quality control of FASTQ files. It is ubiquitous because nearly all high-throughput sequencing data comes in FASTQ files, and your first step is always to check the quality of the reads.\nFastQC produces visualizations and assessments of aspects of your reads such as adapter content, and, as shown below, mean base quality along the read:\n\n\n\n\n\n\n\n\n\n7.2 Running FastQC\nTo run FastQC, you use the command fastqc.\nCommand-line programs are typically run non-interactively, so we don’t fire up the program first, and tell it what to do as we go along. Instead, we at once issue a complete set of instructions for the program to do what we would like it to.\nIf we want to analyze one of our FASTQ files with default FastQC settings, a complete FastQC command to do so would simply be fastqc followed by the name of the file (like with, say, ls!):\nfastqc data/fastq/XX.fastq.gz\nfastqc: command not found\nHowever, there is one wrinkle, as you can see above. It turns out that a FastQC installation is already available to us at OSC 8, but we do have to load it before we can use it. We can do so as follows:\nmodule load fastqc\nNow, let’s try again:\nfastqc /fs/scratch/PAS2250/ENT6703/data/sample1.fastq.gz\n#&gt; Started analysis of sample1.fastq.gz\n#&gt; Approx 5% complete for sample1.fastq.gz\n#&gt; Approx 10% complete for sample1.fastq.gz\n#&gt; Approx 15% complete for sample1.fastq.gz\n#&gt; [truncated]\nSuccess!"
  },
  {
    "objectID": "labs/FASTQ.html#running-a-command-line-program-fastqc",
    "href": "labs/FASTQ.html#running-a-command-line-program-fastqc",
    "title": "Week 3 lab: Working with genome and HTS data",
    "section": "7 Running a command-line program: FastQC",
    "text": "7 Running a command-line program: FastQC\n\n7.1 What is FastQC?\nA useful example of a genomics tool with a CLI is FastQC, for quality control of FASTQ files. It is ubiquitous because nearly all high-throughput sequencing data comes in FASTQ files, and your first step is always to check the quality of the reads.\nFastQC produces visualizations and assessments of aspects of your reads such as adapter content, and, as shown below, mean base quality along the read:\n\n\n\n\n\n\n\n\n\n7.2 Running FastQC\nTo run FastQC, you use the command fastqc.\nCommand-line programs are typically run non-interactively, so we don’t fire up the program first, and tell it what to do as we go along. Instead, we at once issue a complete set of instructions for the program to do what we would like it to.\nIf we want to analyze one of our FASTQ files with default FastQC settings, a complete FastQC command to do so would simply be fastqc followed by the name of the file (like with, say, ls!):\nfastqc data/fastq/XX.fastq.gz\nfastqc: command not found\nHowever, there is one wrinkle, as you can see above. It turns out that a FastQC installation is already available to us at OSC 8, but we do have to load it before we can use it. We can do so as follows:\nmodule load fastqc\nNow, let’s try again:\nfastqc /fs/scratch/PAS2250/ENT6703/data/sample1.fastq.gz\n#&gt; Started analysis of sample1.fastq.gz\n#&gt; Approx 5% complete for sample1.fastq.gz\n#&gt; Approx 10% complete for sample1.fastq.gz\n#&gt; Approx 15% complete for sample1.fastq.gz\n#&gt; [truncated]\nSuccess!"
  },
  {
    "objectID": "labs/FASTQ.html#fastq-files",
    "href": "labs/FASTQ.html#fastq-files",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "6 FASTQ files",
    "text": "6 FASTQ files\n\nRecap: The FASTQ format\nFASTQ is the most common HTS read data file format, and like most genomic data files, these are plain text files. Each sequence that is read by the sequencer (i.e., each “read”) forms one FASTQ entry represented by four lines. The lines contain, respectively:\n\nA header that starts with @ and e.g. uniquely identifies the read\nThe sequence itself\nA + (plus sign)\nOne-character quality scores for each base in the sequence\n\n\n\n\n\nOne entry (read) in a FASTQ file covers 4 lines. The header line is annotated, with some of the more useful components highlighted in red. For viewing purposes, this read (at only 56 bp) is shorter than regular Illumina read lengths.\n\n\n\n\n\nGetting your own copy\nTo get you your own copy of the FASTQ files, we’ll use the Unix copy command cp as follows:\n\nOption -r will enable “recursive” (=dirs, not just files) copying\nOption -v will turn on “verbose” output: it will report what it’s copying\nThe first argument is the source directory\nThe second argument is the target directory, with . being shorthand for the current working dir\n\ncp -rv /fs/scratch/PAS2250/ENT6703/share/data .\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq’ -&gt; ‘data/fastq’\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq/Miapaca2_A178V_R1.fastq.gz’ -&gt; ‘data/fastq/Miapaca2_A178V_R1.fastq.gz’\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq/ASPC1_G31V_R2.fastq.gz’ -&gt; ‘data/fastq/ASPC1_G31V_R2.fastq.gz’\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq/ASPC1_A178V_R2.fastq.gz’ -&gt; ‘data/fastq/ASPC1_A178V_R2.fastq.gz’\nThe FASTQ files all have a .gz extension (and should listed in red in your terminal), indicating they are “gzip-compressed”. This is a common type of compression for large genomic files.\n\n\nInterlude: Viewing the metadata file\nYou can do so by finding and clicking on them in the Explorer in the side bar.\n[TBA]\n\n\nViewing the FASTQ files\nWhile we can easily open small to medium-size files in the editor pane, “visual editors” like that not work as well for very large files.\nA handy command to view text files of any size is less, which opens them up in a “pager” within your shell. That is, you will not get your prompt back until you press q to quit less, and you can e.g. scroll/move around in the file.\nTry it with one of the FASTQ files:\nless data/fastq/ASPC1_A178V_R1.fastq.gz\nBesides scrolling with your mouse, its easiest to move around with up and down arrows and, if you have them, PgUp and PgDn (also, u will move up half a page and d will move down half a page).\nIf you find yourself scrolling down and down to try and reach the end of the file, you can instead press G to go to the very end right away (and g to go back to the top).\n\n\n\n\n\n\nAvoid line-wrapping by less\n\n\n\nDepending on your zoom level and the length of reads in your FASTQ file, some lines may contain too many characters to fit on your screen. If that’s the case, less will by default “wrap” those lines onto the next line on your screen, so characters won’t run off the screen on the right-hand side. That may be useful when the file contains text you’re trying to read in full, but it is often confusing for files like FASTQ as well as for tabular files.\nTo turn off line-wrapping, call less with the -S option:\nless -S data/fastq/ASPC1_A178V_R1.fastq.gz"
  },
  {
    "objectID": "labs/FASTQ.html#interpreting-fastqcs-output",
    "href": "labs/FASTQ.html#interpreting-fastqcs-output",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "8 Interpreting FastQC’s output",
    "text": "8 Interpreting FastQC’s output"
  },
  {
    "objectID": "labs/FASTQ.html#next-steps",
    "href": "labs/FASTQ.html#next-steps",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "9 Next steps",
    "text": "9 Next steps\n\n9.1 Next steps in an RNA-seq workflow\n\n\n9.2 Next steps to run the analyses more efficiently\nI’ve shown you the main pieces of the computational infrastructure for\n“command-line genomics”. We’ve seen a very basic example of loading and running a command-line tool at OSC.\nThe missing pieces for a fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\n(This used the same language (Bash) as the commands you’d type interactively, so at its most basic this involves pasting those commands into a text file.)\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\n(At its most basic, this involves putting sbatch in front of the script name.)\nTo make use of the capabilities of the supercomputer and speeding up our analysis, we can submit multiple jobs in parallel using a loop."
  },
  {
    "objectID": "labs/FASTQ.html#to-learn-more",
    "href": "labs/FASTQ.html#to-learn-more",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "10 To learn more",
    "text": "10 To learn more\n\nOverview of computational skills for “command-line genomics”\n\nThe core skills:\n\nUnix shell basics – the commonly used commands\nSome shell scripting basics\nSLURM basics to submit and manage your batch jobs\nR for “downstream”, statistical and visualization tasks\n\nWhen you start doing genomics projects more often:\n\nUsing conda or containers for software\nUnix data tools (grep, sed, awk, etc)\n\nWhen you want to become proficient in applied bioinformatics:\n\nVersion control with git\nMore advanced: formal workflow/pipeline management tools (e.g. Nextflow)\nMore advanced: Python (or advanced R) for custom data processing\n\n\n\n\nResources for further learning\n\nOSC\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A01_osc.html\nOSC’s online asynchronous courses\nOSC’s new User Resource Guide\n\nVS Code\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A02_vscode.html\n\nUnix shell\n\nOSC’s UNIX Basics\nhttps://www.learnenough.com/command-line-tutorial\nhttps://cvw.cac.cornell.edu/Linux/\n\nOSU courses and workshops\n\nGenome Analytics course (HCS 7004)\nMicrobiome Informatics course (MICRBIO 8161)\nThe online materials for the workshop “Command line basics for genomic analysis at OSC” (Mike Sovic & Jelmer Poelstra, August 2022)\nThe online materials for the course “Practical Computing Skills for Biologists” (Jelmer Poelstra, Spring 2021)\n\nBooks\n\nA Primer for Computational Biology (Shawn T. O’ Neil, 2019) (available online!)\nComputing Skills for Biologists: A Toolbox (Wilmes & Allesino, 2019)\nBioinformatics Data Skills (Vince Buffalo, 2015)\nThe Linux Command Line (William Shotts, 2019)"
  },
  {
    "objectID": "labs/FASTQ.html#introduction-to-the-lab",
    "href": "labs/FASTQ.html#introduction-to-the-lab",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "1 Introduction to the lab",
    "text": "1 Introduction to the lab\nx"
  },
  {
    "objectID": "labs/infrastructure.html#introduction-to-the-lab",
    "href": "labs/infrastructure.html#introduction-to-the-lab",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "1 Introduction to the lab",
    "text": "1 Introduction to the lab\nIn today’s lab:\n\nWe will start with learning about a typical “computational infrastructure” to analyze high-throughput sequencing (HTS) data — this page.\nWe will then use said infrastructure to start the exploration of an HTS dataset. We’ll check out reference genome and HTS read (FASTQ) files, and perform FASTQ quality control – the next page."
  },
  {
    "objectID": "labs/infrastructure.html#computational-infrastructure-overview",
    "href": "labs/infrastructure.html#computational-infrastructure-overview",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "2 Computational infrastructure overview",
    "text": "2 Computational infrastructure overview\nDue in large part to the amount of data involved, a laptop or desktop computer is often not sufficient to work with HTS data, or with large-scale genomics and transcriptomics data more generally.\nAdditionally, most of the specialized programs that help you analyze your data can only be run through a “command-line interface”.\nTherefore, a typical computational infrastructure to do what we may call “command-line genomics” involves:\n\nA supercomputer1 — in our case, the Ohio Supercomputer Center (OSC)\nA text editor — I recommend and will demonstrate VS Code\nThe Unix shell (terminal)\nR (or perhaps Python) for interactive statistical analysis and visualization.\n\nToday, we will go through the first three of the abovementioned items: on this page, we’ll get familiar with them, and on the next page, we’ll apply what we learned to some reference genome and HTS read data.\nIn the lab next week, we will cover the fourth in the context of RNA-seq differential expression analysis.\n\n\n\n\n\n\nSide note: I don’t think I like coding. Can I avoid all of this? (Click to expand)\n\n\n\n\n\nIf you will often be doing genomics projects like the ones mentioned above, it’s hard to avoid using this (kind of) infrastructure. But here are some conditions in which you might reasonably avoid it:\n\nYou’re doing a single genomics project, your main research focus is elsewhere\nYou’re willing to outsource part of the analysis\n\nNote that for several types of HTS projects, including those involving metabarcoding or RNA-seq data (as we’ll see next week), the analysis can be said to consist of two distinct parts:\n\nThe first is compute-heavy and involves command-line programs; it is also quite standardized, and therefore suitable to be outsourced.\nThe second can be done on a laptop and only requires some R coding.\n\nYou could also try a platform like Galaxy, which has a web browser interface and doesn’t require coding — but I wouldn’t recommend this if you’re going to do multiple genomics projects.\n\n\n\n\n\n\n\n\n\nSide note: Advantages of command-line interfaces (Click to expand)\n\n\n\n\n\nAdvantages of Command-Line Interfaces (CLIs) over “Graphical User Interfaces” (GUIs) include:\n\nEfficiency — A CLI allows you to write a simple loop to run it in the same way for many samples.\n(In combination with usage of a supercomputer, you can process all those samples in parallel.)\nReproducibility — You can easily save all commands & scripts, making it straightforward to rerun/adapt an analysis."
  },
  {
    "objectID": "labs/infrastructure.html#the-ohio-supercomputer-center-osc",
    "href": "labs/infrastructure.html#the-ohio-supercomputer-center-osc",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "3 The Ohio Supercomputer Center (OSC)",
    "text": "3 The Ohio Supercomputer Center (OSC)\n\n3.1 Introduction to supercomputers\n\nWhat is a supercomputer?\nA supercomputer is a highly interconnected set of many computer processors and storage units. You can think of it simply as a network of computers — with individual computers called “nodes”.\nSupercomputers are also commonly referred to as High-Performance Computing (HPC) clusters or simply compute clusters. This is what Owens, one of the OSC supercomputers, physically looks like:\n\n\n\n\n\nWhy do I need a supercomputer?\n\nOften, your genomics dataset is too large to be handled efficiently, or at all, by a laptop/desktop computer.\nTo speed up long-running analyses by using more computing power, and repeated analyses (like the independent alignment of reads for different samples) by running them in parallel.\nIt’s also a great place to store large amounts of data — and genomics data is often very large.\n\n\n\n\n\n3.2 Introduction to OSC\n\n\n\nThe Ohio Supercomputer Center (OSC) provides computing resources to researchers (and others) across Ohio. OSC has two supercomputers/clusters (named Owens and Pitzer), and lots of infrastructure for their usage.\nResearch usage is charged at subsidized rates, and in most case, these costs are absorbed at the college level (!).\n\nThe structure of an OSC supercomputer\nWe can think of a supercomputer as having three main parts:\n\nFile Systems: Where files are stored (these are shared between the two OSC clusters)\nLogin Nodes: The handful of computers everyone shares after logging in\nCompute Nodes: The many computers you can reserve to run your analyses\n\n\n\n\n\n\n\n\n\n\nSide note: What is different on a supercomputer like at OSC? (Click to expand)\n\n\n\n\n\nCompared to command-line computing on a laptop or desktop, the following aspects are different when working on a supercomputer like at OSC:\n\nLogin versus compute nodes\n“Login nodes”, the nodes you end up on after logging in, are not meant for heavy computing and you have to request access to “compute nodes” to run most analyses.\n“Non-interactive” computing is common\nIt is common to write and “submit” scripts to a queue instead of running programs interactively.\nSoftware\nYou generally can’t install “the regular way”, and a lot of installed software needs to be “loaded” (as we’ll see today).\nOperating system\nSupercomputers run on the Linux operating system\n\n\n\n\n\n\n\n\n3.3 The OSC OnDemand web portal\nThe OSC OnDemand web portal allows you to use a web browser to access OSC resources such as:\n\nA file browser where you can also create and rename folders and files, etc.\nA Unix shell\nA host of “Interactive Apps”: programs such as RStudio, Jupyter, VS Code and QGIS.\n\n Go to https://ondemand.osc.edu and log in with your OSC (not OSU!) credentials.\nYou should see a landing page similar to the one below:\n\n\n\nWe will now go through some of the dropdown menus in the blue bar along the top.\n\nFiles: File system access\nLet’s start with Files. Hovering over this dropdown menu gives a list of directories you have access to. If your account is brand new, you should only have three 2:\n\nA Home directory (starts with /users/)\nA “project” directory (starts with /fs/ess/) for PAS2250 — permanent, backed-up storage\nA “scratch” directory (starts with /fs/scratch/) PAS2250 — temporary storage\n\nSelect the PAS2250 scratch directory, /fs/scratch/PAS2250, where we’ll be working:\n\n\n\nOnce there, you should see a list of directories and files (here: just a single dir), and you can click on the directories to explore the contents further:\n\n\n\nThis interface is much like the file browser on your own computer, so you can also create, delete, move and copy files and folders, and even upload (from your computer to OSC) and download (from OSC your computer) files3 — see the buttons across the top.\n\n\n Your Turn: Create your own folder (click to see instructions)\n\n\nClick your way into ENT6703 within /fs/scratch/PAS2250 if you’re not already there.\nYou should (at least) see directories/folders named share and jelmer.\nCreate your own folder by clicking the New Directory button at the top.\nPlease give it the exact same name as your OSC username (including any capitalization).\n\n(You can see what your username is by looking at the right side of the blue top bar:)\n\n\n\n\n\n\nClusters: Unix shell access\nInteracting with a supercomputer is most commonly done using a Unix shell, and we’ll learn about the basics of doing so soon. Under the Clusters dropdown menu, you can access a Unix shell either on Owens or Pitzer:\n\n\n\nI’m selecting a shell on the Pitzer supercomputer, which will open a new browser tab looking like this:\n\n\n\nHowever, from now on, we’ll be accessing a Unix shell inside the VS Code text editor, which also gives us some additional functionality in a user-friendly way.\n\n\nInteractive Apps\nWe can access programs with Graphical User Interfaces (GUIs; point-and-click interfaces) via the Interactive Apps dropdown menu — let’s select VS Code using the “Code Server” button:"
  },
  {
    "objectID": "labs/infrastructure.html#the-vs-code-text-editor",
    "href": "labs/infrastructure.html#the-vs-code-text-editor",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "4 The VS Code text editor",
    "text": "4 The VS Code text editor\n\n4.1 What is VS Code?\nVS Code (in full, Visual Studio Code) is basically a fancy text editor.\nTo emphasize the additional functionality relative to basic text editors like Notepad and TextEdit, editors like VS Code are also referred to as “IDEs”: Integrated Development Environments. The RStudio program is another good example of an IDE. For our purposes:\n\nVS code will be our IDE for Unix shell code (this week)\nRStudio will be our IDE for R (in the differential expression lab next week)\n\n\n\n\n4.2 Connecting to VS Code\nBecause “Interactive Apps” like VS Code and RStudio run on compute nodes, and compute nodes need to be “reserved”, we need to fill out a form and specify the following details:\n\nThe OSC Project that should be billed for the compute resource usage: PAS2250\nThe amount of time in hours we want to make a reservation for 4: 4\nThe “working directory”5 for the program: your newly-created folder in /fs/scratch/PAS2250/ENT6703\nThe version of VS Code: 4.8\n\n\n\n\nClick on Launch at the bottom, which will send your request to the “compute job” scheduler. First, your job will be “Queued” — that is, waiting for the job scheduler to allocate resources on the compute nodes to it:\n\n\n\nYour job is typically granted resources within a few seconds (the card will then say “Starting”), and be ready for usage (“Running”) in another couple of seconds:\n\n\n\nThen, click on the blue Connect to VS Code button to open VS Code in a new browser tab. When VS Code opens, you may get these two pop-ups — click “Yes” (and check the box) and “Don’t Show Again”, respectively:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 The VS Code User Interface\n\n\n\n\nSide bars\nThe Activity Bar (narrow side bar) on the far left has:\n\nA      (“hamburger menu”), which has menu items like File that you often find in a top bar.\nA      (cog wheel icon) in the bottom, through which you can mainly access settings.\nIcons to toggle (wide) Side Bar options — but we’ll only use the default selection, the Explorer (file browser)\n\n\n\nEditor pane and Welcome document\nThe main part of the VS Code is the editor pane. Here, we can open files like text files including scripts, and images. (Whenever you open VS Code, an editor tab with a Welcome document is automatically opened. This provides some help and some shortcuts like to recently opened files and folders.)\n\n\nTerminal (with a Unix shell)\n Open a terminal by clicking      =&gt; Terminal =&gt; New Terminal.\n\n\n\n Your Turn: Try a few color themes (click to see instructions)\n\n\nAccess the “Color Themes” option by clicking    =&gt; Color Theme.\nTry out a few themes and see what you like!"
  },
  {
    "objectID": "labs/infrastructure.html#the-unix-shell",
    "href": "labs/infrastructure.html#the-unix-shell",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "5 The Unix shell",
    "text": "5 The Unix shell\n\n5.1 What is the Unix shell?\nA computer’s shell is the interface, inside a Terminal window, that allows you to interact with your computer by typing commands. It is also referred to as the the “command line” — with “command-line tools/programs” being software that is run using shell commands.\nThe Unix shell is the shell of Unix-based operating systems, which include Mac and Linux (but not Windows).\n\n\n\n\n\n\nMany bioinformatics programs are basically specialized commands\n\n\n\nWe’ll now learn a couple of Unix shell commands, to familiarize yourself with working in this environment.\nThis is also useful because in many ways, you can think of using a command-line bioinformatics program as using just another command. Therefore, our skills with Unix commands will extend to using command-line bioinformatics tools!\n\n\n\n\n\n5.2 First steps in the Unix shell\n\nThe prompt\nInside your terminal, the “prompt” indicates that the shell is ready for a command. Our prompt at OSC should show the following pieces of information like so:\n[&lt;username&gt;@&lt;node-name&gt; &lt;working-dir&gt;]$\nFor example:\n[jelmer@p0080 jelmer]$ \nWe type our commands after the dollar sign $, and then press Enter to execute the command. When the command has finished executing, we’ll get our prompt back and can type a new command.\n\n\n\n\n\n\nHow shell code is shown on this website\n\n\n\n\nThe gray boxes like the ones shown above will be used to show the command line expressions that you should type.\nIn upcoming boxes, the prompt itself ([...]$) will not be shown, but only the command line expressions that you type. This is to save space and to allow you for copy-and-pasting (but I recommend typing!).\nPaler gray boxes (below the boxes with command have & with italic text) show the output of commands.\n\n\n\n\n\nA few simple commands: date, whoami, pwd\nThe Unix shell comes with hundreds of commands. Let’s start with a few simple ones.\n\nThe date command prints the current date and time:\n\ndate\nFri Jan 26 14:31:51 EST 2024\n\nThe whoami (who-am-i) command prints your username:\n\nwhoami\njelmer\n\nThe pwd (Print Working Directory) command prints the path to the directory you are currently located in:\n\npwd\n/fs/ess/PAS2250/ENT6703/jelmer\nAll 3 of those commands provided us with some output. That output was printed to screen, which is the default behavior for nearly every Unix command.\n\n\n\n\n\n\nWorking directory and paths\n\n\n\n\nWhen working in a Unix shell, you are always “in” a specific directory and this is called your working directory.\nIn a path (= location of a file or directory) such as that output by pwd, directories are separated by forward slashes /. (With any leading forward slash indicating the computer’s root directory.)\n\n\n\n\n\n\n\n\n\nGeneral shell tips\n\n\n\n\nEverything in the shell is case-sensitive, including commands and file names.\nAvoid spaces in file and dir names! Use e.g. underscores or capitalization to distinguish words.\nAnything after a # is considered a comment and will be ignored by the shell.\n\n\n\n\n\n\n\n5.3 cd and command actions and arguments\nIn the above three command line expressions:\n\nWe merely typed a command and nothing else\nThe command provided some information, which was printed to screen\n\nBut many commands perform an action other than providing information. For example, you can use the command cd to Change Directory (i.e. change your working dir). And like many commands that perform and action, it normally has no output at all.\nLet’s use cd to move to another directory by specifying the path to that directory after the cd command:\ncd /fs/ess/PAS2250/ENT6703/share\npwd\n/fs/ess/PAS2250/ENT6703/share\n\n\n\n\n\n\nI will demonstrate “tab completion”!\n\n\n\n\n\n\nIn more abstract terms, what we did above was to provide cd with an argument, namely the path of the dir to move to. Arguments generally tell commands what file or directory to operate on.\nAs we’ve seen, then, cd gives no output when it succesfully changed the working directory. But let’s also see what happens when it does not succeed — it gives an error:\ncd /fs/Ess/PAS2250\nbash: cd: /fs/Ess/PAS2250: No such file or directory\n\n\nYour Turn: What was the problem with the path we specified? (Click to see the answer)\n\nWe used a capital E in /Ess/ — this should have been /ess/.\nAs pointed out above, paths (dir and file specifications) are case-sensitive on Unix systems!\n\n\n\n\n5.4 ls and command options\n\nThe default behavior of ls\nThe ls command, short for “list”, will list files and directories:\nls\ndata  README.md\n(You should still be in /fs/ess/PAS2250/ENT6703/share. If not, cd there first.)\n\n\n\n\n\n\nSide note: ls output colors (click to expand)\n\n\n\n\n\nUnfortunately, the ls output shown above does not show the different colors you should see in your shell — here are some of the most common ones:\n\nEntries in blue are directories (like data and metadata above)\nEntries in black are regular files (like README.md above)\nEntries in red are compressed files (we’ll see an example soon).\n\n\n\n\nThis default way that ls shows the output can be changed by providing ls with options.\n\n\nOptions (to ls)\nIn general, whereas arguments tell a command what to operate on, options will modify its behavior. For example, we can call ls with the option -l (a dash followed by a lowercase L):\nls -l \ntotal 17\ndrwxr-xr-x 5 jelmer PAS0471 4096 Jan 21 12:39 data\n-rw-r--r-- 1 jelmer PAS0471 1502 Jan 22 11:04 README.md\nNotice that it lists the same items as our first ls call above, but printed in a different format: one item per line, with additional information included, such as the date and time each file was last modified, and the file sizes in bytes (to the left of the date).\nLet’s add another option, -h:\nls -l -h\ntotal 17K\ndrwxr-xr-x 5 jelmer PAS0471 4.0K Jan 21 12:39 data\n-rw-r--r-- 1 jelmer PAS0471 1.5K Jan 22 11:04 README.md\n\n\nYour Turn: What is different about the output, and what do you think that means? (Click to see the answer)\n\nThe only difference is in the format of the column reporting the sizes of the items listed.\nWe now have “Human-readable filesizes” (hence -h), where sizes on the scale of kilobytes will be shown with Ks, of megabytes with Ms, and of gigabytes with Gs. That can be really useful especially for very large files.\n\nConveniently, options can be pasted together as follows:\nls -lh\n\n\nCombining options and arguments\nArguments to ls should be dirs or files to operate on. For example, if we wanted to see what’s inside the data dir, instead of inside our working dir, we could type:\nls data\nfastq\nWell, that’s not much information, just another dir — so let’s look inside that:\nls data/fastq\nERR10802863_R1.fastq.gz  ERR10802865_R2.fastq.gz  ERR10802868_R1.fastq.gz  ERR10802870_R2.fastq.gz  ERR10802875_R1.fastq.gz  ERR10802877_R2.fastq.gz  ERR10802880_R1.fastq.gz  ERR10802882_R2.fastq.gz  ERR10802885_R1.fastq.gz\nERR10802863_R2.fastq.gz  ERR10802866_R1.fastq.gz  ERR10802868_R2.fastq.gz  ERR10802871_R1.fastq.gz  ERR10802875_R2.fastq.gz  ERR10802878_R1.fastq.gz  ERR10802880_R2.fastq.gz  ERR10802883_R1.fastq.gz  ERR10802885_R2.fastq.gz\nERR10802864_R1.fastq.gz  ERR10802866_R2.fastq.gz  ERR10802869_R1.fastq.gz  ERR10802871_R2.fastq.gz  ERR10802876_R1.fastq.gz  ERR10802878_R2.fastq.gz  ERR10802881_R1.fastq.gz  ERR10802883_R2.fastq.gz  ERR10802886_R1.fastq.gz\nERR10802864_R2.fastq.gz  ERR10802867_R1.fastq.gz  ERR10802869_R2.fastq.gz  ERR10802874_R1.fastq.gz  ERR10802876_R2.fastq.gz  ERR10802879_R1.fastq.gz  ERR10802881_R2.fastq.gz  ERR10802884_R1.fastq.gz  ERR10802886_R2.fastq.gz\nERR10802865_R1.fastq.gz  ERR10802867_R2.fastq.gz  ERR10802870_R1.fastq.gz  ERR10802874_R2.fastq.gz  ERR10802877_R1.fastq.gz  ERR10802879_R2.fastq.gz  ERR10802882_R1.fastq.gz  ERR10802884_R2.fastq.gz\nAh, FASTQ files! These contain our sequence data, and we’ll go and explore them in a bit.\nFinally, we can combine options and arguments, and let’s do so take a closer look at our dir with FASTQ files — now the -h option is especially useful to see that the files are 21-22 Mb in size:\nls -lh data/fastq\ntotal 941M\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:34 ERR10802863_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802863_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:34 ERR10802864_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802864_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802865_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802865_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:34 ERR10802866_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802866_R2.fastq.gz\n[...output truncated...]\n\n\n Your Turn: List the files in the data/ref dir. What are the file sizes? (Click for the solution)\n\n\n\n\n\n\n5.5 More general shell tips\n\nCommand history: If you hit the ⇧ (up arrow) once, you’ll retrieve your most recent command, and if you keep hitting it, you’ll go further back. The⇩ (down arrow) will go the other way: towards the present.\nYour cursor can be anywhere on a line (not just at the end) when you press Enter to execute a command!\nIf your prompt is missing, the shell is either still busy executing your command, or you typed an incomplete command. To abort in either of these two scenarios, press Ctrl+C and you’ll get your prompt back.\nAnything that comes after a # is considered a comment instead of code!\n\n# This entire line is a comment\npwd # 'pwd' will be executed but everything after the '#' is ignored\n/fs/ess/PAS2250/ENT6703/jelmer\n\n\n\n Your Turn: Move into your personal directory, and then back into the share dir (Click for the solution)\n\ncd /fs/ess/PAS2250/ENT6703/jelmer\ncd /fs/ess/PAS2250/ENT6703/share\n\n\n\n Your Turn: Use the command history (up arrows) to repeat the previous exercise.\n\n\n\n\n\n Your Turn (Bonus): Two periods .. means the directory “one level up” (towards the computer’s root dir), so cd .. will move you one dir level up. Try to make use of this move into your personal dir and back to the share again. (Click for the solution)\n\ncd ../jelmer\ncd ../share\n\n\n\n Your Turn (Bonus): Practice aborting commands (Click for the instructions)\n\nTo simulate a long-running command that we may want to abort, we can use the sleep command, which will make the computer wait for a specified amount of time until giving your prompt back:\nsleep 60s\nRun that command and instead of waiting for the full 60 seconds, press Ctrl + C to get your prompt back sooner!\nOr, an example of an incomplete command (an opening parenthesis ():\n(\nRun the code above, see what happens, and press Ctrl + C to get your prompt back."
  },
  {
    "objectID": "labs/infrastructure.html#appendix-further-learning",
    "href": "labs/infrastructure.html#appendix-further-learning",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "6 Appendix: Further learning",
    "text": "6 Appendix: Further learning\n\nResources for further learning\n\nOSC\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A01_osc.html\nOSC’s online asynchronous courses\nOSC’s new User Resource Guide\n\nVS Code\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A02_vscode.html\n\nUnix shell\n\nOSC’s UNIX Basics\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A03_shell1.html\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A04_shell2.html\nhttps://www.learnenough.com/command-line-tutorial\nhttps://cvw.cac.cornell.edu/Linux/\n\nOSU courses\n\nGenome Analytics course (HCS 7004)\nMicrobiome Informatics course (MICRBIO 8161)\nComputing Skills for Omics Data (PLNTPTH 5006, taught as IS in SP24 2nd session as PLNTPTH 6193)\n\nOnline workshop/course material\n\nWorkshop “Command line basics for genomic analysis at OSC” (Mike Sovic & Jelmer Poelstra, 2022)\nCourse “Practical Computing Skills for Biologists” (Jelmer Poelstra, 2021)\n\nBooks\n\nA Primer for Computational Biology (Shawn T. O’ Neil, 2019) (available online!)\nComputing Skills for Biologists: A Toolbox (Wilmes & Allesino, 2019)\nBioinformatics Data Skills (Vince Buffalo, 2015)\nThe Linux Command Line (William Shotts, 2019)"
  },
  {
    "objectID": "labs/infrastructure.html#footnotes",
    "href": "labs/infrastructure.html#footnotes",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCloud computing is an alternative, but won’t be covered here.↩︎\nYou can be associated with multiple PAS projects and for each one, a scratch and a project directory is added↩︎\nThough this is not meant for large (&gt;1 GB) transfers. Different methods are available for those but are outside the scope of this introductions.↩︎\nNote that we’ll be kicked off as soon as that amount of time has passed!↩︎\nThis is the starting location in the file system↩︎"
  },
  {
    "objectID": "labs/data.html",
    "href": "labs/data.html",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "",
    "text": "FASTQ is the most common HTS read data file format, and like most genomic data files, these are plain text files. Each sequence that is read by the sequencer (i.e., each “read”) forms one FASTQ entry represented by four lines. The lines contain, respectively:\n\nA header that starts with @ and e.g. uniquely identifies the read\nThe sequence itself\nA + (plus sign)\nOne-character quality scores for each base in the sequence\n\n\n\n\n\nOne entry (read) in a FASTQ file covers 4 lines. The header line is annotated, with some of the more useful components highlighted in red. For viewing purposes, this read (at only 56 bp) is shorter than regular Illumina read lengths.\n\n\n\n\n\n\nTo get you your own copy of the FASTQ files, we’ll use the Unix copy command cp as follows:\n\nOption -r will enable “recursive” (=dirs, not just files) copying\nOption -v will turn on “verbose” output: it will report what it’s copying\nThe first argument is the source directory\nThe second argument is the target directory, with . being shorthand for the current working dir\n\ncp -rv /fs/scratch/PAS2250/ENT6703/share/data .\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq’ -&gt; ‘data/fastq’\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq/Miapaca2_A178V_R1.fastq.gz’ -&gt; ‘data/fastq/Miapaca2_A178V_R1.fastq.gz’\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq/ASPC1_G31V_R2.fastq.gz’ -&gt; ‘data/fastq/ASPC1_G31V_R2.fastq.gz’\n‘/fs/ess/PAS2250/ENT6703/demo/202307_rnaseq/data/fastq/ASPC1_A178V_R2.fastq.gz’ -&gt; ‘data/fastq/ASPC1_A178V_R2.fastq.gz’\nThe FASTQ files all have a .gz extension (and should listed in red in your terminal), indicating they are “gzip-compressed”. This is a common type of compression for large genomic files.\n\n\n\nYou can do so by finding and clicking on them in the Explorer in the side bar.\n[TBA]\n\n\n\nWhile we can easily open small to medium-size files in the editor pane, “visual editors” like that not work as well for very large files.\nA handy command to view text files of any size is less, which opens them up in a “pager” within your shell. That is, you will not get your prompt back until you press q to quit less, and you can e.g. scroll/move around in the file.\nTry it with one of the FASTQ files:\nless data/fastq/ASPC1_A178V_R1.fastq.gz\nBesides scrolling with your mouse, its easiest to move around with up and down arrows and, if you have them, PgUp and PgDn (also, u will move up half a page and d will move down half a page).\nIf you find yourself scrolling down and down to try and reach the end of the file, you can instead press G to go to the very end right away (and g to go back to the top).\n\n\n\n\n\n\nAvoid line-wrapping by less\n\n\n\nDepending on your zoom level and the length of reads in your FASTQ file, some lines may contain too many characters to fit on your screen. If that’s the case, less will by default “wrap” those lines onto the next line on your screen, so characters won’t run off the screen on the right-hand side. That may be useful when the file contains text you’re trying to read in full, but it is often confusing for files like FASTQ as well as for tabular files.\nTo turn off line-wrapping, call less with the -S option:\nless -S data/fastq/ASPC1_A178V_R1.fastq.gz"
  },
  {
    "objectID": "labs/data.html#fastq-files",
    "href": "labs/data.html#fastq-files",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "3 FASTQ files",
    "text": "3 FASTQ files\n\n3.1 The FASTQ format\nFASTQ is the standard HTS read data file format. Like the other genomic data files we’ve seen so far, these are plain text files. Each read forms one FASTQ entry and is represented by four lines:\n\nA header that starts with @ and e.g. uniquely identifies the read\nThe sequence itself\nA + (plus sign — yes, that’s all!)\nOne-character quality scores for each base in the sequence\n\n\n\n\n\nOne entry (read) in a FASTQ file covers 4 lines. The header line is annotated, with some of the more useful components highlighted in red. For viewing purposes, this read (at only 56 bp) is shorter than what is typical.\n\n\n\n\n\n\n\n\n\nSide note: FASTQ quality scores (Click to expand)\n\n\n\n\n\nThe quality scores we saw in the read above represent an estimate of the error probability of the base call.\nSpecifically, they correspond to a numeric “Phred” quality score (Q), which is a function of the estimated probability that a base call is erroneous (P):\n\nQ = -10 * log10(P)\n\nFor some specific probabilities and their rough qualitative interpretation for Illumina data:\n\n\n\nPhred quality score\nError probability\nRough interpretation\n\n\n\n\n10\n1 in 10\nterrible\n\n\n20\n1 in 100\nbad\n\n\n30\n1 in 1,000\ngood\n\n\n40\n1 in 10,000\nexcellent\n\n\n\nThis numeric quality score is represented in FASTQ files not by the number itself, but by a corresponding “ASCII character”. This allows for a single-character representation of each possible score — as a consequence, each quality score character can conveniently correspond to (& line up with) a base character in the read.\n\n\n\nPhred quality score\nError probability\nASCII character\n\n\n\n\n10\n1 in 10\n+\n\n\n20\n1 in 100\n5\n\n\n30\n1 in 1,000\n?\n\n\n40\n1 in 10,000\nI\n\n\n\nIn practice, you almost never have to manually check the quality scores of bases in FASTQ files, but if you do, a rule of thumb is that letter characters are good (Phred of 32 and up).\n\n\n\n\n\n\n3.2 Listing your FASTQ files\nFirst, let’s take another look at your list of FASTQ files:\nls -lh data/fastq\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:36 ERR10802863_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802863_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:36 ERR10802864_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802864_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802865_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802865_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:36 ERR10802866_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802866_R2.fastq.gz\n[...truncated...]\nIn the file listing above:\n\nFirst, take note of the file sizes. They are “only” about 22 Mb in size, and all have a very similar size. This is because I “subsampled” the FASTQ files to only have 500,000 reads per file. The original files were on average over 1 Gb in size with about 30 million reads (but quite a lot of variation in number of reads, as is normal).\nSecond, if you look closely at the file names, it looks like we have two FASTQ files per sample: one with _R1 at the end of the file name, and one with _R2.\n\n\n\nYour Turn: Can you think of what each of the two files represents/contains? (Click for the solution)\n\nThese contain the forward reads (_R1.fastq.gz) vs. the reverse reads (_R2.fastq.gz).\n\n\n\nYour Turn: Do you have any idea why the file extension ends in .gz? (Click for the solution)\n\nThis means it is gzip-compressed. This saves a lot of space: compressed files can be up to 10 times smaller than uncompressed files. Most bioinformatics tools, including FastQC which we’ll run in a bit, can work with gzipped files directly, so there is no need to unzip them.\n\n\n\n\n3.3 Viewing your FASTQ files\nDespite the gzip-compression, we can simply use the less command as before to view the FASTQ files (!):\nless -S data/fastq/ERR10802863_R1.fastq.gz\n@ERR10802863.8435456 8435456 length=74\nCAACGAATACATCATGTTTGCGAAACTACTCCTCCTCGCCTTGGTGGGGATCAGTACTGCGTACCAGTATGAGT\n+\nAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n@ERR10802863.27637245 27637245 length=74\nGCCACACTTTTGAAGAACAGCGTCATTGTTCTTAATTTTGTCGGCAACGCCTGCACGAGCCTTCCACGTAAGTT\n+\nAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE&lt;EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n\n\n\n\n\n\nDifferent header lines\n\n\n\nNote that the header lines (those starting with @) are quite different from the example shown above. This is because these files were downloaded from SRA. When you get files directly from a (Illumina) sequencer, they will have headers much like the earlier example.\n\n\nIn practice, we don’t often have to closely look at the contents of our FASTQ files ourselves. There are simply too many reads to make sense of!\nInstead, we’ll have specialized tools like FastQC summarize them for us: e.g. how many sequences there are, what the quality scores look like, and if there are adapter sequences. We’ll run FastQC below."
  },
  {
    "objectID": "labs/data.html#running-fastqc",
    "href": "labs/data.html#running-fastqc",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "4 Running FastQC",
    "text": "4 Running FastQC\n\n4.1 What is FastQC?\nA useful example of a genomics tool with a CLI is FastQC, for quality control of FASTQ files. It is ubiquitous because nearly all high-throughput sequencing data comes in FASTQ files, and your first step is always to check the quality of the reads.\nFastQC produces visualizations and assessments of aspects of your reads such as adapter content, and, as shown below, mean base quality along the read:\n\n\n\n\n\n\n\n\n\n4.2 Running FastQC\nTo run FastQC, you use the command fastqc.\nCommand-line programs are typically run non-interactively, so we don’t fire up the program first, and tell it what to do as we go along. Instead, we at once issue a complete set of instructions for the program to do what we would like it to.\nIf we want to analyze one of our FASTQ files with default FastQC settings, a complete FastQC command to do so would simply be fastqc followed by the name of the file (like with, say, ls!):\nfastqc data/fastq/XX.fastq.gz\nfastqc: command not found\nHowever, there is one wrinkle, as you can see above. It turns out that a FastQC installation is already available to us at OSC 2, but we do have to load it before we can use it. We can do so as follows:\nmodule load fastqc\nNow, let’s try again:\nfastqc /fs/scratch/PAS2250/ENT6703/data/sample1.fastq.gz\n#&gt; Started analysis of sample1.fastq.gz\n#&gt; Approx 5% complete for sample1.fastq.gz\n#&gt; Approx 10% complete for sample1.fastq.gz\n#&gt; Approx 15% complete for sample1.fastq.gz\n#&gt; [truncated]\nSuccess!"
  },
  {
    "objectID": "labs/data.html#interpreting-fastqcs-output",
    "href": "labs/data.html#interpreting-fastqcs-output",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "5 Interpreting FastQC’s output",
    "text": "5 Interpreting FastQC’s output\n\n\n\n\n\n\n\nRunning the analysis at scale\n\n\n\nI’ve shown you the main pieces of the computational infrastructure for “command-line genomics”. We’ve seen a very basic example of loading and running a command-line tool at OSC.\nThe missing pieces for a fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\n(This used the same language (Bash) as the commands you’d type interactively, so at its most basic this involves pasting those commands into a text file.)\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\n(At its most basic, this involves putting sbatch in front of the script name.)\nTo make use of the capabilities of the supercomputer and speeding up our analysis, we can submit multiple jobs in parallel using a loop."
  },
  {
    "objectID": "labs/data.html#next-steps",
    "href": "labs/data.html#next-steps",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "6 Next steps",
    "text": "6 Next steps\n\n6.1 Next steps in an RNA-seq workflow\n\n\n6.2 Next steps to run the analyses more efficiently\nI’ve shown you the main pieces of the computational infrastructure for\n“command-line genomics”. We’ve seen a very basic example of loading and running a command-line tool at OSC.\nThe missing pieces for a fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\n(This used the same language (Bash) as the commands you’d type interactively, so at its most basic this involves pasting those commands into a text file.)\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\n(At its most basic, this involves putting sbatch in front of the script name.)\nTo make use of the capabilities of the supercomputer and speeding up our analysis, we can submit multiple jobs in parallel using a loop."
  },
  {
    "objectID": "labs/data.html#footnotes",
    "href": "labs/data.html#footnotes",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut see the box below for more info/context↩︎\n Just like with, say, the ls command!↩︎\nFor a full list of installed software at OSC: https://www.osc.edu/resources/available_software/software_list↩︎\nThe installed version of VS Code does not allow us to view HTML files↩︎"
  },
  {
    "objectID": "labs/data.html#reference-genome-files",
    "href": "labs/data.html#reference-genome-files",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "2 Reference genome files",
    "text": "2 Reference genome files\nWe’ll cover the two main types of reference genome files you need in a HTS project like reference-based RNA-seq:\n\nFASTA files: Files with just sequences and their IDs. Your reference genome assembly will be in this format.\nGTF (& GFF) files: These contain annotations in a tabular format, e.g. the start & stop position of each gene.\n\n\n2.1 Finding your reference genome\nImagine that you are one of the researchers involved in the Culex study, or alternatively, that you are still you, but you just want to redo their analysis.\nYou’ll want to see if there’s a Cx. pipiens reference genome available, and if so, download the relevant files. The authors state the following in the paper (section 2.3, “Data analysis”):\n\nBecause the reference genome and annotations of Cx. pipiens are not published yet, we used the reference genome and annotations of phylogenetically closest species that were available in Ensembl, Cx. quinquefasciatus.\n\nBut perhaps that genome of Cx. pipiens has been published in the meantime?\nGenerally, the first place to look reference genome data is at NCBI, https://ncbi.nlm.nih.gov/, where you can start by simply typing the name of your organism in the search box at the home page, like so — by means of example, let’s first search for the hoverfly Episyrphus balteatus:\n\n\n\n\n\nFor this species, we get the following “card” at the top of the results:\n\n\n\n\n\nIf you next click on “Genomes” in the result page above, you should get the following:\n\n\n\n\n\nSo, NCBI has 3 genomes assemblies for Episyrphus balteatus. The top one has a green check mark next to it (which means that this genome has been designated the primary reference genome for the focal organism), and it is also the only genome with an entry in the Annotation column and with a “Chromosome” (vs. “Scaffold”) assembly Level. Therefore, that top assembly, idEpiBalt1.1, would be the one to go with.\nYou can click on each assembly to get more information, including statistics like the number of scaffolds.\n\n\n Your Turn: Now let’s switch to Culex. How many Culex assemblies are on NCBI (do a genus-wide search)? Are there any for Culex pipiens, and if so, which would you pick? (Click for the answer)\n\nGo through the same process as shown above for Episyrphus balteatus, instead entering “Culex” in the search box.\nYou should find that there are 5 Culex assemblies, 2 of which are Culex pipiens. The first one, TS_CPP_V2, has the reference checkmark next to it and has an entry in the Annotation column, which the second one (TS_CPM_V1) doesn’t:\n\n\n\n\n\n(These two are also from different subspecies, but as far as I could see, the authors of our study don’t specify the focal subspecies – though you could probably figure that out based on geographic range.)\n\nAs shown in the solutions above, there is currently a reference genome for Cx. pipiens available1, and we’ll be “using” (looking at) that one. I have downloaded its files for you, which were among the files you just copied.\n\n\n Your Turn: Take a closer look at our focal genome on the NCBI website. What is the size of the genome assembly? How many chromosomes and scaffolds does it contain? And how many protein-coding genes? (Click for the solutions)\n\nOn the genome’s page at NCBI, some of the information includes the following stats on the assembly and the annotation:\n\n\n\n\n\n\n\n\n\n\nSo:\n\nIt is 566.3 Mb (Megabases)\nIt contains 3 chromosomes and 289 scaffolds\nIt has 16,297 protein-coding genes\n\n\n\n\n\n\n\n\nSide note: Downloading the reference genome files (Click to expand)\n\n\n\n\n\nTo download the reference genome files fom the NCBI website, you can either select an assembly in the overview table and click the Download button, or click the Download button at the top of the page for a specific assembly. That should get you the following pop-up window:\n\n\n\n\n\nYou’ll want to select at least the “Genome sequences (FASTA)” and one or both of the “Annotation features” files (GTF is often preferred with RNA-seq).\nThis allows you to download the data to your computer, and you could then upload it OSC. (Though a faster and more reproducible solution would be to use a command to directly download these — the datasets and curl buttons next to the Download one a genome’s page help with that.)\nFinally, if a “RefSeq” assembly is available, like it is for this genome, you’ll want to select that, as it has been curated and standardized by NCBI (whereas “GenBank” entries are exactly as submitted by researchers). This mostly makes a different for the annotation rather than the assembly itself.\n\n\n\n\n\n\n\n\n\nSide note: Reference genome complications (Click to expand)\n\n\n\n\n\nOther useful database for reference genomes are Ensembl and the specialized databases that exist for certain organisms, like FlyBase for Drosophila, VectorBase mostly for mosquitos, and JGI Phytozome for plants.\nIn many cases, these databases don’t contain the exact same reference genome files than NCBI. Often, at least the annotation is different (and actually the product of an independent annotation effort), but even the assembly may have small differences including in chromosome/scaffold names, which can make these files completely incompatible. And to make matters even more complicated, it is not always clear which database is the best source for your genome.\n\nInterestingly, the paper with the Cx. pipiens reference genome that we just found was already published in 2021, well before our focal paper.\nAnd when we take a closer look at the quote from the paper, they say no genome for Cx. pipiens is “available in Ensembl” — which is in fact still the case. Could it be that the authors preferred the Ensembl genome from Cx. quinquefasciatus over the NCBI genome of Cx. pipiens? Or perhaps they did their analyses years ago?\n\n\n\n\n\n\n2.2 Reference genome files I: FASTA\n\nThe FASTA format\nFASTA files contain one or more DNA or amino acid sequences, with no limits on the number of sequences or the sequence lengths. FASTA is the standard format for, e.g.:\n\nGenome assembly sequences\nTranscriptomes and proteomes (all of an organism’s transcripts & amino acid sequences, respectively)\nSequence downloads from NCBI such as a single gene/protein or other GenBank entry\n\nThe following example FASTA file contains two entries:\n&gt;unique_sequence_ID Optional description\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAAAA\n&gt;unique_sequence_ID2\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAATG\nEach entry contains a header and the sequence itself, and:\n\nHeader lines start with a &gt; and are otherwise “free form” but should provide an identifier for the sequence\nA single sequence entry is often not on a single line, but spread across multiple lines with a fixed width\n\n\n\n\n\n\n\nFASTA file name extensions are variable\n\n\n\n\n“Generic” extensions are .fasta and .fa (e.g: culex_assembly.fasta)\nAlso used are extensions that explicitly indicate whether sequences are nucleotides (.fna) or amino acids (.faa)\n\n\n\n\n\nYour Culex genome assembly FASTA\nYour reference genome files are in data/ref:\nls -lh data/ref\n-rw------- 1 jelmer PAS0471 547M Jan 22 12:34 GCF_016801865.2.fna\n-rw------- 1 jelmer PAS0471 123M Jan 22 12:34 GCF_016801865.2.gtf\nWhile we can easily open small to medium-size files in the editor pane, “visual editors” like that do not work well for larger files like these.\nA handy command to view text files of any size is less, which opens them up in a “pager” within your shell – you’ll see what that means if you try it with one of the assembly FASTA file:\nless data/ref/GCF_016801865.2.fna\n&gt;NC_068937.1 Culex pipiens pallens isolate TS chromosome 1, TS_CPP_V2, whole genome shotgun sequence\naagcccttttatggtcaaaaatatcgtttaacttgaatatttttccttaaaaaataaataaatttaagcaaacagctgag\ntagatgtcatctactcaaatctacccataagcacacccctgttcaatttttttttcagccataagggcgcctccagtcaa\nattttcatattgagaatttcaatacaattttttaagtcgtaggggcgcctccagtcaaattttcatattgagaatttcaa\ntacatttttttatgtcgtaggggcgcctccagtcaaattttcatattgagaatttcaatacattttttttaagtcgtagg\nggcgcctccagtcaaattttcatattgagaatttcaatacatttttttaagtcttaggggcgcctccagtcaaattttca\ntattgagaatttcaatacatttttttaagtcgtaggggcgcctccagtcaaattttcatattgagaattttaatacaatt\nttttaaatcctaggggcgccttcagacaaacttaatttaaaaaatatcgctcctcgacttggcgactttgcgactgactg\ncgacagcactaccttggaacactgaaatgtttggttgactttccagaaagagtgcatatgacttgaaaaaaaaagagcgc\nttcaaaattgagtcaagaaattggtgaaacttggtgcaagcccttttatggttaaaaatatcgtttaacttgaatatttt\ntccttaaaaaataaataaatttaagcaaacagctgagtagatgtcatctactcaaatctacccataagcacacccctgga\nCCTAATTCATGGAGGTGAATAGAGCATACGTAAATACAAAACTCATGACATTAGCCTGTAAGGATTGTGTaattaatgca\naaaatattgaTAGAATGAAAGATGCAAGTCccaaaaattttaagtaaatgaATAGTAATCATAAAGATAActgatgatga\n\n\n Your Turn: Explore the file with less (Click to see the instructions)\n\nYou can move around in the file by scrolling with your mouse, with up and down arrows and, if you have them, PgUp and PgDn (also, u will move up half a page and d will move down half a page).\nIf you find yourself scrolling down and down to try and reach the end of the file, you can instead press G to go to the very end right away (and g to go back to the top).\nNotice that you are “inside” a pager and don’t have your shell prompt: press q to quit less.\n\n\n\n\n\n\n\nSide note: Lowercase vs. uppercase nucleotide letters? (Click to expand)\n\n\n\n\n\nAs you have probably noticed, nucleotide bases are typically in typed in uppercase (A, C, G, T). What does the mixture of lowercase and uppercase bases in the Cx. pipiens assembly FASTA mean, then?\nLowercase bases are what is called “soft-masked”: they are repetitive sequences, and bioinformatics programs will treat them differently than non-repetitive sequenced which are in uppercase.\n\n\n\n\n\n\n\n2.3 Reference genome files II: GFF/GTF\n\nThe GFF/GTF format\nThe GTF and GFF formats are tab-delimited tabular files that contain genome annotations, with:\n\nOne row for each annotated “genomic feature” (gene, exon, etc.)\nOne column for each piece of information about a feature, like its genomic coordinates\n\nSee the sample below, with an added header line (not normally present) with column names:\nseqname     source  feature start   end     score  strand  frame    attributes\nNC_000001   RefSeq  gene    11874   14409   .       +       .       gene_id \"DDX11L1\"; transcript_id \"\"; db_xref \"GeneID:100287102\"; db_xref \"HGNC:HGNC:37102\"; description \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; gbkey \"Gene\"; gene \"DDX11L1\"; gene_biotype \"transcribed_pseudogene\"; pseudo \"true\"; \nNC_000001   RefSeq  exon    11874   12227   .       +       .       gene_id \"DDX11L1\"; transcript_id \"NR_046018.2\"; db_xref \"GeneID:100287102\"; gene \"DDX11L1\"; product \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; pseudo \"true\"; \nSome details on the more important/interesting columns:\n\nseqname — Name of the chromosome, scaffold, or contig\nfeature — Name of the feature type, e.g. “gene”, “exon”, “intron”, “CDS”\nstart & end— Start & end position of the feature\nstrand — Whether the feature is on the + (forward) or - (reverse) strand\nattribute — A semicolon-separated list of tag-value pairs with additional information\n\n\n\nYour Culex GTF file\nTake a look at your Cx. pipiens GTF file:\nless -S data/ref/GCF_016801865.2.gtf\n#gtf-version 2.2\n#!genome-build TS_CPP_V2\n#!genome-build-accession NCBI_Assembly:GCF_016801865.2\n#!annotation-source NCBI RefSeq GCF_016801865.2-RS_2022_12\nNC_068937.1     Gnomon  gene    2046    110808  .       +       .       gene_id \"LOC120427725\"; transcript_id \"\"; db_xref \"GeneID:120427725\"; description \"homeotic protein deformed\"; gbkey \"Gene\"; gene \"LOC120427725\"; gene_biotype \"protein_coding\"; \nNC_068937.1     Gnomon  transcript      2046    110808  .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; \nNC_068937.1     Gnomon  exon    2046    2531    .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1     Gnomon  exon    52113   52136   .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1     Gnomon  exon    70113   70962   .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1     Gnomon  exon    105987  106087  .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1     Gnomon  exon    106551  106734  .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \n\n\n\n\n\n\nAvoid line-wrapping with less -S\n\n\n\nLines in a file may contain too many characters to fit on your screen, as will be the case for this GTF file. less will by default “wrap” such lines onto the next line on your screen, but this is often confusing for files like FASTQ and tabular files like GTF.\nTherefore, we turned off line-wrapping above by using the -S option to less.\n\n\n\n\n Your Turn: The GTF file is sorted and all entries from the first line of the table until you again see “gene” in the third column belong to the first gene. Can you make sense of this, given what you know of gene structures? How many transcripts does the first gene have? (Click to see some pointers)\n\n\nThe first gene (“LOC120427725”) has 3 transcripts.\nEach transcript has 6-7 exons, 5 CDSs, and a start and stop codon.\n\nBelow, I’ve printed all lines belonging to the first gene:\nNC_068937.1 Gnomon  gene    2046    110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"\"; db_xref \"GeneID:120427725\"; description \"homeotic protein deformed\"; gbkey \"Gene\"; gene \"LOC120427725\"; gene_biotype \"protein_coding\"; \nNC_068937.1 Gnomon  transcript  2046    110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; \nNC_068937.1 Gnomon  exon    2046    2531    .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1 Gnomon  exon    52113   52136   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1 Gnomon  exon    70113   70962   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1 Gnomon  exon    105987  106087  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1 Gnomon  exon    106551  106734  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \nNC_068937.1 Gnomon  exon    109296  109660  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"6\"; \nNC_068937.1 Gnomon  exon    109726  110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"7\"; \nNC_068937.1 Gnomon  CDS 70143   70962   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  CDS 105987  106087  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"4\"; \nNC_068937.1 Gnomon  CDS 106551  106734  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"5\"; \nNC_068937.1 Gnomon  CDS 109296  109660  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"6\"; \nNC_068937.1 Gnomon  CDS 109726  110025  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  start_codon 70143   70145   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  stop_codon  110026  110028  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  transcript  5979    110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; \nNC_068937.1 Gnomon  exon    5979    6083    .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1 Gnomon  exon    52113   52136   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1 Gnomon  exon    70113   70962   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1 Gnomon  exon    105987  106087  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1 Gnomon  exon    106551  106734  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \nNC_068937.1 Gnomon  exon    109296  109660  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"6\"; \nNC_068937.1 Gnomon  exon    109726  110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"7\"; \nNC_068937.1 Gnomon  CDS 70143   70962   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  CDS 105987  106087  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"4\"; \nNC_068937.1 Gnomon  CDS 106551  106734  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"5\"; \nNC_068937.1 Gnomon  CDS 109296  109660  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"6\"; \nNC_068937.1 Gnomon  CDS 109726  110025  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  start_codon 70143   70145   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  stop_codon  110026  110028  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  transcript  60854   110807  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; \nNC_068937.1 Gnomon  exon    60854   61525   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1 Gnomon  exon    70113   70962   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1 Gnomon  exon    105987  106087  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1 Gnomon  exon    106551  106734  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1 Gnomon  exon    109296  109660  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \nNC_068937.1 Gnomon  exon    109726  110807  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"6\"; \nNC_068937.1 Gnomon  CDS 70143   70962   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"2\"; \nNC_068937.1 Gnomon  CDS 105987  106087  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  CDS 106551  106734  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"4\"; \nNC_068937.1 Gnomon  CDS 109296  109660  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"5\"; \nNC_068937.1 Gnomon  CDS 109726  110025  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"6\"; \nNC_068937.1 Gnomon  start_codon 70143   70145   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"2\"; \nNC_068937.1 Gnomon  stop_codon  110026  110028  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"6\";"
  },
  {
    "objectID": "labs/data.html#our-dataset",
    "href": "labs/data.html#our-dataset",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "1 Our dataset",
    "text": "1 Our dataset\nWe will work with RNA-seq data from the paper “Genome-wide transcriptomic changes reveal the genetic pathways involved in insect migration”, published in 2022 in Molecular Ecology:\n\n\n\n\n\nThe focal organism in the study is the marmalade hoverfly (Episyrphus balteatus) (hoverflies, family Syrphidae, are in the US also known as flower flies), which has migratory and non-migratory phenotypes:\n\n\n\nFig 1 from the paper. (a) Female feeding on a buttercup. (b) Location of the mountain pass of Bujaruelo. (c) The 30 m wide pass concentrates migrants crossing the Pyrenees. (d) Active Episyrphus migration (black dots on skyline) over the pass in October\n\n\n\n1.1 Today’s & next week’s focus\nToday we will focus on the general aspects of reference genomes and HTS data: recall that nearly all HTS data comes in the form of FASTQ files, and that reference genomes are central to many types of genomics and transcriptomics project.\nNext week, after covering RNA-seq methodology in the lecture, we will run a differential expression analysis."
  },
  {
    "objectID": "labs/data.html#introduction",
    "href": "labs/data.html#introduction",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "1 Introduction",
    "text": "1 Introduction\n\n1.1 Our dataset\nWe will work with RNA-seq data from the paper “Two avian Plasmodium species trigger different transcriptional responses on their vector Culex pipiens”, published late last year in Molecular Ecology (link):\n\n\n\n\n\nThis paper uses RNA-seq data to study gene expression in Culex pipiens mosquitos infected with malaria-causing Plasmodium protozoans — specifically, it compares mosquitos according to:\n\nInfection status: Plasmodium cathemerium vs. P. relictum vs. control\nTime after infection: 24 h vs. 10 days vs. 21 days\n\n\n\n\n1.2 What we will do\nToday we’ll focus on the general aspects of reference genomes and HTS data — specifically, we will:\n\nSee how you can find a reference genome and the associated files\nExplore the reference genome files\nExplore our HTS reads\nPerform quality-control on some of our reads with a command-line tool, FastQC\n\nNext week, after covering RNA-seq methodology in the lecture, we will run a differential expression analysis.\n\n\n\n\n\n\nWhat we won’t do\n\n\n\nNext week’s differential expression analysis (in R) will start with a “gene count table”. Several steps are needed to produce that count table from the FASTQ files that we’ll explore today — next week, you’ll learn a bit more about what those steps are, but we won’t run them ourselves in the interest of time.\n\n\n\n\n\n1.3 Getting your own copy of the files\nThe main data files in a reference-based HTS project are reference genome files and sequence reads. We’ll discuss those files in more detail below — first, let’s get everyone their own copy of the data.\n\nCheck you’re in your personal dir in /fs/scratch/PAS2250/ENT6703 (use cd to change if needed):\n\npwd\n/fs/scratch/PAS2250/ENT6703/jelmer\n\nThen, use the Unix copy command cp as follows (yes, there’s a space + period at the end!):\n\ncp -rv /fs/scratch/PAS2250/ENT6703/share/data .\n‘/fs/scratch/PAS2250/ENT6703/share/data’ -&gt; ‘./data’\n‘/fs/scratch/PAS2250/ENT6703/share/data/meta’ -&gt; ‘./data/meta’\n‘/fs/scratch/PAS2250/ENT6703/share/data/meta/metadata.tsv’ -&gt; ‘./data/meta/metadata.tsv’\n‘/fs/scratch/PAS2250/ENT6703/share/data/ref’ -&gt; ‘./data/ref’\n‘/fs/scratch/PAS2250/ENT6703/share/data/ref/GCF_016801865.2.gtf’ -&gt; ‘./data/ref/GCF_016801865.2.gtf’\n‘/fs/scratch/PAS2250/ENT6703/share/data/ref/GCF_016801865.2.fna’ -&gt; ‘./data/ref/GCF_016801865.2.fna’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq’ -&gt; ‘./data/fastq’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802868_R2.fastq.gz’ -&gt; ‘./data/fastq/ERR10802868_R2.fastq.gz’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802863_R1.fastq.gz’ -&gt; ‘./data/fastq/ERR10802863_R1.fastq.gz’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802880_R2.fastq.gz’ -&gt; ‘./data/fastq/ERR10802880_R2.fastq.gz’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802880_R1.fastq.gz’ -&gt; ‘./data/fastq/ERR10802880_R1.fastq.gz’\n# [...truncated...]\n\n\n\n\n\n\nIn the command above:\n\n\n\n\nOption -r will enable “recursive” (=dirs, not just files) copying\nOption -v will turn on “verbose” output: it will report what it’s copying\nThe first argument (the /fs/ path) is the source directory\nThe second argument is the target directory: . means the current working dir\n\n\n\nUse the tree command (with -C to show colors) to recursively list files in a way that gives a nice overview:\ntree -C\n.\n└── data\n    ├── fastq\n    │   ├── ERR10802863_R1.fastq.gz\n    │   ├── ERR10802863_R2.fastq.gz\n    │   ├── ERR10802864_R1.fastq.gz\n    │   ├── ERR10802864_R2.fastq.gz\n    │   ├── [...truncated - more FASTQ files...]\n    ├── meta\n    │   └── metadata.tsv\n    └── ref\n        ├── GCF_016801865.2.fna\n        └── GCF_016801865.2.gtf\n4 directories, 47 files\nAs we saw earlier, we have a whole bunch of FASTQ files (.fastq.gz extension, the reads), a metadata file, and two reference genomes files (.fna and .gtf). You’ll take a closer look at each of those below.\n\n\n\n1.4 Viewing the metadata\nYou will first take a look at the “metadata” associated with the samples analyzed in this paper, such as the treatment information for each sample, and a sample ID that we can link to the files with reads.\nThe metadata file metadata.tsv (tsv for “tab-separated values”) is in the folder data/meta:\nls -lh data/meta\n-rw-r--r-- 1 jelmer PAS0471 644 Jan 21 09:15 metadata.tsv\nYou can find this file in the VS Code side bar and click on it to open it in the editor. Alternatively, you could use the cat command to show the file contents in the shell:\ncat data/meta/metadata.tsv\nsample_id    time     treatment\nERR10802882  10_days  cathemerium\nERR10802875  10_days  cathemerium\nERR10802879  10_days  cathemerium\nERR10802883  10_days  cathemerium\nERR10802878  10_days  control\nERR10802884  10_days  control\nERR10802877  10_days  control\nERR10802881  10_days  control\nERR10802876  10_days  relictum\nERR10802880  10_days  relictum\nERR10802885  10_days  relictum\nERR10802886  10_days  relictum\nERR10802864  24_h     cathemerium\nERR10802867  24_h     cathemerium\nERR10802870  24_h     cathemerium\nERR10802866  24_h     control\nERR10802869  24_h     control\nERR10802863  24_h     control\nERR10802871  24_h     relictum\nERR10802874  24_h     relictum\nERR10802865  24_h     relictum\nERR10802868  24_h     relictum\n\n\n Your Turn: Based on this metadata, try to understand the experimental design (Click to see pointers)\n\n\nThe time column contains the amount of time after infection, with “h” short for hours.\nThe treatment column contains the treatment: which Plasmodium species, or “control” (not infected).\nWe have 3 treatments across each of two timepoints, with a number of replicates per treatment-timepoint combination.\n\n\n\n\n Your Turn: How many biological replicates are there? Is a treatment missing relative to what was described above and in the paper? (Click to see the answers)\n\n\nThere are 4 replicates per time x treatment combination, except in two cases (the paper says those two samples were removed from the final analysis).\nThe 21-days timepoint is missing: I removed it to simplify the dataset a bit.\n\n\n\n\n\n\n\n\nSide note: How did I retrieve this paper’s data? (Click to expand)\n\n\n\n\n\nAt the end of the paper, there is a section called “Open Research” with a “Data Availability Statement”, which reads:\n\nRaw sequences generated in this study have been submitted to the European Nucleotide Archive ENA database (https://www.ebi.ac.uk/ena/browser/home) under project accession number PRJEB41609, Study ERP125411. Sample metadata are available at https://doi.org/10.20350/digitalCSIC/15708.\n\nI used the second link above to download the metadata, which I slightly edit to simplify. I used the project accession number PRJEB41609 to directly download the raw sequences (i.e., the FASTQ files we’ll explore below) to OSC using a command-line tool called fastq-dl."
  },
  {
    "objectID": "labs/data.html#fastqc",
    "href": "labs/data.html#fastqc",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "4 FastQC",
    "text": "4 FastQC\nA useful example of a genomics tool with a CLI is FastQC, for quality control of FASTQ files. It is ubiquitous because nearly all HTS data comes in FASTQ files, and your first step is always to check the quality of the reads.\n\n\n4.1 Running FastQC\nTo run FastQC, use the command fastqc.\nIf you want to analyze one of your FASTQ files with default FastQC settings, a complete FastQC command to do so would simply be fastqc followed by the name of the file2:\nfastqc data/fastq/ERR10802863_R1.fastq.gz\nHowever, an annoying default behavior by FastQC is to write its output files in the same dir as the input files — in general, it’s not great practice to directly mix your primary data and your results like that.\nTo figure out how we can change that, first consider that many commands and bioinformatics tools alike have an option -h and/or --help that will print some usage information to the screen.\n\n\nYour Turn: Print FastQC’s help info, and figure out which option you can use to specify an output directory of your choice. (Click for the solution)\n\nfastqc -h and fastqc --help will both work. You’ll get quite a bit of output printed to screen, including the snippet about output directories shown below:\nfastqc -h\n  -o --outdir     Create all output files in the specified output directory.\n                    Please note that this directory must exist as the program\n                    will not create it.  If this option is not set then the \n                    output file for each sequence file is created in the same\n                    directory as the sequence file which was processed.\nSo, you can use -o or equivalently, --outdir to specify an output dir.\n\nNow, let’s try to run FastQC and tell it to use the output dir results/fastqc:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nfastqc: command not found\nHowever, there is a wrinkle, as you can see above. It turns out that a FastQC installation is already available to us at OSC3, but we do have to load it before we can use it. Without going into further details about software usage at OSC, please accept that we load FastQC as follows:\nmodule load fastqc\nNow, let’s try again:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nSpecified output directory 'results/fastqc' does not exist\n\n Your Turn: What is going on here? Can you try to fix this problem?\n\n\n\n\nClick here for hints\n\nYou can create a new directory by using the buttons in the VS Code side bar, or using the mkdir command — here, try it as mkdir -p followed by the directory you want to create.\n\n\n\nClick here for the solution\n\n\nThe problem, as the error fairly clearly indicates, is that the output directory that we specified with --outdir does not currently exist. We might have expected FastQC to be smart/flexible enough to create this dir for us (many bioinformatics tools are), but alas.\nWith the mkdir command, to create “two levels” of dirs at once, like we need to here (both results and then fastqc within there), we need its -p option:\n\nmkdir -p results/fastqc\n\nAnd for our final try before we give up and throw our laptop out the window:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\n#&gt; Started analysis of ERR10802863_R1.fastq.gz\n#&gt; Approx 5% complete for ERR10802863_R1.fastq.gz\n#&gt; Approx 10% complete for ERR10802863_R1.fastq.gz\n#&gt; Approx 15% complete for ERR10802863_R1.fastq.gz\n#&gt; [truncated]\n#&gt; Analysis complete for ERR10802863_R1.fastq.gz\nSuccess!!\n\n\n\n4.2 FastQC output files\nLet’s take a look at the files in the output dir we specified:\nls -lh results/fastqc\nTODO\nThere is a XX and an HTML file,\n\n\n Your Turn: Now run FastQC for the corresponding R2 file. Would you use the same output dir? (Click for the solution)\n\nYes, it makes sense to use the same output dir, since as you could see above, the output file names have the input file identifiers in them. As such, we don’t need to worry about overwriting files, and it will be easier to have all the results in a single dir.\nTo run FastQC for the R2 file:\nfastqc --outdir results/fastqc ERR10802863_R2.fastq.gz\n#&gt; Started analysis of ERR10802863_R2.fastq.gz\n#&gt; Approx 5% complete for ERR10802863_R2.fastq.gz\n#&gt; Approx 10% complete for ERR10802863_R2.fastq.gz\n#&gt; Approx 15% complete for ERR10802863_R2.fastq.gz\n#&gt; [truncated]\n#&gt; Analysis complete for ERR10802863_2.fastq.gz\nls -lh results/fastqc\nTODO\n\n\n\n\n4.3 Interpreting FastQC’s output\nFirst, we’ll have to download the HTML files. TODO - FINISH\n\n\nOverview of module results\nFastQC has “pass” (checkmark in green), “warning” (exclamation mark in orange), and “fail” (cross in red) assessments for each module, as you can see below.\nThese are handy but it is important to realize that… TODO\n\n\n\n\n\nBasic statistics\n\n\n\n\n\nPer base quality sequence quality\nIn a FASTQ file, every single base has a quality score. These figures visualize the mean per-base quality score along the length of the read.\n\nA decrease in sequence quality along the reads is normal.\nR2 (reverse) reads are usually worse than R1 (forward) reads.\n\n\n\nGood / OK:\n\n\n\n\nBad:\n\n\n\n\n\n\n\nPer sequence quality scores\nQuality scores averaged over the full sequence.\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\nPer base sequence content\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\nIt’s worth noting that some types of library will always produce biased sequence composition, normally at the start of the read. Libraries produced by priming using random hexamers (including nearly all RNA-Seq libraries) and those which were fragmented using transposases inherit an intrinsic bias in the positions at which reads start. Whilst this is a true technical bias, it isn’t something which can be corrected by trimming and in most cases doesn’t seem to adversely affect the downstream analysis. It will however produce a warning or error in this module. — source\n\n\n\nPer sequence GC content\n\nAn unusual distribution could indicate contamination.\nThe expected distribution is for whole-genome shotgun sequencing – it is normal for RNA-seq data to have a narrower distribution.\n\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\nPer base N content\nQuantifies the percentage of uncalled bases (N) across the read.\n\nNs may become more common at the end of the read, and at the start of the read for highly biased libraries.\nA peak like in the figure on the right indicates a problem with a specific cycle in the Illumina run.\n\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\nSequence length distribution\nWill throw a warning, like below, as soon as not all sequences are of the same length, but this is quite normal.\n\n\n\n\n\nSequence duplication levels\nChecks how many duplicates (= identical sequences) are present.\n\nOften throws a warning for RNA-seq data, which can be ignored, as these represent highly expressed transcripts.\nPay attention to the blue line (red line can mostly be ignored).\n\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\nOverrepresented sequences\n\nReturns a Warning if any sequence is &gt;0.1% of total.\nReturns Failure if any sequence is &gt;1% of total.\n\n\n\n\n\n\nAdapter content\nChecks for known adapter sequences. When some of the insert sizes are shorter than the read length, adapters can end up in the sequence – these should be removed!\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\n\n4.4 Interpreting our FastQC output\n\n\nYour Turn: Open the HTML file for the R1 FASTQ file and go through all the modules. Can you make sense of it? Does the data look good to you, overall?\n\n\n\n\nYour Turn: Now open the HTML file for the R2 FASTQ file and take a look just at the quality scores. Does it look any worse than the R1?"
  },
  {
    "objectID": "labs/data.html#summary-and-overview-of-modules",
    "href": "labs/data.html#summary-and-overview-of-modules",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "5 Summary and overview of modules",
    "text": "5 Summary and overview of modules\n\n\n\n\n\nModule 1: Basic statistics\n\n\n\n\n\nModule 2: Per-base quality along the read\n\nIn a FASTQ file, every single base has a quality score. These figures visualize the mean per-base quality score along the length of the read.\n\nGood / OK:\n\n\n\nBad:\n\n\n\n\nA decrease in sequence quality along the reads is normal.\nR2 (reverse) reads are usually worse than R1 (forward) reads.\n\n\n\nModule 3: Per-sequence quality scores\n\nQuality scores averaged over the full sequence.\n\nGood:\n\n\n\nBad:\n\n\n\n\n\nModule 4: Per-base sequence content\nGood:\n\n\n\nBad:\n\n\n\n\nIt’s worth noting that some types of library will always produce biased sequence composition, normally at the start of the read. Libraries produced by priming using random hexamers (including nearly all RNA-Seq libraries) and those which were fragmented using transposases inherit an intrinsic bias in the positions at which reads start. Whilst this is a true technical bias, it isn’t something which can be corrected by trimming and in most cases doesn’t seem to adversely affect the downstream analysis. It will however produce a warning or error in this module. — source\n\n\n\nModule 5: Per-sequence GC content\nGood:\n\n\n\nBad:\n\n\n\n\nAn unusual distribution could indicate contamination.\nThe expected distribution is for whole-genome shotgun sequencing – it is normal for RNA-seq data to have a narrower distribution.\n\n\n\nModule 6: Per-base N content\n\nQuantifies the percentage of uncalled bases (N) across the read.\n\nGood:\n\n\n\nBad:\n\n\n\n\nNs may become more common at the end of the read,\nand at the start of the read for highly biased libraries.\nA peak like in the fig. on the right indicates a problem with a specific cycle in the Illumina run.\n\n\n\nModule 7: Sequence length distribution\nWarning:\n\n\n\nWill throw a warning as soon as not all sequences are of the same length, but this is quite normal.\n\n\nModule 8: Sequence duplication levels\n\nChecks, for a subset of sequences, how many duplicates (= identical sequences) are present.\n\nGood:\n\n\n\n\nFigure source\n\n\n\n“Bad”:\n\n\n\n\nOften throws a warning for RNA-seq data, which can be ignored, as these represent highly expressed transcripts.\nPay attention to the blue line (red line can mostly be ignored).\n\n\n\nModule 9: Overrepresented sequences\n\n\n\n\nReturns a Warning if any sequence is &gt;0.1% of total.\nReturns Failure if any sequence is &gt;1% of total.\n\n\n\nModule 10: Adapter content\n\nChecks for known adapter sequences\n\nGood:\n\n\n\nBad:\n\n\n\n\nFigure source\n\n\n\n.content-box-info[ When some of the insert sizes are shorter than the read length, adapters can end up in the sequence – these should be removed!]\n\n\nModule 11: K-mer content\n\nAnother way to check for duplicated sequences, especially in the presence of sequencing error.\n\n\n\nModule 12: Per-tile sequence quality\n.pull-left[ Good:\n\n\n\n]\n.pull-right[ Bad:\n\n\n\n]\n\n\n\n\n\n\n\nRunning the analysis at scale\n\n\n\nI’ve shown you the main pieces of the computational infrastructure for “command-line genomics”. We’ve seen a very basic example of loading and running a command-line tool at OSC.\nThe missing pieces for a fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\n(This used the same language (Bash) as the commands you’d type interactively, so at its most basic this involves pasting those commands into a text file.)\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\n(At its most basic, this involves putting sbatch in front of the script name.)\nTo make use of the capabilities of the supercomputer and speeding up our analysis, we can submit multiple jobs in parallel using a loop."
  },
  {
    "objectID": "labs/data.html#in-closing",
    "href": "labs/data.html#in-closing",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "5 In closing",
    "text": "5 In closing\nIn today’s lab, you were introduced to:\n\nWorking at the Ohio Supercomputer Center\nUsing the VS Code text editor\nUsing the Unix shell\nReference genome FASTA & GTF files & where to find these\nHTS read FASTQ files and how to quality-control these\nHow to run a command-line bioinformatics tool\n\nTaking a step back, I’ve shown you the main pieces of the computational infrastructure for what we may call “command-line genomics”: genomics analysis using command-line tools. And we’ve seen a basic example of loading and running a command-line tool at OSC.\n\n\n\n\n\n\nSide note: scaling the analysis & next step for real projects (Click to expand)\n\n\n\n\n\nThe missing pieces for a typical, fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\nTo make speed things, using the OSC’s capabilities, we can submit multiple jobs in parallel using a loop.\n\nIf it seems that speed and computing power may not be an issue, given how fast FastQC ran, keep in mind that:\n\nWe here worked with subsampled (much smaller than usual) FASTQ files\nWe only ran FastQC for one of our 23 samples, and your experiment may have 50+ samples\nWe need to run a bunch more tools, and some of those take much longer to run or need lots of RAM memory.\n\nAll that said, those missing pieces mentioned above are outside the scope of this short introduction — but if you managed today, it should not be hard to learn those skills either."
  },
  {
    "objectID": "labs/DE.html#getting-set-up",
    "href": "labs/DE.html#getting-set-up",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "",
    "text": "Log in to OSC at https://ondemand.osc.edu.\nClick on Interactive Apps (top bar) &gt; RStudio Server\n\nTBA\n\nFill out the form as shown below:\n\nTBA\n\nNow, you should see a box like this:\n\n\n\n\n\nYour job should start running pretty soon, and when it’s ready the box should look like this:\n\n\n\n\n\nClick Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open. You’re ready to go!\n\n\n\n\nTBA\nNow, RStudio will reload with the newly created Project open.\nIf you get the pop-up below, click Don't Save (do this whenever you get that pop-up):\n\n\n\n\n\n\n\nif(! \"pacman\" %in% installed.packages()) install.packages(\"pacman\")\npackages &lt;- c(\"DESeq2\",          # Differential expression analysis\n              \"tidyverse\",       # Misc. data manipulation and plotting\n              \"ggrepel\",         # PCA with sample IDs\n              \"pheatmap\")        # Heatmap plot\npacman::p_load(char = packages)\n\ntheme_set(theme_bw())  # Set ggplot theme\n\n\n\n\nInput files:\n\nGene counts table\nMetadata table – so we can group our samples and make comparisons between these groups.\n\n\ncount_table_file &lt;- here(\"results/count/gene_counts_all.txt\")\nmetadata_file &lt;- here(\"data/meta/metadata.txt\")\n\nOutput directories – and we create them if they don’t already exist:\n\noutdir &lt;- here(\"results/DE/\")\nif (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)\n\n\n\n\nLoad the count table:\n\nraw_counts &lt;- read.table(count_table_file,\n                         sep = \"\\t\", header = TRUE, skip = 1)\n\nLoad the metadata information:\n\nmetadata &lt;- read.table(metadata_file, header = TRUE)\n\nhead(metadata)\n\nThe Treatment column currently has the values Agrobacterium_noexp, Agrobacterium_myb, and mock.\nTo shorten this a bit, we’ll get rid of “Agrobacterium_”:\n\nmetadata$Treatment &lt;- sub(\"Agrobacterium_\", \"\", metadata$Treatment)\n\nunique(metadata$Treatment)"
  },
  {
    "objectID": "labs/DE.html#prepare-the-data",
    "href": "labs/DE.html#prepare-the-data",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "2 Prepare the data",
    "text": "2 Prepare the data\nChange the column names, which are very long:\n\ncolnames(raw_counts)[7:8]\n\n\nmy_regex &lt;- \".+PonceM_(.+)_V1N.+\"\ncolnames(raw_counts) &lt;- sub(my_regex, \"\\\\1\", colnames(raw_counts))\n\ncolnames(raw_counts)\n\nBesides the counts, there are columns with metadata for each gene:\n\nraw_counts[1:5, 1:8]\n\nLet’s remove those:\n\ncounts &lt;- raw_counts[, 7:ncol(raw_counts)]\nrownames(counts) &lt;- raw_counts$Geneid\n\n\n2.1 Check sample IDs\nFor differential expression analysis, we will be using the popularDESeq2 R/Bioconductor package (paper, website).\nWe will load both the count table and the metadata into DESeq2. When doing so, DESeq2 assumes that sample IDs in both tables match and are provided in the same order. Let’s make sure this is indeed the case.\nSort both data frames alphabetically:\n\nmetadata &lt;- metadata[order(metadata$SampleID), ]\ncounts &lt;- counts[, order(colnames(counts))]\n\nCheck if names are the same:\n\nmetadata$SampleID\n\ncolnames(counts)\n\nmatching_names &lt;- identical(metadata$SampleID, colnames(counts))\nmatching_names\nif(matching_names == FALSE) stop(\"Sample ID in metadata and count matrix do not match!\")\n\n\n\n2.2 Create the DESeq2 object\nWe will create the DESeq2 object using the function DESeqDataSetFromMatrix(), which we will provide with three pieces of information:\n\nThe count data with argument countData.\nThe metadata with argument colData.\nThe model design for the DE analysis – argument design.\nFor now, we will specify ~1, which means “no design” – we will change this before the actual DE analysis.\n\n\ndds_raw &lt;- DESeqDataSetFromMatrix(countData = counts,\n                                  colData = metadata,\n                                  design = ~ 1)"
  },
  {
    "objectID": "labs/DE.html#explore-the-count-data",
    "href": "labs/DE.html#explore-the-count-data",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "3 Explore the count data",
    "text": "3 Explore the count data\nWhat are number of rows and columns of the count matrix?\n\ndim(counts)\n\nHow many genes have non-zero counts?\n\ndim(counts[rowSums(counts) &gt; 0, ])\n\nHow many genes have total counts of at least 10?\n\ndim(counts[rowSums(counts) &gt;= 10, ])\n\n\n3.1 Histogram of gene counts\nLet’s plot a histogram of gene counts:\n\ntheme_set(theme_bw())\n\nsummed_gene_counts &lt;- data.frame(gene_count = rowSums(counts)) %&gt;%\n  rownames_to_column(\"gene_id\")\n\nggplot(data = summed_gene_counts) +\n  geom_histogram(aes(x = gene_count), binwidth = 10000) +\n  scale_y_log10(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0,0))\n\nZoom in a bit:\n\nggplot(data = summed_gene_counts) +\n  geom_histogram(aes(x = gene_count), binwidth = 1000) +\n  scale_y_log10(expand = c(0, 0)) +\n  scale_x_continuous(limits = c(0, 200000), expand = c(0,0)) +\n  theme(plot.margin = margin(0.5, 0.7, 0.5, 0.5, \"cm\"))\n\nHow are counts distributed across samples? That is, we would like a sum of counts for each column. To get this, we use the apply() function, which can apply a function (in our case sum()) to all columns (hence MARGIN = 2 – for rows, use 1) of our counts dataframe:\n\napply(X = counts, MARGIN = 2, FUN = sum)"
  },
  {
    "objectID": "labs/DE.html#principal-component-analysis-pca",
    "href": "labs/DE.html#principal-component-analysis-pca",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "4 Principal Component Analysis (PCA)",
    "text": "4 Principal Component Analysis (PCA)\n\n4.1 Run the PCA and prepare for plotting\nFirst, we normalize the count data to have even sampling across samples (with respect to library size) and approximately even variance:\n\nvsd &lt;- varianceStabilizingTransformation(dds_raw, blind = TRUE)\n\nNext, we run the PCA and retrieve the data to plot with ggplot2:\n\npcaData &lt;- plotPCA(vsd,\n                   ntop = 500,\n                   intgroup = c(\"AMF\", \"Treatment\"),\n                   returnData = TRUE)\n\nWe extract the percentage of variance explained by different principal components, so we can later add this information to the plot:\n\npercentVar &lt;- round(100 * attr(pcaData, \"percentVar\"))\npercentVar\n\n\n\n4.2 Plot the PCA results\n\nggplot(pcaData,\n       aes(x = PC1, y = PC2, color = AMF, shape = Treatment)) +\n  geom_point(size = 6) +\n  xlab(paste0(\"PC1: \", percentVar[1], \"% of variance\")) +\n  ylab(paste0(\"PC2: \", percentVar[2], \"% of variance\"))\n\n\n\n4.3 Plot again – with sample names\n\nggplot(pcaData,\n       aes(PC1, PC2, color = AMF, shape = Treatment)) +\n  geom_point(size = 3) +\n  geom_label_repel(aes(label = name)) +\n  xlab(paste0(\"PC1: \", percentVar[1], \"% of variance\")) +\n  ylab(paste0(\"PC2: \", percentVar[2], \"% of variance\"))"
  },
  {
    "objectID": "labs/DE.html#de-analysis-full-dataset",
    "href": "labs/DE.html#de-analysis-full-dataset",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "5 DE analysis – full dataset",
    "text": "5 DE analysis – full dataset\nThe design has two factors: AMF and Treatment. Rather than fit a multivariate model, we can start by merging the two into a single factor called group, and fit a univariate model with this factor.\n\ndds_raw$group &lt;- factor(paste(dds_raw$AMF, dds_raw$Treatment, sep = \"_\"))\ntable(dds_raw$group)\n\nWe will set the “reference” level of the factor to be the double negative control (empty substrate, no Agrobacteria):\n\ndds_raw$group &lt;- relevel(dds_raw$group, ref = \"control_mock\")\ndds_raw$group\n\nNext, we set the analysis design:\n\ndesign(dds_raw) &lt;- formula(~ group)\n\nAnd finally, we perform the differential expression analysis with the DEseq() function:\n\ndds &lt;- DESeq(dds_raw)\n\nThe DESeq() function above performs three steps consecutively:\n\nestimateSizeFactors() – “Normalization” by library size and composition.\nNote that DESeq2 doesn’t actually normalize the counts in the sense that it produces a matrix with adjusted counts. Instead it uses raw counts and includes the size factors in the modeling.\nTo learn more about gene count normalization, see this video and this page.\nestimateDispersions() – Estimate gene-wise dispersion (variance in counts).\nnbinomWaldTest(ddsObj) – Fit the negative binomial GLM and calculate Wald statistics, which is the test statistic underlying the p-value for whether a gene is differentially expressed.\n\nThese functions could also be called separately, which would be useful if you want to be able to change more defaults.\n\n5.1 The results table\n\nres &lt;- results(dds)\nhead(res)\n\nBy default, the results table prints statistics comparing the last level of the factor with the first level: that is, log-fold change and p-values describe differences between these two levels specifically. However, we can easily extract equivalent statistics for any pairwise comparison among our factor levels, which we will see later.\nFor now, we will explore what each column in this table means:\n\nThe baseMean column contains the mean expression level across all samples.\nThe log2FoldChange column contains the log2-fold change of gene counts between the compared levels, that is, it represents the effect size.\nA log2-fold change of 1 indicates that the expression in the reference level is two-fold lower than that of the other level, a log2-fold change of 2 indicates a four-fold difference, a log2-fold change of 3 indicates an eight-fold difference, and so on.\nSimilarly, negative log2-fold values indicate a change in gene counts in the other direction: the reference level is higher than the other level.\nThe lfcSE column indicates the uncertainty in terms of the standard error (SE) of the log2-fold change estimate.\nThe stat column indicates the value for the Wald test’s test statistic.\nThe pvalue column reported the uncorrected p-value from the Wald test.\nBecause we are testing significance for many genes, we need to correct for multiple testing. DESeq2 uses the Benjamini-Hochberg False Discovery Rate (FDR) correction, and these values are reported in the column padj (i.e., adjusted p-value).\n\nA summary of this information about each column can be seen by running the mcols() function:\n\nmcols(res)\n\n\n\n5.2 NA values in the results table\nSome values in the results table can be set to NA for one of the following reasons:\n\nIf a gene contains a sample with a count outlier, both the p-value and adjusted p-value will be set to NA. (DESeq2 performs outlier detection using Cook’s distance.)\nIf all samples have zero counts for a given gene, the baseMean column will be zero, and the log2-fold change estimates, p-value and adjusted p-value will all be set to NA.\nDESeq2 also automatically filters genes with a low mean count in the sense that it does not include them in the multiple testing correction. Therefore, in such cases, the p-value will not be NA, but the adjusted p-value will be.\nBecause we have very low power to detect differential expression for such low-count genes, it is beneficial to remove them prior to the multiple testing correction: that way, the correction becomes less severe for the remaining genes.\n\nLet’s see how many genes have NA p-values:\n\n# Number of genes with NA p-value:\nsum(is.na(res$pvalue))\n\n# As a proportion of the total number of genes in the test:\nsum(is.na(res$pvalue)) / nrow(res)\n\nAnd NA adjusted p-values:\n\n# Number of genes with NA p-value:\nsum(is.na(res$padj))\n\n# As a proportion of the total number of genes in the test:\nsum(is.na(res$padj)) / nrow(res)"
  },
  {
    "objectID": "labs/DE.html#de-analysis-contrast-two-custom-groups",
    "href": "labs/DE.html#de-analysis-contrast-two-custom-groups",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "6 DE analysis – contrast two custom groups",
    "text": "6 DE analysis – contrast two custom groups\nUsing the resultsNames function, we can see which pairwise contrasts between different levels of the factor are available (though it is not displayed in a particularly readable fashion):\n\nresultsNames(dds)\n\nNot all pairwise contrasts between the 5 levels in our group factor are available here: instead, control_mock, which we set as the reference level, is being compared with the other 3 levels. (However, we can make other pairwise comparisons, too.)\nAbove, we looked at the results for the last of these comparisons (group_Ri_myb_vs_control_mock, i.e. “Ri_myb” vs. “control_mock”), simply because DESeq2 will show the last comparison by default when calling the results() function.\nTo see the results table for one of the other 3 comparisons, we pass a vector to the contrast argument of the results() function with the factor (group) and the two levels to be contrasted. For example, to see the results for “Ri_mock” vs. “control_mock”:\n\n# Here, we could specify *any* pairwise contrast,\n# not just the ones with \"control_mock\" that resultsNames() prints as seen above.\nmy_contrast &lt;- c(\"Ri_mock\", \"control_mock\")\n\nres &lt;- results(dds,\n               contrast = c(\"group\", my_contrast))\n\nHow many adjusted p-values were less than 0.1?\n\nsum(res$padj &lt; 0.1, na.rm = TRUE)"
  },
  {
    "objectID": "labs/DE.html#visually-exploring-the-results",
    "href": "labs/DE.html#visually-exploring-the-results",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "7 Visually exploring the results",
    "text": "7 Visually exploring the results\nWe will create a few plots, by way of example, of the results for the “Ri_mock” versus “control_mock” comparison, which we extracted above.\n\n7.1 Volcano plot\nFor a nice overview of the results, we can plot a so-called “volcano plot”.\n\n\n7.2 Plot specific genes\nWe can also create plot of expression levels for individual genes. That is especially interesting for genes with highly significant differential expression.\nLet’s plot the top-5 most significantly differentially expressed genes:\n\n# First, we select the 5 genes with the lowest adjusted p-value:\ntop5 &lt;- row.names(res[order(res$padj)[1:5], ])\n\n\n# Then we create a function to make a plot for a single gene:\nplotgene &lt;- function(geneID, dds) {\n  \n  d &lt;- plotCounts(dds,\n                  gene = geneID,\n                  intgroup = \"group\",\n                  returnData = TRUE)\n\n  p &lt;- ggplot(d, aes(x = group, y = count)) +\n          geom_point(position = position_jitter(w = 0.1, h = 0)) +\n          labs(title = geneID) +\n          theme_bw()\n  \n  print(p)\n}\n\nFinally, we use sapply() to apply this function to each of our genes in the top5 vector.\n\nnone &lt;- sapply(top5, plotgene, dds)\n\nIf we wanted to, we could easily create plots for 100s of genes, this way.\n\n\n7.3 Heatmap\nWe can create heatmaps with the pheatmap function. Let’s start by creating a function that will plot a heatmap given a vector of gene IDs and a DESeq2 object dds:\n\nplot_heatmap &lt;- function(geneIDs, dds) {\n  \n  ntd &lt;- assay(normTransform(dds))\n  \n  ntd_sel &lt;- ntd[match(geneIDs, rownames(ntd)), ]\n  df_meta &lt;- as.data.frame(colData(dds)[, c(\"AMF\", \"Treatment\")])\n  \n  pheatmap(ntd_sel,\n         cluster_rows = FALSE,\n         cluster_cols = FALSE,\n         show_rownames = FALSE,\n         annotation_col = df_meta)\n}\n\nNow, we can easily create a heatmap for the top-20 most highly differentially expressed genes:\n\ntop20_DE &lt;- row.names(res[order(res$padj)[1:20], ])\nplot_heatmap(top20_DE, dds)\n\nOr for the 20 most highly expressed genes:\n\ntop20_hi_idx &lt;- order(rowMeans(counts(dds, normalized = TRUE)),\n                  decreasing = TRUE)[1:20]\ntop20_hi &lt;- row.names(dds)[top20_hi_idx]\nplot_heatmap(top20_hi, dds)\n\n\n\n7.4 Export the results\nLet’s save the results dataframe to file.\nNote that it will only contain the results for one comparison. Also, if we write the results dataframe to file, we won’t be able to tell from the file what the comparison is, so let’s store that in two columns:\n\nmy_contrast\n\nmy_contrast_pasted &lt;- paste0(my_contrast, collapse = \"_vs_\")\nmy_contrast_pasted\n\n\nres$level1 &lt;- my_contrast[1]\nres$level2 &lt;- my_contrast[2]\nkable(head(res))\n\nNow we can write res to file:\n\nres_file &lt;- file.path(outdir, paste0(my_contrast_pasted, '_all-res.txt'))\n\nwrite.table(res, res_file,\n            sep = '\\t', row.names = TRUE, quote = FALSE)"
  },
  {
    "objectID": "labs/DE.html#de-analysis-with-two-factors",
    "href": "labs/DE.html#de-analysis-with-two-factors",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "8 DE analysis – with two factors",
    "text": "8 DE analysis – with two factors\n\n8.1 Controlling for one factor\nSay we wanted to analyze the effect of “mock” versus “myb” (“Treatment” column) while controlling for the effects of “control” versus “Ri” (“AMF” column).\nLet’s start by turning “Treatment” and “AMF” into factors, and saving a new DESeq2 object:\n\n# Convert Treatment and AMF into factors: \ndds_raw$Treatment &lt;- relevel(factor(dds_raw$Treatment), ref = \"mock\")\ndds_raw$AMF &lt;- relevel(factor(dds_raw$AMF), ref = \"control\")\n\n# Save a new object:\ndds_2f_raw &lt;- dds_raw\n\nTo include both factors, we use a + in the formula. Note that the order matters: using AMF + Treatment, we test for the effect of “Treatment” (the last factor), while controlling for the effect of AMF (the first factor).\n\ndesign(dds_2f_raw) &lt;- formula(~ AMF + Treatment)\n\nRun DESeq with the new design:\n\ndds_2f &lt;- DESeq(dds_2f_raw)\nres &lt;- results(dds_2f)\n\nHow many adjusted p-values were less than 0.1?\n\nsum(res$padj &lt; 0.1, na.rm = TRUE)"
  },
  {
    "objectID": "labs/removed.html",
    "href": "labs/removed.html",
    "title": "Removed bits",
    "section": "",
    "text": "Here is how you could use commands download the files to OSC directly (Click to expand)\n\n\n\n\n\n\nFirst you download the files. This is copied from the code provided on the NCBI website when you click curl — however, that code needs to be preceded by the curl and followed by &gt; ncbi_dataset.zip:\n\ncurl https://api.ncbi.nlm.nih.gov/datasets/v2alpha/genome/accession/GCF_945859705.1/download?include_annotation_type=GENOME_FASTA,GENOME_GFF,RNA_FASTA,CDS_FASTA,PROT_FASTA,SEQUENCE_REPORT &gt; ncbi_dataset.zip\n\nNext, you’ll want to extract the ZIP archive that you downloaded:\n\nunzip ncbi_dataset.zip\n\nNow the files should be there — you can use the tree command instead of ls to get a nice recursive overview:\n\ntree ncbi_dataset\nncbi_dataset/\n└── data\n    ├── assembly_data_report.jsonl\n    ├── dataset_catalog.json\n    └── GCF_945859705.1\n        ├── cds_from_genomic.fna\n        ├── GCF_945859705.1_idEpiBalt1.1_genomic.fna\n        ├── genomic.gff\n        ├── protein.faa\n        ├── rna.fna\n        └── sequence_report.jsonl\n\n2 directories, 8 files\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "labs/data.html#fastq-quality-scores-cont.",
    "href": "labs/data.html#fastq-quality-scores-cont.",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "4 FASTQ quality scores (cont.)",
    "text": "4 FASTQ quality scores (cont.)\nThis numeric quality score is represented in FASTQ files not by the number itself, but by a corresponding “ASCII character”.\nThis allows for a single-character representation of each possible score — as a consequence, each quality score character can conveniently correspond to (& line up with) a base character in the read.\n. . .\n\n\n\nPhred quality score\nError probability\nASCII character\n\n\n\n\n10\n1 in 10\n+\n\n\n20\n1 in 100\n5\n\n\n30\n1 in 1,000\n?\n\n\n40\n1 in 10,000\nI\n\n\n\nIn practice, you almost never have to manually check the quality scores of bases in FASTQ files, but if you do, a rule of thumb is that letter characters are good (Phred of 32 and up)."
  },
  {
    "objectID": "labs/data.html#quality-control-with-fastqc",
    "href": "labs/data.html#quality-control-with-fastqc",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "4 Quality control with FastQC",
    "text": "4 Quality control with FastQC\nA useful example of a genomics tool with a command-line interface is FastQC, for quality control of FASTQ files. It is ubiquitous because nearly all HTS data comes in FASTQ files, and your first step is always to check the quality of the reads.\n\n\n4.1 Running FastQC\nTo run FastQC, use the command fastqc.\nIf you want to analyze one of your FASTQ files with default FastQC settings, a complete FastQC command to do so would simply be fastqc followed by the name of the file2:\nfastqc data/fastq/ERR10802863_R1.fastq.gz\nHowever, an annoying default behavior by FastQC is that it writes its output files in the same dir as where the input files are — in general, it’s not great practice to directly mix your primary data and results like that.\nTo figure out how we can change that behavior, first consider that many commands and bioinformatics tools alike have an option -h and/or --help that will print some usage information to the screen.\n\n\nYour Turn: Try to print FastQC’s help info, and figure out which option you can use to specify an output directory of your choice. (Click for the solution)\n\nfastqc -h and fastqc --help will both work to show the help info.\nYou’ll get quite a bit of output printed to screen, including the snippet about output directories that is reproduced below:\nfastqc -h\n  -o --outdir     Create all output files in the specified output directory.\n                    Please note that this directory must exist as the program\n                    will not create it.  If this option is not set then the \n                    output file for each sequence file is created in the same\n                    directory as the sequence file which was processed.\nSo, you can use -o or equivalently, --outdir to specify an output dir.\n\nNow, let’s try to run FastQC and tell it to use the output dir results/fastqc:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nfastqc: command not found\nHowever, there is a wrinkle, as you can see above. It turns out that a FastQC installation is already available to us at OSC3, but we do have to load it before we can use it. Without going into further details about software usage at OSC, please accept that we load FastQC as follows:\nmodule load fastqc\nNow, let’s try again:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nSpecified output directory 'results/fastqc' does not exist\n\n\n\n Your Turn: What is going on here? Had you perhaps seen this coming given the help text we saw earlier? Can you try to fix the problem? (Click here for hints)\n\nYou can create a new directory by using the buttons in the VS Code side bar, or using the mkdir command — here, try it as mkdir -p followed by the name (path) of the directory you want to create.\n\n\n\nExercise solution (Click to expand)\n\n\nThe problem, as the error fairly clearly indicates, is that the output directory that we specified with --outdir does not currently exist. We might have expected FastQC to be smart/flexible enough to create this dir for us (many bioinformatics tools are), but alas. On the other hand, if we had read the help text clearly, it did warn us about this.\nWith the mkdir command, to create “two levels” of dirs at once, like we need to here (both results and then fastqc within there), we need its -p option:\n\nmkdir -p results/fastqc\n\nAnd for our final try before we give up and throw our laptop out the window:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nStarted analysis of ERR10802863_R1.fastq.gz\nApprox 5% complete for ERR10802863_R1.fastq.gz\nApprox 10% complete for ERR10802863_R1.fastq.gz\nApprox 15% complete for ERR10802863_R1.fastq.gz\n[...truncated...]\nAnalysis complete for ERR10802863_R1.fastq.gz\nSuccess!!\n\n\n\n4.2 FastQC output files\nLet’s take a look at the files in the output dir we specified:\nls -lh results/fastqc\n-rw-r--r-- 1 jelmer PAS0471 241K Jan 21 21:50 ERR10802863_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Jan 21 21:50 ERR10802863_R1_fastqc.zip\n\nThere is a .zip file, which contains tables with FastQC’s data summaries\nThere is an .html (HTML) file, which contains plots — this is what we’ll look at next\n\n\n\n Your Turn: Run FastQC for the corresponding R2 file. Would you use the same output dir? (Click for the solution)\n\nYes, it makes sense to use the same output dir, since as you could see above, the output file names have the input file identifiers in them. As such, we don’t need to worry about overwriting files, and it will be easier to have all the results in a single dir.\nTo run FastQC for the R2 file:\nfastqc --outdir results/fastqc ERR10802863_R2.fastq.gz\nStarted analysis of ERR10802863_R2.fastq.gz\nApprox 5% complete for ERR10802863_R2.fastq.gz\nApprox 10% complete for ERR10802863_R2.fastq.gz\nApprox 15% complete for ERR10802863_R2.fastq.gz\n[...truncated...]\nAnalysis complete for ERR10802863_2.fastq.gz\nls -lh results/fastqc\n-rw-r--r-- 1 jelmer PAS0471 241K Jan 21 21:50 ERR10802863_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Jan 21 21:50 ERR10802863_R1_fastqc.zip\n-rw-r--r-- 1 jelmer PAS0471 234K Jan 21 21:53 ERR10802863_R2_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 244K Jan 21 21:53 ERR10802863_R2_fastqc.zip\n\n\n\n\n4.3 Interpreting FastQC’s output\nFirst, we’ll unfortunately have to download FastQC’s output HTML files4:\n\nFind the FastQC HTML files in the file explorer in the VS Code side bar.\nRight-click on one of them, click Download... and follow the prompt to download the file somewhere to your computer (doesn’t matter where, just make sure you see where it goes).\nRepeat this for the second file\nThen, open your computer’s file browser, find the downloaded files, and double-click on one. It should be opened in your default web browser.\n\nNow, we’ll go through a couple of the FastQC plots/modules, first seeing some example plots with good/bad results for reference.\n\n\nOverview of module results\nFastQC has “pass” (checkmark in green), “warning” (exclamation mark in orange), and “fail” (cross in red) assessments for each module, as you can see below.\nThese are handy and typically at least somewhat meaningful, but it is important to realize that a “warning” or a “fail” is not necessarily the bad news that it may appear to be, because, e.g.:\n\nSome of these modules could perhaps be called overly strict.\nSome warnings and fails are easily remedied or simply not a very big deal.\nFastQC assumes that your data is derived from whole-genome shotgun sequencing, and other types of data, like RNA-seq data, will always trigger a couple of warnings and files based on their characteristics.\n\n\n\n\n\n\n\nBasic statistics\nThis shows, for example, the number of sequences (reads) and the read length range for your file:\n\n\n\n\n\n\nPer base quality sequence quality\nThis figure visualize the mean per-base quality score (y-axis) along the length of the reads (x-axis). Note that:\n\nA decrease in sequence quality along the reads is normal.\nR2 (reverse) reads are usually worse than R1 (forward) reads.\n\n\n\nGood / acceptable:\n\n\n\n\nBad:\n\n\n\n\n\nTo interpret the quality scores along the y-axis, note the color scaling in the graphs (green is good, etc.), and see this table for details:\n\n\n\nPhred quality score\nError probability\nRough interpretation\n\n\n\n\n10\n1 in 10\nterrible\n\n\n20\n1 in 100\nbad\n\n\n30\n1 in 1,000\ngood\n\n\n40\n1 in 10,000\nexcellent\n\n\n\n\n\n\nPer sequence quality scores\nThis shows the same quality scores we saw above, but now simply as a density plot of per-read averages, with the quality score now along the x-axis, and the number of reads with that quality score along the y-axis:\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\n\nSequence length distribution\nWill throw a warning as soon as not all sequences are of the same length (like below), but this is quite normal.\n\n\n\n\n\n\nAdapter content\nChecks for known adapter sequences. When some of the insert sizes are shorter than the read length, adapters can end up in the sequence – these should be removed!\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\n\n\n4.4 Interpreting our FastQC output\n\n\nYour Turn: Open the HTML file for the R1 FASTQ file and go through the modules we discussed above. Can you make sense of it? Does the data look good to you, overall?\n\n\n\n\nYour Turn: Now open the HTML file for the R2 FASTQ file and take a look just at the quality scores. Does it look any worse than the R1?"
  },
  {
    "objectID": "labs/data.html#appendix",
    "href": "labs/data.html#appendix",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "6 Appendix",
    "text": "6 Appendix\n\nBonus exercises\n\n\n Your Turn (Bonus): Explore the assembly FASTA file with grep (Click to see the instructions)\n\ngrep is an incredibly useful Unix command with which you can search files for specific text. By default, it will print lines that match your search in their entirety.\nFor example, we could search the genome for the short sequence ACCGATACGACG:\ngrep \"ACCGATACGACG\" data/ref/GCF_016801865.2.fna\naaaatcgaaaaacgcgTTTACCTTACATTGACAAAGTTGACCGATACGACGGCTCGATGTGCCAAACCGGTCACAAAGTC\nAATATTGACATTTCTTTTGCATTCTTCAGGTTCAGTGACCACAAACGGGACCGATACGACGGCTACCATCGGAATGCACC\nTCAAAATGTGTCAATTAACGTAACTAGATTTTTACGATCATAATAAGTAGATACCGATACGACGGGGCGGCATTTATGCT\nTAAGTAGATACCGATACGACGGGGCGGCATTCATGCTGCTACAGGGCTCAGCGGACCGACAAGCGACTGTGAAACGCAGC\n(Matches should be highlighted in red, but that doesn’t show here, unfortunately)\nOr count the number of times the much shorter sequence GGACC occurs:\ngrep -c \"GGACC\" data/ref/GCF_016801865.2.fna\n120492\nTry to adapt the above example to:\n\nPrint all entry headers in the assembly FASTA file\nCount the number of entry header (= the number of entries) in the assembly FASTA file\n\nDoes the number of entries make sense given how many chromosomes and scaffolds the assembly consists of according to NCBI?\n\n\n\n Bonus exercise solutions (Click to expand)\n\nTo print all FASTA entry headers, simply search for &gt; with grep (since &gt; should not occur in the sequences themselves, which can only be bases or N). Make sure to uses quotes (\"&gt;\")!\ngrep \"&gt;\" data/ref/GCF_016801865.2.fna\n&gt;NC_068937.1 Culex pipiens pallens isolate TS chromosome 1, TS_CPP_V2, whole genome shotgun sequence\n&gt;NC_068938.1 Culex pipiens pallens isolate TS chromosome 2, TS_CPP_V2, whole genome shotgun sequence\n&gt;NC_068939.1 Culex pipiens pallens isolate TS chromosome 3, TS_CPP_V2, whole genome shotgun sequence\n&gt;NW_026292818.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0001, whole genome shotgun sequence\n&gt;NW_026292819.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0002, whole genome shotgun sequence\n&gt;NW_026292820.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0003, whole genome shotgun sequence\n&gt;NW_026292821.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0004, whole genome shotgun sequence\n[...truncated...]\nWe can count the number of header lines by modifying our above command only with the addition of the -c option:\ngrep -c \"&gt;\" data/ref/GCF_016801865.2.fna\n290\n\n\n\nAttribution\n\nSome of the FastQC example plots were taken from here."
  }
]