[
  {
    "objectID": "lectures/rnaseq.html#recap-central-dogma-omics",
    "href": "lectures/rnaseq.html#recap-central-dogma-omics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Recap: central dogma & omics",
    "text": "Recap: central dogma & omics"
  },
  {
    "objectID": "lectures/rnaseq.html#the-transcriptome",
    "href": "lectures/rnaseq.html#the-transcriptome",
    "title": "Transcriptomics with RNA-seq",
    "section": "The transcriptome",
    "text": "The transcriptome\nThe transcriptome is the full set of transcripts expressed by an organism, which:\n\n\nIs not at all stable across time & space in any given organism\n(unlike the genome but much like the proteome)\nVaries both qualitatively (which transcripts are expressed) but especially quantitatively (how much of each transcript is expressed)"
  },
  {
    "objectID": "lectures/rnaseq.html#transcriptomics",
    "href": "lectures/rnaseq.html#transcriptomics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Transcriptomics",
    "text": "Transcriptomics\nTranscriptomics is the study of the transcriptome,\ni.e. the large-scale study of RNA transcripts expressed in an organism.\n\nMany approaches & applications — but most commonly, transcriptomics focuses on:\n\n\nmRNA rather than on noncoding RNA types such as rRNA, tRNA, and miRNA\nQuantifying gene expression levels (& ignoring nucleotide-level variation)\nStatistically comparing expression between groups (treatments, populations, tissues)\n\n\n\n\n\n\nhttps://hbctraining.github.io"
  },
  {
    "objectID": "lectures/rnaseq.html#why-do-transcriptomics",
    "href": "lectures/rnaseq.html#why-do-transcriptomics",
    "title": "Transcriptomics with RNA-seq",
    "section": "Why do transcriptomics?",
    "text": "Why do transcriptomics?\nConsidering…\n\nThat protein production gives clues about the activity of specific biological functions, and the molecular mechanisms underlying those functions;\nThat it is much easier to measure transcript expression than protein expression at scale;\nThe central dogma\n\n\n… we can use gene expression levels as a proxy for protein expression levels and make functional inferences."
  },
  {
    "objectID": "lectures/rnaseq.html#why-do-transcriptomics-cont.",
    "href": "lectures/rnaseq.html#why-do-transcriptomics-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "Why do transcriptomics? (cont.)",
    "text": "Why do transcriptomics? (cont.)\nSpecifically, we can use transcriptomics to:\n\n\nCompare & contrast phenotypic vs. molecular responses/differences\n\n\n\n\nFind the pathways and genes that:\n\nUnderlie phenotypic responses\nExplain differences between groups (treatments, genotypes, sexes, tissues, etc.)\nCan be targeted to enhance or reduce organismal responses to help control pathogens and pests"
  },
  {
    "objectID": "lectures/rnaseq.html#what-is-rna-seq",
    "href": "lectures/rnaseq.html#what-is-rna-seq",
    "title": "Transcriptomics with RNA-seq",
    "section": "What is RNA-seq?",
    "text": "What is RNA-seq?\nRNA-seq is the current state-of-the-art family of methods to study the transcriptome.\nIt involves the random sequencing of millions of transcript fragments per sample.\n\nWe will focus on the most common type of RNA-seq, which:\n\n\nDoes not actually sequence the RNA, but first reverse transcribes RNA to cDNA\nAttempts to sequence only mRNA while avoiding noncoding RNAs (“mRNA-seq”)\nDoes not distinguish between RNA from different cell types (“bulk RNA-seq”)\nUses short reads (≤150 bp) that do not cover full transcripts but do uniquely ID genes"
  },
  {
    "objectID": "lectures/rnaseq.html#other-rna-seq-applications",
    "href": "lectures/rnaseq.html#other-rna-seq-applications",
    "title": "Transcriptomics with RNA-seq",
    "section": "Other RNA-seq applications",
    "text": "Other RNA-seq applications\nRNA-seq data can also be used for applications other than expression quantification:\n\nSNP identification & analysis (for popgen, molecular evolution, functional associations)\n\n\n\nFor organisms without a reference genome: identify genes present in the organism\nFor organisms with a reference genome: discover new genes & transcripts,\nand improve genome annotation\n\n\n\n\nAll in all, RNA-seq is a very widely used technique —\nit constitutes the most common usage of high-throughput sequencing!"
  },
  {
    "objectID": "lectures/rnaseq.html#rna-seq-project-examples",
    "href": "lectures/rnaseq.html#rna-seq-project-examples",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA-seq project examples",
    "text": "RNA-seq project examples\nRNA-seq is also the most common data type I assist with as an MCIC bioinformatician. Some projects I’ve worked on used it to identify genes & pathways that differ between:\n\nMultiple soybean cultivars in response to Phytophtora sojae inoculation; soybean in response to different Phytophtora species and strains (Dorrance lab, PlantPath)\nWheat vs. Xanthomonas with a gene knock-out vs. knock-in (Jacobs lab, PlantPath)\n\n\n\nMated and unmated mosquitos (Sirot lab, College of Wooster)\nTissues of the ambrosia beetle and its symbiotic fungus (Ranger lab, USDA Wooster)\nDiapause-inducing conditions for two pest stink bug species (Michel lab, Entomology)\n\n\n\n\nHuman carcinoma cell lines with vs. without a manipulated gene (Cruz lab, CCC)\nPig coronaviruses with vs. without an experimental insertion (Wang lab, CFAH)\n\n\n\nAnd to improve the annotation of a nematode genome (Taylor lab, PlantPath)"
  },
  {
    "objectID": "lectures/rnaseq.html#experimental-design-groups-replicates",
    "href": "lectures/rnaseq.html#experimental-design-groups-replicates",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\nRNA-seq typically compares groups of samples defined by differences in:\n\nTreatments (e.g. different host plant, temperature, diet, mated/unmated) and/or\nOrganismal variants: ages/developmental stages, sexes, or genotypes (lines/biotypes/subspecies/morphs) and/or\nTissues"
  },
  {
    "objectID": "lectures/rnaseq.html#experimental-design-groups-replicates-1",
    "href": "lectures/rnaseq.html#experimental-design-groups-replicates-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\n\nhttps://github.com/ScienceParkStudyGroup/rnaseq-lesson"
  },
  {
    "objectID": "lectures/rnaseq.html#experimental-design-groups-replicates-2",
    "href": "lectures/rnaseq.html#experimental-design-groups-replicates-2",
    "title": "Transcriptomics with RNA-seq",
    "section": "Experimental design: groups & replicates",
    "text": "Experimental design: groups & replicates\nTo be able to make statistically supported conclusions about expression differences between such groups of samples, we must have biological replication.\nWhen designing an RNA-seq experiment, keep the following in mind:\n\nNumbers of replicates\nThese are typically quite low: 3 replicates per treatment (x tissue x biotype, etc.) is the most common. Not advisable to go lower — if possible, use 4 or 5 replicates.\n\n\n\nStatistical comparison design\nPreferably, keep your design relatively simple with 1-2 independent variables and 2-3 levels for each of them. Specifically, pairwise comparisons are easiest to interpret.\n\n\n\n\n\n\n\n\n\nTechnical replicates?\n\n\nYou won’t need technical replicates that only replicate library prep and/or sequencing, but depending on your experimental design, may want to technically replicate something else."
  },
  {
    "objectID": "lectures/rnaseq.html#from-samples-to-reads-overview-of-steps",
    "href": "lectures/rnaseq.html#from-samples-to-reads-overview-of-steps",
    "title": "Transcriptomics with RNA-seq",
    "section": "From samples to reads: overview of steps",
    "text": "From samples to reads: overview of steps\n\nhttps://sydney-informatics-hub.github.io/training-RNAseq-slides"
  },
  {
    "objectID": "lectures/rnaseq.html#rna-extraction-library-prep",
    "href": "lectures/rnaseq.html#rna-extraction-library-prep",
    "title": "Transcriptomics with RNA-seq",
    "section": "RNA extraction & library prep",
    "text": "RNA extraction & library prep\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary preparation is typically done by sequencing facilities\n\n\n\nThere are two main ways to select for mRNAs, which make up only a few % of RNAs: poly-A selection and ribo-depletion.\n\n\n\nMany samples can be “multiplexed” into a single RNA-seq library\n\n\n\n\n\n\nFig. from Kukurba & Montgomery 2015"
  },
  {
    "objectID": "lectures/rnaseq.html#sequencing-considerations",
    "href": "lectures/rnaseq.html#sequencing-considerations",
    "title": "Transcriptomics with RNA-seq",
    "section": "Sequencing considerations",
    "text": "Sequencing considerations\n\nSequencing technology\n\nIllumina short reads: by far the most common\nPacBio or ONT long reads: consider if sequencing full transcripts (isoforms) is key\n\n\n\n\n\nSingle-end vs. paired-end reads (for Illumina)\n\nPaired-end has limited added value for reference-based, gene-level workflows (but can be key in other scenarios) — but it is still common as prices are often similar\n\n\n\n\n\n\nSequencing “depth” / amount — how many reads per sample\n\nGuidelines highly approximate (cf. in genomics) — depends not just on transcriptome size; also on expression level distribution, expression levels of genes of interest, etc.\nTypical recommendations are 20-50 million reads per sample (more for e.g. transcript-level inferences)"
  },
  {
    "objectID": "lectures/rnaseq.html#sequencing-depth-vs.-replicates",
    "href": "lectures/rnaseq.html#sequencing-depth-vs.-replicates",
    "title": "Transcriptomics with RNA-seq",
    "section": "Sequencing depth vs. replicates",
    "text": "Sequencing depth vs. replicates\nFor statistical power, more replicates are better than a higher sequencing depth:\n\n\nFig. from Liu et al. 2014"
  },
  {
    "objectID": "lectures/rnaseq.html#overview-of-steps",
    "href": "lectures/rnaseq.html#overview-of-steps",
    "title": "Transcriptomics with RNA-seq",
    "section": "Overview of steps",
    "text": "Overview of steps\n\nModified after Kukurba & Montgomery 2015"
  },
  {
    "objectID": "lectures/rnaseq.html#from-reads-to-counts-overview",
    "href": "lectures/rnaseq.html#from-reads-to-counts-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "From reads to counts: overview",
    "text": "From reads to counts: overview\nYou will typically receive a “demultiplexed” (split-by-sample) set of FASTQ files.\nOnce you receive your data, the first series of analysis steps involves going from the raw reads to a count table (which will have a read count for each gene in each sample).\n\n\nThis part is bioinformatics-heavy with large files, a need for lots of computing power such as with a supercomputer, command-line (Unix shell) programs — it specifically involves:\n\n\n\nRead preprocessing\nAligning reads to a reference genome (+ alignment QC)\nQuantifying expression levels\n\n\n\n\n\n\n\nThis can be run using standardized, one-size-fits-all workflows, and is therefore (relatively) suitable to be outsourced to a company, facility, or collaborator."
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-read-pre-processing",
    "href": "lectures/rnaseq.html#reads-to-counts-read-pre-processing",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: Read pre-processing",
    "text": "Reads to counts: Read pre-processing\nRead pre-processing includes the following steps:\n\n\nChecking the quantity and quality of your reads\n\nDoes not change your data, but helps decide next steps / sample exclusion\nAlso useful to check for contamination, library complexity, and adapter content\n\n\n\n\n\nRemoving unwanted sequences\n\nAdapters, low-quality bases, and very short reads\nrRNA-derived reads (optional)\nContaminant sequences (optional)"
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment to a reference genome",
    "text": "Reads to counts: alignment to a reference genome\nThe alignment of reads to a reference genome needs to be “splice-aware”.\n\n\nBerge et al. 2019"
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome-1",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-to-a-reference-genome-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment to a reference genome",
    "text": "Reads to counts: alignment to a reference genome\nAlternatively, you can align to the transcriptome (i.e., all mature transcripts):\n\nBerge et al. 2019"
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-alignment-qc",
    "href": "lectures/rnaseq.html#reads-to-counts-alignment-qc",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: alignment QC",
    "text": "Reads to counts: alignment QC\n\nAlignment rates\nWhat percentage of reads was successfully aligned? (Should be &gt;80%)\n\n\n\n\nAlignment targets\nWhat percentages of aligned reads mapped to exons vs. introns vs. intergenic regions?\n\n\n\n\n\nWhat might cause high intronic mapping rates?\n\nAn abundance of pre-mRNA versus mature-mRNA.\n\n\n\n\n\nWhat might cause high intergenic mapping rates?\n\nDNA contamination or poor genome assembly/annotation quality"
  },
  {
    "objectID": "lectures/rnaseq.html#reads-to-counts-quantification",
    "href": "lectures/rnaseq.html#reads-to-counts-quantification",
    "title": "Transcriptomics with RNA-seq",
    "section": "Reads to counts: quantification",
    "text": "Reads to counts: quantification\nAt heart, a simple counting exercise once you have the alignments in hand.\nBut made more complicated by sequencing biases and multi-mapping reads.\n\n\nCurrent best-performing tools (e.g. Salmon) do transcript-level quantification — even though this is typically followed by gene-level aggregation prior to downstream analysis.\n\n\n\n\n\n\n\n\n\nFast-moving field\n\n\nSeveral very commonly used tools like FeatureCounts (&gt;15k citations) and HTSeq (&lt;18k citations) have become disfavored in the past couple of years, as they e.g. don’t count multi-mapping reads at all."
  },
  {
    "objectID": "lectures/rnaseq.html#a-best-practice-workflow-to-produce-counts",
    "href": "lectures/rnaseq.html#a-best-practice-workflow-to-produce-counts",
    "title": "Transcriptomics with RNA-seq",
    "section": "A best-practice workflow to produce counts",
    "text": "A best-practice workflow to produce counts\nThe “nf-core” initiative (https://nf-co.re) attempts to produce best-practice and automated workflows/pipelines, like for RNA-seq (https://nf-co.re/rnaseq):"
  },
  {
    "objectID": "lectures/rnaseq.html#count-table-analysis-overview",
    "href": "lectures/rnaseq.html#count-table-analysis-overview",
    "title": "Transcriptomics with RNA-seq",
    "section": "Count table analysis: overview",
    "text": "Count table analysis: overview\nThe second part of RNA-seq data analysis involves analyzing the count table.\nIn contrast to the first part, this can be done on a laptop and instead is heavier on statistics, data visualization and biological interpretation.\n\n\nIt is typically done with the R languange, and common steps include:\n\nPrincipal Component Analysis (PCA)\nAssessing overall sample clustering patterns\nDifferential Expression (DE) analysis\nFinding genes that differ in expression level between sample groups (DEGs)\nFunctional enrichment analysis\nSee whether certain gene function groupings are overrepresented among DEGs"
  },
  {
    "objectID": "lectures/rnaseq.html#pca",
    "href": "lectures/rnaseq.html#pca",
    "title": "Transcriptomics with RNA-seq",
    "section": "PCA",
    "text": "PCA\nA PCA analysis will help to visualize overall patterns of similarity among samples,\nfor example whether our groups of interest cluster:\n\n\nFig. 1 from Garrigos et al. 2023"
  },
  {
    "objectID": "lectures/rnaseq.html#differential-expression-de-analysis",
    "href": "lectures/rnaseq.html#differential-expression-de-analysis",
    "title": "Transcriptomics with RNA-seq",
    "section": "Differential expression (DE) analysis",
    "text": "Differential expression (DE) analysis\nA Differential Expression (DE) analysis allows you to test, for every single expressed gene in your dataset, whether it significantly differs in expression level between groups.\n\nTypically, this is done with pairwise comparisons between groups:"
  },
  {
    "objectID": "lectures/rnaseq.html#differential-expression-de-analysis-1",
    "href": "lectures/rnaseq.html#differential-expression-de-analysis-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Differential expression (DE) analysis",
    "text": "Differential expression (DE) analysis\nA Differential Expression (DE) analysis allows you to test, for every single expressed gene in your dataset, whether it significantly differs in expression level between groups.\nTypically, this is done with pairwise comparisons between groups:"
  },
  {
    "objectID": "lectures/rnaseq.html#de-analysis-general-statistical-considerations",
    "href": "lectures/rnaseq.html#de-analysis-general-statistical-considerations",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: general statistical considerations",
    "text": "DE analysis: general statistical considerations\n\nGene count normalization\nTo be able to fairly compare samples, raw gene counts need to be adjusted:\n\nBy library size, which is the total number of gene counts per sample\nBy library composition, e.g. to correct for sample-specific extremely abundant genes that “steal” most of that sample’s counts\n\n\n\n\n\nProbability distribution of the count data\n\nGene counts have higher variance than a Poisson distribution: negative binomial distribution is typically used.\nVariance (“dispersion”) estimates are gene-specific but “borrow” information from other genes (details beyond the scope of this lecture)."
  },
  {
    "objectID": "lectures/rnaseq.html#de-analysis-general-statistical-considerations-cont.",
    "href": "lectures/rnaseq.html#de-analysis-general-statistical-considerations-cont.",
    "title": "Transcriptomics with RNA-seq",
    "section": "DE analysis: general statistical considerations (cont.)",
    "text": "DE analysis: general statistical considerations (cont.)\n\nMultiple-testing correction\n\n10,000+ genes are independently tested during a DE analysis, so there is a dire need for multiple testing correction.\nThe standard method is the Benjamini-Hochberg (BH) method.\n\n\n\n\n\nLog2-fold changes (LFC) as a measure of expression difference\n\nWe’ll discuss this in the lab.\n\n\n\n\n\n\n\n\n\n\n\nR packages to the rescue\n\n\nSpecialized R/Bioconductor packages like DESeq2 and EdgeR make differential expression analysis relatively straightforward and automatically take care of the abovementioned considerations (we will use DESeq2 in the lab)."
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-introduction",
    "href": "lectures/rnaseq.html#functional-enrichment-introduction",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: introduction",
    "text": "Functional enrichment: introduction\nLists of DEGs can be quite long, and it is not always easy to make biological sense of them. Functional enrichment analyses help with this.\nFunctional enrichment analyses check whether certain functional categories of genes are statistically overrepresented among up- and/or downregulated genes.\n\n\nThere are a number of databases that group genes into functional categories, but the two main ones used for enrichment analysis are:\n\nGene Ontology (GO)\nKyoto Encyclopedia of Genes and Genomes (KEGG)"
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-go",
    "href": "lectures/rnaseq.html#functional-enrichment-go",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: GO",
    "text": "Functional enrichment: GO\n\n\n\nGenes are assigned zero, one or more GO “terms”\nHierarchical structure with more specific terms grouping into more general terms\nHighest-level grouping are the three “ontologies”: Biological Process, Molecular Function, Cellular Component\n\n\n\nFig. 4 from Garrigos et al. 2023"
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-kegg",
    "href": "lectures/rnaseq.html#functional-enrichment-kegg",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: KEGG",
    "text": "Functional enrichment: KEGG\nKEGG focuses on pathways for cellular and organismal functions whose genes can be drawn and connected in maps.\n\n\n\n\n\n\n\nRodriguez et al. 2020: “KEGG representation of up-regulated genes related to jasmonic acid (JA) signal transduction pathways (ko04075) in banana cv. Calcutta 4 after inoculation with Pseudocercospora fijiensis. Genes or chemicals up-regulated at any time point were highlighted in green.”"
  },
  {
    "objectID": "lectures/rnaseq.html#functional-enrichment-kegg-1",
    "href": "lectures/rnaseq.html#functional-enrichment-kegg-1",
    "title": "Transcriptomics with RNA-seq",
    "section": "Functional enrichment: KEGG",
    "text": "Functional enrichment: KEGG\n\nRodriguez et al. 2020"
  },
  {
    "objectID": "r_homework.html#r-homework-for-the-week-4-lab",
    "href": "r_homework.html#r-homework-for-the-week-4-lab",
    "title": "R homework",
    "section": "R homework for the week 4 lab",
    "text": "R homework for the week 4 lab\nIf you have limited or no experience with R, I highly recommend that you go through part of the Data Carpentry “Data Analysis and Visualisation in R for Ecologists” lesson.\nAt least make your way through:\n\nThe introductory page\nEpisode 1 (“Before we start”))\nEpisode 2 (“Introduction to R”))\n\nIf you have time, then you can also go through:\n\nEpisode 3 (data frames) — until (not including) the “Formatting dates” section.\nEpisode 4 (tidyverse) — until (not including) the “Split-apply-combine” section.\nEpisode 5 (ggplot) — until (not including) the “Arranging plots” section.\n\nYou can do this homework either with your own R & RStudio installation (the Carpentry lesson contains installation instructions), or use RStudio at OSC (see the instructions below).\nIf you run into any issues when going through this material, or just have questions, don’t hesitate to email Jelmer.\n\n\n\n\n\n\nNot sure if you know enough R to skip this?\n\n\n\nThe best way to find out is to take a look at the material!"
  },
  {
    "objectID": "r_homework.html#start-an-rstudio-session-at-osc",
    "href": "r_homework.html#start-an-rstudio-session-at-osc",
    "title": "R homework",
    "section": "Start an RStudio session at OSC",
    "text": "Start an RStudio session at OSC\nIn case you want to use RStudio at the Ohio Supercomputer Center (OSC) for your homework, follow these instructions to get started:\n\nLog in to OSC at https://ondemand.osc.edu\nClick on Interactive Apps (top bar) and then RStudio Server (all the way at the bottom)\nFill out the form as follows:\n\nCluster: Pitzer\nR version: 4.3.0\nProject: PAS2250\nNumber of hours: 4\nNode type: any\nNumber of cores: 2\n\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nClick the big blue Launch button at the bottom\nNow, you should be sent to a new page with a box at the top for your RStudio Server “job”, which should initially be “Queued” (waiting to start).\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nYour job should start running very soon, with the top bar of the box turning green and saying “Running”.\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nClick Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open in a new browser tab. You’re ready to go!\n\n\n\n\n\n\n\n\nHaving trouble installing the tidyverse package?\n\n\n\nIf you are using RStudio at OSC and the installation of the tidyverse package (or another package) with install.packages() fails, please load the packages that the Carpentries lesson uses as follows (no installation needed):\n\ncustom_library &lt;- \"/fs/scratch/PAS2250/ENT6703/share/rlib\"\nlibrary(tidyverse, lib.loc = custom_library)\nlibrary(hexbin, lib.loc = libdir)\nlibrary(patchwork, lib.loc = libdir)\nlibrary(RSQLite, lib.loc = libdir)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jelmer’s guest lectures in ENTMLGY 6703, SP24",
    "section": "",
    "text": "Schedule\n\n\n\nWeek\nDate\nModule\nTopic & link\n\n\n\n\n3\nJan 25th\nHigh-throughput sequencing (HTS)\nLecture: High-throughput sequencing & genomes\n\n\n3\nJan 26th\nHigh-throughput sequencing (HTS)\n- Lab part 1: Computational infrastructure- Lab part 2: Working with genome and HTS data\n\n\n4\nFeb 1st\nRNA-seq\nLecture: RNA-seq\n\n\n4\nFeb 2nd\nRNA-seq\nLab: Differential expression analysis\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "labs/DE.html#introduction",
    "href": "labs/DE.html#introduction",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "1 Introduction",
    "text": "1 Introduction\n\nRecap\nLast week, you explored the RNA-seq reads from the 2023 Molecular Ecology paper “Two avian Plasmodium species trigger different transcriptional responses on their vector Culex pipiens” (link), as well as the Culex pipiens reference genome files.\nIn yesterday’s lecture, you learned about the steps to generate a gene count table from this input data:\n\nRead preprocessing: QC, trimming, and optionally rRNA removal\nAlignment of reads to a reference genome (+ alignment QC)\nQuantification of expression levels\n\n\n\n\nToday\nYou will not go through the above steps yourselves, but will start from the output of step 3: a gene count table. Today, with that gene count table, you will:\n\nCreate an R object that also incorporates the metadata\nPerform exploratory data analysis including a PCA\nRun a Differential Expression (DE) analysis\nExtract and visualize the DE results"
  },
  {
    "objectID": "labs/DE.html#getting-set-up",
    "href": "labs/DE.html#getting-set-up",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "2 Getting set up",
    "text": "2 Getting set up\n\n2.1 Start an RStudio session at OSC\n\nLog in to OSC at https://ondemand.osc.edu\nClick on Interactive Apps (top bar) and then RStudio Server (all the way at the bottom)\nFill out the form as follows:\n\nCluster: Pitzer\nR version: 4.3.0\nProject: PAS2250\nNumber of hours: 4\nNode type: any\nNumber of cores: 2\n\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nClick the big blue Launch button at the bottom\nNow, you should be sent to a new page with a box at the top for your RStudio Server “job”, which should initially be “Queued” (waiting to start).\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nYour job should start running very soon, with the top bar of the box turning green and saying “Running”.\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nClick Connect to RStudio Server at the bottom of the box, and an RStudio Server instance will open in a new browser tab. You’re ready to go!\n\n\n\n\n2.2 Change two settings\nFirst, we’ll prevent R from saving your “Workspace”:\n\nClick Tools (top bar, below your browser’s address bar) &gt; Global Options\nIn the pop-up window (stay on the General tab), change the settings under the “Workspace” heading to:\n\n\n\n\n\n\n\n\n\n\n\n\nWhy are we doing this? (Click to expand)\n\n\n\n\n\nIn short, the default behavior of saving and restoring your “Workspace”, which are all the items (objects) that you create during an R session, is bad practice. Instead, you should recreate your environment from a script and/or saved files with individual pieces of data, as we’ll do today.\n\n\n\n\nSecond, we’ll “update” our pipe symbol from %&gt;% 1 to |&gt; 2:\n\nAgain click Tools &gt; Global Options (you may still be there)\nNow go to Code tab in the side panel on the left, and check the box for Use native pipe operator, |&gt; (requires R 4.1+)\nClick OK at the bottom of the pop-up window\n\n\n\n\n\n\n\n\n\n2.3 Create a new RStudio Project\nUsing an “RStudio Project” will most of all help to make sure your working directory in R is correct. To create a new RStudio Project inside your personal dir in /fs/scratch/PAS2250/ENT6703:\n\nClick File (top bar, below your browser’s address bar) &gt; New Project\nIn the popup window, click Existing Directory.\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nClick Browse... to select your personal dir.\n\n\n\nClick to see a screenshot\n\n\n\n\n\n\n\n\nIn the next window, you should be in your Home directory (abbreviated as ~), from which you can’t click your way to /fs/scratch! Instead, you’ll first have to click on the (very small!) ... highlighted in the screenshot below:\n\n\n\n\n\n\n\nType at least part of the path to your personal dir (which is in /fs/scratch/PAS2250/ENT6703), e.g. as shown below, and click OK:\n\n\n\n\n\n\n\nNow you should be able to browse/click the rest of the way to your personal directory.\nClick Choose to pick your selected directory.\nClick Create Project.\n\n\n\n\n2.4 Create an R script\nWe’re going to write all our code in an R script instead of typing it directly in the console. This helps us to keep track of what we’ve been doing, especially in the longer run, and to be able to re-run our code after modifying input data or one of the lines of code.\nCreate and open a new R script by clicking File (top menu bar) &gt; New File &gt; R Script.\nSave this new script right away by clicking File &gt; Save As, then click New Folder and create a folder named “scripts”. Inside that folder, save the script with a name like lab4_DE.R (the extension for R scripts is .R).\n\n\n\n\n\n\nMake sure to type all the R code below inside your script, and then send it to the console from there.\n\n\n\nYou can send code to the console by pressing Ctrl + Enter on Windows, or Cmd + Return on a Mac.\n\n\n\n\n\n2.5 Load the necessary packages\nIn R, we need to install and then use “packages” (basically, add-ons) to perform specialized tasks like differential expression analysis3. Installing packages is quite straightforward in principle, but in RStudio Server at OSC, there can be some hickups.\nI have therefore created a “library” (a directory with a collection of packages) for you — you can load the packages from that library, without needing to install them yourself. Copy the code below into your R script and then send it to the R console:\n\n# First, we define the dir that has the custom library:\ncustom_library &lt;- \"/fs/scratch/PAS2250/ENT6703/share/rlib\"\n\n# Then, we load all needed R packages from that library:\nlibrary(tidyverse, lib.loc = custom_library)       # Misc. data manipulation and plotting\nlibrary(pheatmap, lib.loc = custom_library)        # Heatmap plot\nlibrary(EnhancedVolcano, lib.loc = custom_library) # Volcano plot\nlibrary(DESeq2, lib.loc = custom_library)          # Differential expression analysis\n\n\n\nThis will produce output in the R console (a lot when loading DESeq2), and some of it in orange, but all should be good unless you see explicit errors at the bottom (Click to see expected output)\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nlibrary(pheatmap)\n\n\nlibrary(EnhancedVolcano)\n\nLoading required package: ggrepel\n\n\n\nlibrary(DESeq2)\n\nLoading required package: S4Vectors\n\n\nLoading required package: stats4\n\n\nLoading required package: BiocGenerics\n\n\n\nAttaching package: 'BiocGenerics'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    intersect, setdiff, union\n\n\nThe following objects are masked from 'package:dplyr':\n\n    combine, intersect, setdiff, union\n\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nThe following objects are masked from 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\n\nAttaching package: 'S4Vectors'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    second, second&lt;-\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, rename\n\n\nThe following object is masked from 'package:tidyr':\n\n    expand\n\n\nThe following object is masked from 'package:utils':\n\n    findMatches\n\n\nThe following objects are masked from 'package:base':\n\n    expand.grid, I, unname\n\n\nLoading required package: IRanges\n\n\n\nAttaching package: 'IRanges'\n\n\nThe following object is masked from 'package:lubridate':\n\n    %within%\n\n\nThe following objects are masked from 'package:dplyr':\n\n    collapse, desc, slice\n\n\nThe following object is masked from 'package:purrr':\n\n    reduce\n\n\nLoading required package: GenomicRanges\n\n\nLoading required package: GenomeInfoDb\n\n\nLoading required package: SummarizedExperiment\n\n\nLoading required package: MatrixGenerics\n\n\nLoading required package: matrixStats\n\n\n\nAttaching package: 'matrixStats'\n\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\n\n\nAttaching package: 'MatrixGenerics'\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\n\nLoading required package: Biobase\n\n\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\n\nAttaching package: 'Biobase'\n\n\nThe following object is masked from 'package:MatrixGenerics':\n\n    rowMedians\n\n\nThe following objects are masked from 'package:matrixStats':\n\n    anyMissing, rowMedians\n\n\n\n\n\n\n2.6 Define our input files\nFor the differential expression analysis, we have the following input files:\n\nMetadata table — The metadata we saw last week (slightly modified), to enable between-treatment comparisons\nGene counts table — Produced by running the nf-core rnaseq workflow on the input data we saw last week\n\n\n# We'll save the paths to our input files for later use\n# ('..' goes up one dir in the dir hierarchy - same as in the Unix shell) \ncount_table_file &lt;- \"../share/results/counts/salmon.merged.gene_counts_length_scaled.tsv\"\nmetadata_file &lt;- \"../share/data/meta/metadata_ed.tsv\""
  },
  {
    "objectID": "labs/DE.html#create-a-deseq2-object",
    "href": "labs/DE.html#create-a-deseq2-object",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "3 Create a DESeq2 object",
    "text": "3 Create a DESeq2 object\nLike in the Culex paper whose data we are working with, we will perform a Principal Component Analysis (PCA) and a Differential Expression (DE) analysis using the popular DESeq2 package (paper, website).\nThe DESeq2 package has its own “object type” (a specific R format type) and before we can do anything else, we need to create a DESeq2 object from three components:\n\nMetadata\nOur independent variables should be in the metadata, allowing DESeq2 to compare groups of samples.\nCount table\nA matrix (table) with one row per gene, and one column per sample.\nA statistical design\nA statistical design formula (basically, which groups to compare) will tell DESEq2 how to analyze the data\n\n\n\n3.1 Metadata\nFirst, we’ll load the metadata file and take a look at the resulting dataframe:\n\n# Read in the count table\nmeta_raw &lt;- read_tsv(metadata_file, show_col_types = FALSE)\n\n\n# Take a look at the first 6 rows\nhead(meta_raw)\n\n# A tibble: 6 × 3\n  sample_id   time  treatment  \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;      \n1 ERR10802882 10dpi cathemerium\n2 ERR10802875 10dpi cathemerium\n3 ERR10802879 10dpi cathemerium\n4 ERR10802883 10dpi cathemerium\n5 ERR10802878 10dpi control    \n6 ERR10802884 10dpi control    \n\n\nWe’ll make sure the data frame is sorted by sample ID, and that the sample IDs are contained in “row names”:\n\nmeta &lt;- meta_raw |&gt;\n  # 1. Sort by the 'sample_id' column\n  arrange(sample_id) |&gt;\n  # 2. Turn the 'sample_id' column into row names:\n  column_to_rownames(\"sample_id\") |&gt;\n  # 3. Turn the 'time' and 'treatment' columns into \"factors\":\n  mutate(time = factor(time, levels = c(\"24hpi\", \"10dpi\")),\n         treatment = factor(treatment, levels = c(\"control\", \"cathemerium\", \"relictum\")))\n\n\n# Take a look at the first 6 rows\nhead(meta)\n\n             time   treatment\nERR10802863 24hpi     control\nERR10802864 24hpi cathemerium\nERR10802865 24hpi    relictum\nERR10802866 24hpi     control\nERR10802867 24hpi cathemerium\nERR10802868 24hpi    relictum\n\n\n\n\n\n\n\n\nIn the two outputs above, note the difference between having the sample IDs as a separate column versus as row names.\n\n\n\n\n\n\n\n\n\nFactors are a common R data type for categorical variables (Click to expand)\n\n\n\n\n\nWe changed the two independent variable columns (time and treatment) into factors, because DESEq2 wants this — this also allowed us to use a custom, non-alphanumeric ordering where 24hpi comes before 10dpi:\n\nhead(meta$time)\n\n[1] 24hpi 24hpi 24hpi 24hpi 24hpi 24hpi\nLevels: 24hpi 10dpi\n\n\n\n\n\n\n\n\n3.2 Count table\nSecond, we will load the count table into R:\n\n# Read in the count table\ncount_df &lt;- read_tsv(count_table_file, show_col_types = FALSE)\n\n\n# Take a look at the first 6 rows\nhead(count_df)\n\n# A tibble: 6 × 24\n  gene_id gene_name ERR10802863 ERR10802864 ERR10802865 ERR10802866 ERR10802867\n  &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 ATP6    ATP6         10275.       8255.       4103.      18615.      11625.  \n2 ATP8    ATP8             3.85        2.92        2.33        7.76        7.01\n3 COX1    COX1         88041.      83394.      36975.     136054.     130863.  \n4 COX2    COX2          8749.       7925.       2901.      16802.      10026.  \n5 COX3    COX3         55772.      50312.      35074.      80510.      69850.  \n6 CYTB    CYTB         38543.      36352.      22185.      62147.      57461.  \n# ℹ 17 more variables: ERR10802868 &lt;dbl&gt;, ERR10802869 &lt;dbl&gt;, ERR10802870 &lt;dbl&gt;,\n#   ERR10802871 &lt;dbl&gt;, ERR10802874 &lt;dbl&gt;, ERR10802875 &lt;dbl&gt;, ERR10802876 &lt;dbl&gt;,\n#   ERR10802877 &lt;dbl&gt;, ERR10802878 &lt;dbl&gt;, ERR10802879 &lt;dbl&gt;, ERR10802880 &lt;dbl&gt;,\n#   ERR10802881 &lt;dbl&gt;, ERR10802882 &lt;dbl&gt;, ERR10802883 &lt;dbl&gt;, ERR10802884 &lt;dbl&gt;,\n#   ERR10802885 &lt;dbl&gt;, ERR10802886 &lt;dbl&gt;\n\n\nHere, too, we have to make several modifications: DESeq2 expects an all-numeric matrix with whole numbers (integers) and with gene IDs as row names:\n\n# Prepare the count table so it can be loaded into DESeq2\ncount_mat &lt;- count_df |&gt;\n  # 1. Turn the 'gene_id' column into row names:\n  column_to_rownames(\"gene_id\") |&gt;\n  # 2. Remove a remaining non-numeric column (which has gene names):\n  select(-gene_name) |&gt;\n  # 3. Round everything to whole numbers:\n  round() |&gt;\n  # 4. Convert it to a formal 'matrix' format:\n  as.matrix()\n\n\n# Take a look at the first 6 rows\nhead(count_mat)\n\n     ERR10802863 ERR10802864 ERR10802865 ERR10802866 ERR10802867 ERR10802868\nATP6       10275        8255        4103       18615       11625        7967\nATP8           4           3           2           8           7           2\nCOX1       88041       83394       36975      136054      130863       62279\nCOX2        8749        7925        2901       16802       10026        6701\nCOX3       55772       50312       35074       80510       69850       42478\nCYTB       38543       36352       22185       62147       57461       28159\n     ERR10802869 ERR10802870 ERR10802871 ERR10802874 ERR10802875 ERR10802876\nATP6       12788        4408       13648       13834        1346       10032\nATP8           2           0           2           1           3           2\nCOX1      109596      106402      104394       77682       38276       78290\nCOX2       11494        6603       11151        9893        1473       13146\nCOX3       68228       71945       66900       52368       14665       37275\nCYTB       46219       52035       46090       35247       17449       38762\n     ERR10802877 ERR10802878 ERR10802879 ERR10802880 ERR10802881 ERR10802882\nATP6         987        1834        3337        5036        1983       11586\nATP8           0           0           0           3           0          27\nCOX1       17785       32099       64490       63960       50965       76113\nCOX2        1141        1907        3439        8334        2063       12752\nCOX3        8797       15948       26278       29997       17802       35419\nCYTB       11177       22262       34368       33401       25854       43912\n     ERR10802883 ERR10802884 ERR10802885 ERR10802886\nATP6       18821        2792       11749        6682\nATP8          40           0           8           1\nCOX1      108343       65829      107741       94682\nCOX2       19148        2713       17947       10656\nCOX3       51441       24915       50029       47750\nCYTB       57844       34616       50587       51198\n\n\n\nCheck that the sample IDs match\nWhen creating the DESeq2 object, DESeq2 assumes that sample IDs in both tables match and are provided in the same order. Let’s make sure this is indeed the case:\n\nall(row.names(meta) == colnames(count_mat))\n\n[1] TRUE\n\n\n\n\n\n\n3.3 Create the DESeq2 object\nWe will create the DESeq2 object using the function DESeqDataSetFromMatrix(), which we will provide with three arguments corresponding to the components discussed above:\n\nThe metadata with argument colData.\nThe count data with argument countData.\nThe statistical design for the DE analysis with argument design. For now, we will specify ~1, which effectively means “no design” — we will change this before the actual DE analysis.\n\n\n# (`dds` is a name commonly used for DESeq2 objects, short for \"DESeq Data Set\")\ndds &lt;- DESeqDataSetFromMatrix(\n  colData = meta,\n  countData = count_mat,\n  design = ~ 1\n  )\n\nconverting counts to integer mode\n\n\nBefore we will run the differential expression analysis, though, we will do a bit of exploratory data analysis using our dds object."
  },
  {
    "objectID": "labs/DE.html#exploratory-data-analysis",
    "href": "labs/DE.html#exploratory-data-analysis",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "4 Exploratory Data Analysis",
    "text": "4 Exploratory Data Analysis\n\n4.1 Our count matrix\nWhat are the number of rows (=number of genes) and columns (=number of samples) of our count matrix?\n\ndim(count_mat)\n\n[1] 18855    22\n\n\nHow many genes have total (= across all samples) counts that are non-zero?\n\nnrow(count_mat[rowSums(count_mat) &gt; 0, ])\n\n[1] 17788\n\n\n\n Your Turn\n\nHow many genes have total counts of at least 10?\n\n\n\nClick to see the solution\n\n\nnrow(count_mat[rowSums(count_mat) &gt;= 10, ])\n\n[1] 16682\n\n\n\n\nBonus: How many genes have mean counts of at least 10?\n\n\n\nClick to see the solution\n\n\n# Now we need to divide by the number of samples, which is the number of columns,\n# which we can get with 'ncol'\nnrow(count_mat[rowSums(count_mat) / ncol(count_mat) &gt;= 10, ])\n\n[1] 12529\n\n\n\n\nHow do the “library sizes”, i.e. the summed per-sample gene counts, compare across samples?\n\ncolSums(count_mat)\n\nERR10802863 ERR10802864 ERR10802865 ERR10802866 ERR10802867 ERR10802868 \n   24297245    17177436    22745445    26849403    21471477    17506262 \nERR10802869 ERR10802870 ERR10802871 ERR10802874 ERR10802875 ERR10802876 \n   24299398    25490128    26534405    22194841    18927885    28804150 \nERR10802877 ERR10802878 ERR10802879 ERR10802880 ERR10802881 ERR10802882 \n    9498249    14807513    20667093    23107463    17545375    19088206 \nERR10802883 ERR10802884 ERR10802885 ERR10802886 \n   21418234    19420046    24367372    25452228 \n\n\n\n Your Turn (Bonus)\nThat’s not so easy to read / interpret. Can you instead get these numbers in millions, rounded to whole numbers, and sorted from low to high?\n\n\nClick to see the solution\n\n\nsort(round(colSums(count_mat) / 1000000))\n\nERR10802877 ERR10802878 ERR10802864 ERR10802868 ERR10802881 ERR10802875 \n          9          15          17          18          18          19 \nERR10802882 ERR10802884 ERR10802867 ERR10802879 ERR10802883 ERR10802874 \n         19          19          21          21          21          22 \nERR10802865 ERR10802880 ERR10802863 ERR10802869 ERR10802885 ERR10802870 \n         23          23          24          24          24          25 \nERR10802886 ERR10802866 ERR10802871 ERR10802876 \n         25          27          27          29 \n\n\n\n\n\n\n\n4.2 Principal Component Analysis (PCA)\nWe will now run a PCA to look for overall patterns of (dis)similarity among samples. This will help us answer questions like:\n\nDo the samples cluster by treatment (infection status) and/or time point?\nWhich of these two variables has a greater effect on overall patterns of gene expression?\nIs there an overall interaction between these two variables?\n\nFirst, we have to normalize the count data to account for differences in library size among samples and “stabilize” the variance among genes4:\n\ndds_vst &lt;- varianceStabilizingTransformation(dds)\n\n\n\n\n\n\n\nThe authors of the study did this as well:\n\n\n\n\nWe carried out a Variance Stabilizing Transformation (VST) of the counts to represent the samples on a PCA plot.\n\n\n\n\nNext, we can run and plot the PCA with a single function call, plotPCA from DESeq2:\n\n# With 'intgroup' we specify the variables (columns) to color samples by\nplotPCA(dds_vst, intgroup = c(\"time\", \"treatment\"))\n\n\n\nClick to see the plot\n\n\n\n\n\n\n\n\n\n\n\n\n Your Turn\n\nBased on our PCA plot, try to answer the three questions asked at the beginning of this PCA section.\nHow does our plot compare to the PCA plot in the paper (Figure 1), in terms of the conclusions you just drew in the previous exercise.\n\n\n\nClick to see the paper’s Figure 1\n\n\n\n\n\n\nBonus: Compare the PCA plot with different numbers of included genes (Hint: figure out how to do so by looking at the help by running ?plotPCA)\nBonus: Customize the PCA plot — e.g. can you “separate” treatment and time point (different shapes for one variable, and different colors for the other), like in Fig. 1 of the paper?\n\n\n\nClick to see some hints for PCA plot customization\n\nTo expand on the point of the exercise: in the plot we made above, each combination of time point and treatment has a distinct color — it would be better to use point color only to distinguish one of the variables, and point shape to distinguish the other variable (as was also done in the paper’s Fig. 1).\nTo be able to customize the plot properly, we best build it from scratch ourselves, rather than using the plotPCA function. But then how do we get the input data in the right shape?\nA nice trick is that we can use returnData = TRUE in the plotPCA function, to get plot-ready formatted data instead of an actual plot:\n\npca_df &lt;- plotPCA(dds_vst, ntop = 500,\n                  intgroup = c(\"time\", \"treatment\"), returnData = TRUE)\n\nWith that pca_df dataframe in hand, it will be relatively straightforward to customize the plot, if you know some ggplot2.\n\n\n\nClick to see a possible solution\n\nFirst, we’ll get the data in the right format, as explained in the hint:\n\npca_df &lt;- plotPCA(dds_vst, ntop = 500,\n                  intgroup = c(\"time\", \"treatment\"), returnData = TRUE)\n\nSecond, we’ll extract and store the percentage of variance explained by different principal components, so we can later add this information to the plot:\n\npct_var &lt;- round(100 * attr(pca_df, \"percentVar\"), 1)\npct_var\n\n[1] 85.3  3.1\n\n\nNow we can make the plot:\n\nggplot(pca_df,\n       aes(x = PC1, y = PC2, color = treatment, shape = time)) +\n  geom_point(size = 5) +\n  labs(x = paste0(\"PC1 (\", pct_var[1], \"%)\"),\n       y = paste0(\"PC2 (\", pct_var[2], \"%)\")) +\n  scale_color_brewer(palette = \"Dark2\", name = \"Infection status\") +\n  scale_shape(name = \"Time points\") +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "labs/DE.html#differential-expression-de-analysis",
    "href": "labs/DE.html#differential-expression-de-analysis",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "5 Differential Expression (DE) analysis",
    "text": "5 Differential Expression (DE) analysis\n\n5.1 Figuring out how to do the analysis\nFirst, let’s see how the DE analysis was done in the paper:\n\nThen, we used the DESeq2 package (Love et al., 2014) to perform the differential gene expression analysis comparing: (i) P. relictum-infected mosquitoes vs. controls, (ii) P. cathemerium-infected mosquitoes vs. controls, and (iii) P. relictum-infected mosquitoes vs. P. cathemerium-infected mosquitoes.\n\nThis is not terribly detailed and could be interpreted in a couple of different ways. For example, they may have compared infection statuses by ignoring time points or by controlling for time points (and there are different ways to do the latter).\nIgnoring time would mean analyzing the full dataset (all time points) while only using the infection status as an independent variable, i.e. the design ~treatment.\n\n Your turn\nGiven the PCA results, do you think that ignoring the time variable is a good idea?\n\nControlling for time can additionally be done in two ways:\n\nA two-factor analysis: ~ time + treatment\nPairwise comparisons between each combination of time and treatment (we’ll see below how we can do that)\n\nIf we take a look at Table 1 with the DE results, it will become clearer how they did their analysis:\n\n\n\n\n\n\n Your Turn\nHow do you interpret this: did they run pairwise comparisons or a two-factor model?\n\n\nClick to see the answer\n\nIt looks like they performed pairwise comparisons between each combination of time and treatment.\n\n\nThat brings us a step closer, but pairwise comparisons with &gt;1 independent variable can (also!) be done in two ways:\n\nAfter subsetting the dataset to each combination of time and treatment.\nAfter creating a single, combined independent variable that is a combination of time and treatment.\n\nThe latter method is the more common one, and is what we will do below5.\n\n\n\n5.2 Setting the statistical design\nWe will now create a new variable that is a combination of treatment and time, and call it group:\n\n# Create a combined variable called 'group':\ndds$group &lt;- factor(paste(dds$treatment, dds$time, sep = \"_\"))\n\n# Which unique values does 'group' have, and how many samples are in each?\ntable(dds$group)\n\n\ncathemerium_10dpi cathemerium_24hpi     control_10dpi     control_24hpi \n                4                 3                 4                 3 \n   relictum_10dpi    relictum_24hpi \n                4                 4 \n\n\nNext, we set the analysis design:\n\n# Note: the symbol before 'group' is a tilde, ~ \ndesign(dds) &lt;- ~ group\n\nNow we’re ready to run the DE analysis!\n\n\n\n5.3 Running the DE analysis\nWhile we had to do a lot of prep to get here, actually running the DE analysis is very simple:\n\n# We are assigning the output back to the same `dds` object - the DE results are added to it\ndds &lt;- DESeq(dds)\n\nestimating size factors\n\n\nestimating dispersions\n\n\ngene-wise dispersion estimates\n\n\nmean-dispersion relationship\n\n\nfinal dispersion estimates\n\n\nfitting model and testing\n\n\nThe DESeq() function is a wrapper that performs three steps (functions) consecutively:\n\nestimateSizeFactors() — “Normalization” by library size and composition.\nestimateDispersions() — Estimate gene-wise dispersion (variance in counts).\nnbinomWaldTest(ddsObj) — Fit the negative binomial GLM and calculate test statistics\n\nA key thing to understand is that above, DESeq2 automatically performed pairwise comparisons between each of the (6) levels of the group variable. This means that for any individual gene, it tested whether the gene is differentially expressed separately for each of these pairwise comparisons."
  },
  {
    "objectID": "labs/DE.html#extracting-the-de-results",
    "href": "labs/DE.html#extracting-the-de-results",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "6 Extracting the DE results",
    "text": "6 Extracting the DE results\nDESeq2 stores the results as a separate table for each pairwise comparison, and now, we’ll extract one of these.\n\n6.1 The results table\nWe can extract the results for one pairwise comparison (which DESeq2 refers to as a contrast) at a time, by specifying it with the contrast argument as a vector of length 3:\n\nThe focal independent variable (here, group)\nThe first (reference) level of the independent variable (in the example below, relictum_24hpi)\nThe second level of the independent variable (in the example below, control_24hpi)\n\n\nfocal_contrast &lt;- c(\"group\", \"relictum_24hpi\", \"control_24hpi\")\nres_rc24 &lt;- results(dds, contrast = focal_contrast)\n\nhead(res_rc24)\n\nlog2 fold change (MLE): group relictum_24hpi vs control_24hpi \nWald test p-value: group relictum_24hpi vs control_24hpi \nDataFrame with 6 rows and 6 columns\n       baseMean log2FoldChange     lfcSE      stat    pvalue      padj\n      &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;\nATP6  7658.0445      -0.416305  0.609133 -0.683438 0.4943300  0.776172\nATP8     4.9196      -1.311116  1.388811 -0.944057 0.3451406        NA\nCOX1 75166.8670      -0.590935  0.282075 -2.094958 0.0361747  0.208045\nCOX2  7807.1848      -0.610152  0.578401 -1.054893 0.2914743  0.615249\nCOX3 41037.7359      -0.400173  0.251760 -1.589498 0.1119479  0.388880\nCYTB 36916.6130      -0.501653  0.261927 -1.915242 0.0554617  0.266528\n\n\nWhat do the columns in this table contain?\n\nbaseMean: Mean expression level across all samples.\nlog2FoldChange: The “log2-fold change” of gene counts between the compared levels.\nlfcSE: The uncertainty in terms of the standard error (SE) of the log2-fold change estimate.\nstat: The value for the Wald test’s test statistic.\npvalue: The uncorrected p-value from the Wald test.\npadj: The multiple-testing corrected p-value (i.e., adjusted p-value).\n\n\n\n\n\n\n\nMultiple testing correction\n\n\n\nBecause we are testing significance for many genes, we need to correct for multiple testing. DESeq2 uses the Benjamini-Hochberg False Discovery Rate (FDR) correction. For more info, see this StatQuest video.\n\n\n\n\n\n\n\n\nLog2-fold changes (LFCs)\n\n\n\nIn RNA-seq, log2-fold changes (LFCs) are the standard way of representing the magnitude (effect size) of expression level differences between two groups of interest. With A and B being the compared sample groups, the LFC is calculated as:\nlog2(mean of A / mean of B)\nDue the log-transformation, the LFC also increase more slowly than a raw fold-change:\n\nAn LFC of 1 indicates a 2-fold difference\nAn LFC of 2 indicates a 4-fold difference\nAn LFC of 3 indicates a 8-fold difference\n\nA nice property of LFC is that decreases and increases in expression are expressed symmetrically:\n\nAn LFC of 1 means that group A has a two-fold higher expression that group B\nAn LFC of -1 means that group A has a two-fold lower expression that group B\n\n\n\n\n Your Turn (Bonus)\nBased on the above, or your knowledge of log-transformations, what do you expect the following to return:\n\n# In the context of a LFC, these 2 numbers would be mean expression levels in 2 groups\nlog2(8 / 2)\nlog2(2 / 8)\n\n\n\nClick to see the solution\n\n\nA fold-change of 4 (8/2) is a LFC of 2:\n\n\nlog2(8 / 2)\n\n[1] 2\n\n\n\nA fold-change of 0.25 (2/8) is a LFC of -2:\n\n\nlog2(2 / 8)\n\n[1] -2\n\n\n\n\n\n\n\n6.2 Numbers of DEGs\nHow many adjusted p-values were less than 0.05 (i.e., significant)?\n\n# (We need 'na.rm = TRUE' because some p-values are 'NA')\n# (If we don't remove NAs from the calculation, sum() will just return NA)\nsum(res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 801\n\n\nSo, we have 801 Differentially Expressed Genes (DEGs) for this specific pairwise comparison.\n\n Your Turn\nThe paper’s Table 1 (which we saw above) reports the number of DEGs for a variety of comparisons.\n\nHow does the number of DEGs we just got compare to what they found in the paper for this comparison?\nThe table also reports numbers of up- and downregulated genes separately. Can you find this out for our DEGs?\n\n\n\nClick to see the solution\n\n\nSolution using tidyverse/dplyr:\n\n\n# First we need to convert the results table into a regular data frame\nas.data.frame(res_rc24) |&gt;\n  # Then we only select the rows/genes that are significant\n  filter(padj &lt; 0.05) |&gt;\n  # If we run count() on a logical test, we get the nrs. that are FALSE v. TRUE\n  dplyr::count(log2FoldChange &gt; 0)\n\n  log2FoldChange &gt; 0   n\n1              FALSE 616\n2               TRUE 185\n\n\n\nSolution using base R:\n\n\n# Down-regulated (relictum &lt; control):\nsum(res_rc24$log2FoldChange &lt; 0 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 616\n\n# Up-regulated (relictum &gt; control):\nsum(res_rc24$log2FoldChange &gt; 0 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 185\n\n\n\n\n\n\nBonus: The table also reports the number of DEGs with an absolute LFC &gt; 1. Can you find this out for our DEGs?\n\n\n\nClick to see the solution\n\n\nSolution using tidyverse/dplyr:\n\n\n# First we need to convert the results table into a regular data frame\nas.data.frame(res_rc24) |&gt;\n  # Then we only select the rows/genes that are significant\n  filter(padj &lt; 0.05, abs(log2FoldChange) &gt; 1) |&gt;\n  # If we run count() on a logical test, we get the nrs. that are FALSE v. TRUE\n  dplyr::count(log2FoldChange &gt; 0)\n\n  log2FoldChange &gt; 0   n\n1              FALSE 159\n2               TRUE  49\n\n\n\nSolution using base R:\n\n\n# Down-regulated (relictum &lt; control):\nsum(res_rc24$log2FoldChange &lt; -1 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 159\n\n# Up-regulated (relictum &gt; control):\nsum(res_rc24$log2FoldChange &gt; 1 & res_rc24$padj &lt; 0.05, na.rm = TRUE)\n\n[1] 49\n\n\n\n\nBonus: Extract the results for one or more other contrasts in the table, and compare the results."
  },
  {
    "objectID": "labs/DE.html#visualizing-the-de-results",
    "href": "labs/DE.html#visualizing-the-de-results",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "7 Visualizing the DE results",
    "text": "7 Visualizing the DE results\nWe will create a few plots for the results for the relictum_24hpi vs. control_24hpi comparison, which we extracted above.\n\n7.1 Volcano plot\nFor a nice overview of the results, we can plot a so-called “volcano plot” using the EnhancedVolcano() function from the package of the same name (see here for a “vignette” / tutorial):\n\nEnhancedVolcano(\n  toptable = res_rc24,      # DESeq2 results to plot   \n  title = \"relictum vs. control at 24 hpi\",\n  x = \"log2FoldChange\",     # Plot the log2-fold change along the x-axis\n  y = \"padj\",               # Plot the p-value along the y-axis\n  lab = rownames(res_rc24), # Use the rownames for the gene labels (though see below)\n  labSize = 0               # Omit gene labels for now\n  )\n\n\n\nClick to see the plot\n\n\n\n\n\n\n\n\n\n\n\n\n Your Turn (Bonus)\nThe EnhancedVolcano() function by default adds gene IDs to highly significant genes, but above, we turned off gene name labeling by setting labSize = 0. I did this because the default p-value cut-off for point labeling is 1e-5 and in this case, that would make the plot quite busy with gene labels. We might want to try a plot with a stricter p-value cut-off that does show the gene labels.\n\nPlay around with the p-value cut-off and the labeling to create a plot you like.\nCheck the vignette, or the help page (accessed by running ?EnhancedVolcano) to see how you can do this.\n\n\n\nClick for an example\n\n\nEnhancedVolcano(\n  toptable = res_rc24,      \n  title = \"relictum vs. control at 24 hpi\",\n  x = \"log2FoldChange\",     \n  y = \"padj\",             \n  lab = rownames(res_rc24), \n  labSize = 4,               # Now we will show the gene labels\n  pCutoff = 10e-10,          # Modify the p-value cut-off\n  subtitle = NULL,           # I'll also remove the silly subtitle\n  caption = NULL,            # ... and the caption\n  )\n\n\n\n\n\n\n\n\n\n\n\nFigure out the identity of the abovementioned log2-fold change outlier.\n(You can do so either by labeling it in the plot, or by filtering the res_rc24 table.)\n\n\n\nClick for the solution for how to lab it in the plot\n\n\n\nEnhancedVolcano(\n  toptable = res_rc24,      \n  title = \"relictum vs. control at 24 hpi\",\n  x = \"log2FoldChange\",     \n  y = \"padj\",             \n  lab = rownames(res_rc24), \n  labSize = 4,               \n  pCutoff = 0.05,            # Modify the p-value cut-off\n  FCcutoff = 20,             # Modify the LFC cut-off\n  )\n\nWarning: Removed 1 rows containing missing values (`geom_vline()`).\n\n\n\n\n\n\n\n\n\n\n\n\nClick for the solution for how to find it in the results table\n\n\n\nas.data.frame(res_rc24) |&gt; filter(log2FoldChange &gt; 20)\n\n              baseMean log2FoldChange    lfcSE     stat       pvalue\nLOC120413430  7.540043       24.46898 5.397990 4.532979           NA\nLOC120431476 39.720375       23.01445 5.301369 4.341228 1.416886e-05\n                     padj\nLOC120413430           NA\nLOC120431476 0.0008584398\n\n\n(Interestingly, there’s a second gene with a LFC &gt; 20 that we hadn’t seen in the plot, because it has NA as the pvalue and padj. See the section “Extra info: NA values in the results table” in the Appendix above for why p-values can be set to NA.)\n\n\n\n\n\n7.2 Plot specific genes\nWe can also create plots of expression levels for individual genes. That is especially interesting for genes with highly significant differential expression. So let’s plot the most highly significant DEG.\nFirst, let’s create a vector with most highly significant DEGs, which we’ll use again for the heatmap below.\n\ntop25_DE &lt;- row.names(res_rc24[order(res_rc24$padj)[1:25], ])\n\ntop25_DE\n\n [1] \"LOC120423768\" \"LOC120423767\" \"LOC120414587\" \"LOC128092307\" \"LOC120431154\"\n [6] \"LOC120427827\" \"LOC120415152\" \"LOC120422735\" \"LOC120431739\" \"LOC120431733\"\n[11] \"LOC120428214\" \"LOC120427588\" \"LOC120415540\" \"LOC120415522\" \"LOC120429000\"\n[16] \"LOC120414889\" \"LOC120413491\" \"LOC120414802\" \"LOC120423826\" \"LOC120429211\"\n[21] \"LOC120425480\" \"LOC120431003\" \"LOC120421894\" \"LOC120423819\" \"LOC128093166\"\n\n\nDESeq2 has a plotting function but the plot is not very good. We will still use that function but just to quickly extract the counts for our gene of interest in the right format for plotting, using returnData = TRUE:\n\nfocal_gene_counts &lt;- plotCounts(\n  dds,\n  gene = top25_DE[1],\n  intgroup = c(\"time\", \"treatment\"),\n  returnData = TRUE\n  )\n\nhead(focal_gene_counts)\n\n                 count  time   treatment\nERR10802863 1543.81532 24hpi     control\nERR10802864 2279.03704 24hpi cathemerium\nERR10802865   25.42295 24hpi    relictum\nERR10802866 1105.75009 24hpi     control\nERR10802867 1199.28425 24hpi cathemerium\nERR10802868   32.14394 24hpi    relictum\n\n\nNow, we can make the plot:\n\nggplot(focal_gene_counts,\n       # Treatment along the x-axis, gene counts along the y, color by treatment:\n       aes(x = treatment, y = count, fill = treatment)) +\n  # Plot separate \"facets\" with the different time points\n  facet_wrap(vars(time)) +\n  # Add a boxplot with a partly transparaent (alpha) color:\n  geom_boxplot(alpha = 0.5, outlier.shape = NA) +\n  # _And_ add individual points:\n  geom_point(size = 4, shape = 21,\n             position = position_jitter(w = 0.1, h = 0)) +\n  # Plot styling (e.g., we don't need a legend)\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\nClick to see the plot\n\n\n\n\n\n\n\n\n\n\n\n\n Your turn\n\nPlot one or a few more of the top-DE genes. Do they have similar expression patterns across treatment and time points as the first one?\n\n\n\nBonus: Plot the gene with the very high LFC value that we saw when making the volcano plot. How would you interpret this?\n\n\n\nClick for the solution\n\n\nfocal_gene_counts &lt;- plotCounts(\n  dds,\n  gene = \"LOC120431476\",\n  intgroup = c(\"time\", \"treatment\"),\n  returnData = TRUE\n  )\n\nggplot(focal_gene_counts, aes(x = treatment, y = count, fill = treatment)) +\n  geom_boxplot(alpha = 0.5, outlier.shape = NA) +\n  geom_point(size = 4, shape = 21, position = position_jitter(w = 0.1, h = 0)) +\n  facet_wrap(vars(time)) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWow! It looks like in every single time + treatment combinations, all but one (or in one case, two) of the samples have zero expression, but there are several extreme outliers.\nOur focal comparison at 24hpi (left panel/facet), and comparing control vs relictum: so it looks like the difference between these two groups is solely due to the one outlier in relictum. Nevertheless, even the multiple-testing corrected p-value (padj) is significant for this gene:\n\nas.data.frame(res_rc24) |&gt;\n  rownames_to_column(\"gene\") |&gt;\n  filter(gene == \"LOC120431476\")\n\n          gene baseMean log2FoldChange    lfcSE     stat       pvalue\n1 LOC120431476 39.72038       23.01445 5.301369 4.341228 1.416886e-05\n          padj\n1 0.0008584398\n\n\nSo, we have to be careful with talking our statistical results at face value, and need to visualize important genes!\n\n\n\n\n\n\n\nOutliers!\n\n\n\nYou may want to check out the solution to the previous exercise, even if you don’t get around to doing it yourself."
  },
  {
    "objectID": "labs/DE.html#in-closing",
    "href": "labs/DE.html#in-closing",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "8 In Closing",
    "text": "8 In Closing\nToday, you have performed several steps in the analysis of gene counts that result from a typical RNA-seq workflow. Specifically, you have:\n\nCreated a DESEq2 object from the gene count data and the experiment’s metadata\nPerformed exploratory data analysis including a PCA\nRan a Differential Expression (DE) analysis with DESeq2\nExtracted, interpreted, and visualized the DE results\n\n\nNext steps\nTypical next steps in such an analysis include:\n\nExtracting, comparing, and synthesizing DE results across all pairwise comparisons (this would for example allow us to make the upset plot in Figure 2 of the paper)\nFunctional enrichment analysis with Gene Ontology (GO) terms, as done in the paper, and/or with KEGG pathways."
  },
  {
    "objectID": "labs/DE.html#appendix",
    "href": "labs/DE.html#appendix",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "9 Appendix",
    "text": "9 Appendix\n\n\n\n\n\n\nNA values in the results table (Click to expand)\n\n\n\n\n\nSome values in the results table can be set to NA for one of the following reasons:\n\nIf a gene contains a sample with a count outlier, both the p-value and adjusted p-value will be set to NA. (DESeq2 performs outlier detection using Cook’s distance.)\nIf all samples have zero counts for a given gene, the baseMean column will be zero, and the log2-fold change estimates, p-value and adjusted p-value will all be set to NA.\nDESeq2 also automatically filters genes with a low mean count in the sense that it does not include them in the multiple testing correction. Therefore, in such cases, the p-value will not be NA, but the adjusted p-value will be.\nBecause we have very low power to detect differential expression for such low-count genes, it is beneficial to remove them prior to the multiple testing correction: that way, the correction becomes less severe for the remaining genes.\n\nLet’s see how many genes have NA p-values:\n\n# Number of genes with NA p-value:\nsum(is.na(res_rc24$pvalue))\n\n[1] 1124\n\n# As a proportion of the total number of genes in the test:\nsum(is.na(res_rc24$pvalue)) / nrow(res_rc24)\n\n[1] 0.05961283\n\n\nAnd NA adjusted p-values:\n\n# Number of genes with NA p-value:\nsum(is.na(res_rc24$padj))\n\n[1] 7283\n\n# As a proportion of the total number of genes in the test:\nsum(is.na(res_rc24$padj)) / nrow(res_rc24)\n\n[1] 0.3862636\n\n\n\n\n\n\n\n\n\n\n\nExporting the results (Click to expand)\n\n\n\n\n\nYou may be wondering how we can save the DE results tables:\n\n# Create the output directory, if necessary:\ndir.create(\"results/DE\", recursive = TRUE, showWarnings = FALSE)\n\n# Write the \nwrite_tsv(as.data.frame(res_rc24), \"results/DE/resultsres_rc24.tsv\")\n\n\n\n\n\n9.1 Heatmaps\nRather than plotting expression levels for many individual genes, we can create “heatmap” plots to plot dozens (possibly even hundreds) of genes at once.\nWe will create heatmaps with the pheatmap function, and let’s make a heatmap for the top-25 most highly significant DEGs for our focal contrast.\nUnlike with some of the functions we used before, we unfortunately can’t directly use our DESeq2 object, but we have to extract and subset the count matrix, and also pass the metadata to the heatmap function:\n\n# We need a normalized count matrix, like for the PCA\n# We can simply extract the matrix from the normalized dds object we created for the PCA\nnorm_mat &lt;- assay(dds_vst)\n\n# In the normalized count matrix, select only the genes of interest\n# We'll reuse the 'top25_DE' vector that we created for the individual gene plots\nnorm_mat_sel &lt;- norm_mat[match(top25_DE, rownames(norm_mat)), ]\n\n# Sort the metadata\nmeta_sort &lt;- meta |&gt;\n  arrange(treatment, time) |&gt;\n  select(treatment, time)\n\nNow we can create the plot:\n\npheatmap(\n  norm_mat_sel,\n  annotation_col = meta_sort,  # Add the metadata\n  cluster_cols = FALSE,        # Don't cluster samples (=columns, cols)\n  show_rownames = FALSE,       # Don't show gene names\n  scale = \"row\",               # Perform z-scaling for each gene\n  )\n\n\n\n\n\n\n\n\nThe z-scaling with scale = will make sure we can compare genes with very different expression levels: after all, we’re interested in relative expression levels across samples/sample groups\npheatmap will by default perform hierarchical clustering both at the sample (col) and gene (row) level, such that more similar samples and genes will appear closer to each other. Above, turned clustering off for samples, since we want to keep them in their by-group order.\n\n\n\n\n\n\nClick to see the plot\n\n\n\n\n\n\n\n\n\n\n\n\n Your Tuen (Bonus)\nMake a heatmap with the top-25 most-highly expressed genes (i.e., genes with the highest mean expression levels across all samples).\n\n\nClick for a hint: how to get that top-25\n\n\ntop25_hi &lt;- names(sort(rowMeans(norm_mat), decreasing = TRUE)[1:25])\n\n\n\n\nClick for the solution\n\n\n# In the normalized count matrix, select only the genes of interest\nnorm_mat_sel &lt;- norm_mat[match(top25_hi, rownames(norm_mat)), ]\n\n# Sort the metadata\nmeta_sort &lt;- meta |&gt;\n  arrange(treatment, time) |&gt;\n  select(treatment, time)\n\n# Create the heatmap\npheatmap(\n  norm_mat_sel,\n  annotation_col = meta_sort,\n  cluster_cols = FALSE,\n  show_rownames = FALSE,\n  scale = \"row\"\n  )"
  },
  {
    "objectID": "labs/DE.html#footnotes",
    "href": "labs/DE.html#footnotes",
    "title": "Week 4 lab: RNA-seq differential expression analysis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAn older pipe, which requires loading an R package to work↩︎\nThe new base R pipe that does not require a package↩︎\nAnd even for more basic tasks, it is common to use packages that are preferred over the functionality that is by default available in R, like in the case of plotting.↩︎\nSpecifically, the point is to remove the dependence of the variance in expression level on its mean, among genes↩︎\nI can’t tell from the paper which method they used↩︎"
  },
  {
    "objectID": "labs/infrastructure.html#introduction-to-the-lab",
    "href": "labs/infrastructure.html#introduction-to-the-lab",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "1 Introduction to the lab",
    "text": "1 Introduction to the lab\nIn today’s lab:\n\nWe will start with learning about a typical “computational infrastructure” to analyze high-throughput sequencing (HTS) data — this page.\nWe will then use that infrastructure to start the exploration of an HTS dataset. We’ll check out reference genome and HTS read files, and perform read quality control – the next page."
  },
  {
    "objectID": "labs/infrastructure.html#computational-infrastructure-overview",
    "href": "labs/infrastructure.html#computational-infrastructure-overview",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "2 Computational infrastructure overview",
    "text": "2 Computational infrastructure overview\nDue in large part to the amount of data involved, a laptop or desktop computer is often not sufficient to work with HTS data, or with large-scale genomics and transcriptomics data more generally.\nAdditionally, most of the specialized programs that help you analyze your data can only be run through a “command-line interface”.\nTherefore, a typical computational infrastructure to do what we may call “command-line genomics” involves:\n\nA supercomputer1 — in our case, the Ohio Supercomputer Center (OSC)\nA text editor — I recommend and will demonstrate VS Code\nThe Unix shell (terminal)\nR (or perhaps Python) for interactive statistical analysis and visualization.\n\nToday, we will go through the first three of the abovementioned items: on this page, we’ll get familiar with them, and on the next page, we’ll apply what we learned to some reference genome and HTS read data.\nIn the lab next week, we will cover the fourth in the context of RNA-seq differential expression analysis.\n\n\n\n\n\n\nSide note: “I don’t think I like coding. Can I avoid all of this?” (Click to expand)\n\n\n\n\n\nIf you will often be doing genomics projects like the ones mentioned above, it’s hard to avoid using this (kind of) infrastructure. But here are some conditions in which you might reasonably avoid it:\n\nYou’re doing a single genomics project, your main research focus is elsewhere\nYou’re willing to outsource part of the analysis\n\nNote that for several types of HTS projects, including those involving metabarcoding or RNA-seq data (as we’ll see next week), the analysis consists of two distinct parts:\n\nThe first is compute-heavy and involves command-line programs; it is also quite standardized, and therefore suitable to be outsourced.\nThe second can be done on a laptop and in terms of coding only requires R\n\nYou could also try a platform like Galaxy, which has a web browser interface and doesn’t require coding — but I wouldn’t recommend this if you’re going to do multiple genomics projects.\n\n\n\n\n\n\n\n\n\nSide note: Advantages of command-line interfaces (Click to expand)\n\n\n\n\n\nAdvantages of Command-Line Interfaces (CLIs) over “Graphical User Interfaces” (GUIs) include:\n\nEfficiency — A CLI allows you to write a simple loop to run it in the same way for many samples.\n(In combination with usage of a supercomputer, you can process all those samples in parallel.)\nReproducibility — You can easily save all commands & scripts, making it straightforward to rerun/adapt an analysis."
  },
  {
    "objectID": "labs/infrastructure.html#the-ohio-supercomputer-center-osc",
    "href": "labs/infrastructure.html#the-ohio-supercomputer-center-osc",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "3 The Ohio Supercomputer Center (OSC)",
    "text": "3 The Ohio Supercomputer Center (OSC)\n\n3.1 Introduction to supercomputers\nA supercomputer is a highly interconnected set of many computer processors and storage units. You can think of it simply as a network of computers — with individual computers called “nodes”.\nSupercomputers are also commonly referred to as High-Performance Computing (HPC) clusters or simply compute clusters. This is what Owens, one of the OSC supercomputers, physically looks like:\n\n\n\nWhy you might need a supercomputer:\n\nOften, your genomics dataset is too large to be handled efficiently, or at all, by a laptop/desktop computer.\nTo speed up long-running analyses by using more computing power, and repeated analyses (like the independent alignment of reads for different samples) by running them in parallel.\nIt’s also a great place to store large amounts of data — and genomics data is often very large.\n\n\n\n\n3.2 Introduction to OSC\n\n\n\nThe Ohio Supercomputer Center (OSC) provides computing resources to researchers (and others) across Ohio. OSC has two supercomputers/clusters (named Owens and Pitzer), and lots of infrastructure for their usage. Research usage is charged at subsidized rates, and in most case, these costs are absorbed at the college level.\n\nThe structure of an OSC supercomputer\nWe can think of a supercomputer as having three main parts:\n\nFile Systems: Where files are stored (these are shared between the two OSC clusters)\nLogin Nodes: The handful of computers everyone shares after logging in\nCompute Nodes: The many computers you can reserve to run your analyses\n\n\n\n\n\n\n\n\n\n\nSide note: What works differently on a supercomputer like at OSC? (Click to expand)\n\n\n\n\n\nCompared to command-line computing on a laptop or desktop, the following aspects are different when working on a supercomputer like at OSC:\n\nLogin versus compute nodes\n“Login nodes”, the nodes you end up on after logging in, are not meant for heavy computing and you have to request access to “compute nodes” to run most analyses.\n“Non-interactive” computing is common\nIt is common to write and “submit” scripts to a queue instead of running programs interactively.\nSoftware\nYou generally can’t install “the regular way”, and a lot of installed software needs to be “loaded” (as we’ll see today).\nOperating system\nSupercomputers run on the Linux operating system\n\n\n\n\n\n\n\n\n3.3 The OSC OnDemand web portal\n Go to https://ondemand.osc.edu and log in with your OSC (not OSU!) credentials.\nYou should see a landing page similar to the one below:\n\n\n\nWe will now go through some of the dropdown menus in the blue bar along the top.\n\nFiles: File system access\nHovering over the Files dropdown menu gives a list of directories (=folders, and “dir” for short) that you have access to. If your account is brand new, you should only two directories listed2:\n\nA Home directory (starts with /users/)\nA project “scratch” directory (starts with /fs/scratch/) PAS2250\n\nSelect the PAS2250 scratch directory, /fs/scratch/PAS2250, where we’ll be working today and next week:\n\n\n\nOnce there, you should see a list of directories and files (here: just a single dir), and you can click on the directories to explore the contents further:\n\n\n\nThis interface is much like the file browser on your own computer, so you can also create, delete, move and copy files and folders, and even upload (from your computer to OSC) and download (from OSC your computer) files3 — see the buttons across the top.\n\n\n Your Turn: Create your own folder (click to see instructions)\n\n\nClick your way into ENT6703 within /fs/scratch/PAS2250 if you’re not already there.\nYou should (at least) see directories/folders named share and jelmer.\nCreate your own folder by clicking the New Directory button at the top.\nPlease give it the exact same name as your OSC username (including any capitalization).\n\n(You can see what your username is by looking at the right side of the blue top bar:)\n\n\n\n\n\n\nClusters: Unix shell access\nInteracting with a supercomputer is most commonly done using a Unix shell, and we’ll learn about the basics of doing so soon. Under the Clusters dropdown menu, you can access a Unix shell either on Owens or Pitzer:\n\n\n\nI’m selecting a shell on the Pitzer supercomputer, which will open a new browser tab looking like this:\n\n\n\nHowever, from now on, we’ll be accessing a Unix shell inside the VS Code text editor, which also gives us some additional functionality in a user-friendly way.\n\n\nInteractive Apps\nWe can access programs with Graphical User Interfaces (GUIs; point-and-click interfaces) via the Interactive Apps dropdown menu — let’s select VS Code using the “Code Server” button:"
  },
  {
    "objectID": "labs/infrastructure.html#the-vs-code-text-editor",
    "href": "labs/infrastructure.html#the-vs-code-text-editor",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "4 The VS Code text editor",
    "text": "4 The VS Code text editor\n\n4.1 What is VS Code?\nVS Code (in full, Visual Studio Code) is basically a fancy text editor.\nTo emphasize the additional functionality relative to basic text editors like Notepad and TextEdit, editors like VS Code are also referred to as “IDEs”: Integrated Development Environments. The RStudio program is another good example of an IDE. For our purposes:\n\nVS code will be our IDE for Unix shell code (this week)\nRStudio will be our IDE for R (in the differential expression lab next week)\n\n\n\n\n4.2 Connecting to VS Code\nBecause Interactive Apps like VS Code and RStudio run on compute nodes (not login nodes), which need to be “reserved”, we have to fill out a form and specify the following details (see also the screenshot below):\n\n\n\n\n\n\n\nOption\nValue\n\n\n\n\nThe OSC Project that should be billed for the compute resource usage\nPAS2250\n\n\nThe Number of hours we want to make a reservation for4\n4\n\n\nThe Working Directory5 for the program\nyour newly-created personal folder in /fs/scratch/PAS2250/ENT6703 (e.g. /fs/scratch/PAS2250/ENT6703/jelmer)\n\n\nThe Codeserver Version\n4.8\n\n\n\n\n\n\nClick on Launch at the bottom, which will send your request to the “compute job” scheduler. First, your job will be “Queued” — that is, waiting for the job scheduler to allocate resources on the compute nodes to it:\n\n\n\nYour job is typically granted resources within a few seconds (the card will then say “Starting”), and be ready for usage (“Running”) in another couple of seconds:\n\n\n\nThen, click on the blue Connect to VS Code button to open VS Code in a new browser tab. When VS Code opens, you may get these two pop-ups — click “Yes” (and check the box) and “Don’t Show Again”, respectively:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 The VS Code User Interface\n\n\n\n\nSide bars\nThe Activity Bar (narrow side bar) on the far left has:\n\nA      (“hamburger menu”), which has menu items like File that you often find in a top bar.\nA      (cog wheel icon) in the bottom, through which you can mainly access settings.\nIcons to toggle (wide) Side Bar options — but we’ll only use the default selection, the Explorer (file browser)\n\n\n\nEditor pane and Welcome document\nThe main part of the VS Code is the editor pane. Here, we can open files like scripts and other types of text files, and images. (Whenever you open VS Code, an editor tab with a Welcome document is automatically opened. This provides some help and some shortcuts like to recently opened files and folders.)\n\n\nTerminal (with a Unix shell)\n Open a terminal by clicking      =&gt; Terminal =&gt; New Terminal.\n\n\n\n Your Turn: Try a few color themes (click to see instructions)\n\n\nAccess the “Color Themes” option by clicking    =&gt; Color Theme.\nTry out a few themes and see what you like!"
  },
  {
    "objectID": "labs/infrastructure.html#the-unix-shell",
    "href": "labs/infrastructure.html#the-unix-shell",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "5 The Unix shell",
    "text": "5 The Unix shell\n\n5.1 What is the Unix shell?\nA computer’s shell is an interface inside a Terminal window that allows you to interact with your computer by typing commands. It is also referred to as the the “command line” — with “command-line tools/programs” being software that is run using shell commands.\nThe Unix shell is the shell of Unix-based operating systems, which include Mac and Linux (but not Windows).\n\n\n\n\n\n\nMany bioinformatics programs are basically specialized commands\n\n\n\nWe’ll now learn a couple of Unix shell commands, to familiarize yourself with working in this environment.\nDoing so is also useful because in many ways, you can think of using a command-line bioinformatics program as using just another Unix command. Therefore, our skills with Unix commands will extend to using command-line bioinformatics tools!\n\n\n\n\n\n5.2 First steps in the Unix shell\n\nThe prompt\nInside your terminal, the “prompt” indicates that the shell is ready for a command. Your prompt at OSC should show the following pieces of information:\n[&lt;username&gt;@&lt;node-name&gt; &lt;working-dir&gt;]$\nFor example:\n[jelmer@p0080 jelmer]$ \nYou type your command line expressions after the dollar sign $, and then press Enter to execute them. When it has finished executing, we’ll get our prompt back and can type a new command.\n\n\n\n\n\n\nHow shell code is shown on this website\n\n\n\n\nThe gray boxes like the ones shown above will be used to show the command line expressions that you should type.\nIn upcoming boxes, the prompt itself ([...]$) will not be shown, but only the command line expressions that you type. This is to save space and to allow you for copy-and-pasting (but I recommend typing!).\nPaler gray boxes (below the boxes with command have & with italic text) show the output of commands.\n\n\n\n\n\nA few simple commands: date, whoami, pwd\nThe Unix shell comes with hundreds of “commands”: small programs that perform specific actions. If you’re familiar with R or Python, a Unix command is like an R/Python function.\nLet’s start with a few simple commands:\n\nThe date command prints the current date and time:\n\ndate\nFri Jan 26 14:31:51 EST 2024\n\nThe whoami (who-am-i) command prints your username:\n\nwhoami\njelmer\n\nThe pwd (Print Working Directory) command prints the path to the directory you are currently located in:\n\npwd\n/fs/scratch/PAS2250/ENT6703/jelmer\nAll 3 of those commands provided us with some output. That output was printed to screen, which is the default behavior for nearly every Unix command.\n\n\n\n\n\n\nWorking directory and paths\n\n\n\n\nWhen working in a Unix shell, you are always “in” a specific directory and this is called your working directory.\nIn a path (= location of a file or directory) such as that output by pwd, directories are separated by forward slashes /. (And a leading forward slash, if present, indicates the computer’s root directory.)\n\n\n\n\n\n\n\n\n\nGeneral shell tips\n\n\n\n\nEverything in the shell is case-sensitive, including commands and file names.\nAvoid spaces in file and directory names! Use e.g. underscores or capitalization to distinguish words.\n\n\n\n\n\n\n\n5.3 cd and command actions & arguments\nIn the above three command line expressions:\n\nWe merely typed a command and nothing else\nThe command provided some information, which was printed to screen\n\nBut many commands perform an action other than providing information. For example, you can use the command cd to Change Directory (i.e. change your working dir). And like many commands that perform an action, cd normally has no output at all.\nLet’s use cd to move to another directory by specifying the path to that directory after the cd command:\ncd /fs/scratch/PAS2250/ENT6703/share\npwd\n/fs/scratch/PAS2250/ENT6703/share\n\n\n\n\n\n\nI will demonstrate “tab completion”!\n\n\n\n\n\n\nIn more abstract terms, what we did above was to provide cd with an argument, namely the path of the dir to move to. Arguments generally tell commands what file or directory to operate on.\nAs we’ve seen, then, cd gives no output when it succesfully changed the working directory. But let’s also see what happens when it does not succeed — it gives an error:\ncd /fs/Scratch/PAS2250\nbash: cd: /fs/Scratch/PAS2250: No such file or directory\n\n\nYour Turn: What was the problem with the path we specified? (Click to see the answer)\n\nWe used a capital S in /Scratch/ — this should have been /scratch/.\nAs pointed out above, paths (dir and file specifications) are case-sensitive on Unix systems!\n\n\n\n\n5.4 ls and command options\n\nThe default behavior of ls\nThe ls command, short for “list”, will list files and directories:\nls\ndata  README.md\n(You should still be in /fs/scratch/PAS2250/ENT6703/share. If not, cd there first.)\n\n\n\n\n\n\nSide note: ls output colors (click to expand)\n\n\n\n\n\nUnfortunately, the ls output shown above does not show the different colors you should see in your shell — here are some of the most common ones:\n\nEntries in blue are directories (like data and metadata above)\nEntries in black are regular files (like README.md above)\nEntries in red are compressed files (we’ll see an example soon).\n\n\n\n\nThis default way that ls shows the output can be changed by providing ls with options.\n\n\nOptions (to ls)\nIn general, whereas arguments tell a command what to operate on, options will modify its behavior. For example, we can call ls with the option -l (a dash followed by a lowercase L):\nls -l \ntotal 17\ndrwxr-xr-x 5 jelmer PAS0471 4096 Jan 21 12:39 data\n-rw-r--r-- 1 jelmer PAS0471 1502 Jan 22 11:04 README.md\nNotice that it lists the same items as our first ls call above, but printed in a different format: one item per line, with additional information included, such as the date and time each file was last modified, and the file sizes in bytes (to the left of the date).\nLet’s add another option, -h:\nls -l -h\ntotal 17K\ndrwxr-xr-x 5 jelmer PAS0471 4.0K Jan 21 12:39 data\n-rw-r--r-- 1 jelmer PAS0471 1.5K Jan 22 11:04 README.md\n\n\nYour Turn: What is different about the output, and what do you think that means? (Click to see the answer)\n\nThe only difference is in the format of the column reporting the sizes of the items listed.\nWe now have “Human-readable filesizes” (hence -h), where sizes on the scale of kilobytes will be shown with Ks, of megabytes with Ms, and of gigabytes with Gs. That can be really useful especially for very large files.\n\nConveniently, options can be pasted together as follows:\nls -lh\n\n\nCombining options and arguments\nArguments to ls should be dirs or files to operate on. For example, if we wanted to see what’s inside the data dir, instead of inside our working dir, we could type:\nls data\nfastq  meta  ref\nThe data dir appears to contain three (sub)dirs with different kinds of data. We’ll talk in detail about that later, but for now let’s look inside the fastq dir:\nls data/fastq\nERR10802863_R1.fastq.gz  ERR10802865_R2.fastq.gz  ERR10802868_R1.fastq.gz  ERR10802870_R2.fastq.gz  ERR10802875_R1.fastq.gz  ERR10802877_R2.fastq.gz  ERR10802880_R1.fastq.gz  ERR10802882_R2.fastq.gz  ERR10802885_R1.fastq.gz\nERR10802863_R2.fastq.gz  ERR10802866_R1.fastq.gz  ERR10802868_R2.fastq.gz  ERR10802871_R1.fastq.gz  ERR10802875_R2.fastq.gz  ERR10802878_R1.fastq.gz  ERR10802880_R2.fastq.gz  ERR10802883_R1.fastq.gz  ERR10802885_R2.fastq.gz\nERR10802864_R1.fastq.gz  ERR10802866_R2.fastq.gz  ERR10802869_R1.fastq.gz  ERR10802871_R2.fastq.gz  ERR10802876_R1.fastq.gz  ERR10802878_R2.fastq.gz  ERR10802881_R1.fastq.gz  ERR10802883_R2.fastq.gz  ERR10802886_R1.fastq.gz\nERR10802864_R2.fastq.gz  ERR10802867_R1.fastq.gz  ERR10802869_R2.fastq.gz  ERR10802874_R1.fastq.gz  ERR10802876_R2.fastq.gz  ERR10802879_R1.fastq.gz  ERR10802881_R2.fastq.gz  ERR10802884_R1.fastq.gz  ERR10802886_R2.fastq.gz\nERR10802865_R1.fastq.gz  ERR10802867_R2.fastq.gz  ERR10802870_R1.fastq.gz  ERR10802874_R2.fastq.gz  ERR10802877_R1.fastq.gz  ERR10802879_R2.fastq.gz  ERR10802882_R1.fastq.gz  ERR10802884_R2.fastq.gz\nAh, FASTQ files! These contain our sequence data, and we’ll go and explore them in a bit.\nFinally, we can combine options and arguments, and let’s do so take a closer look at our dir with FASTQ files — now the -h option is especially useful and allows us see that the FASTQ files are 21-22 Mb in size:\nls -lh data/fastq\ntotal 941M\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:34 ERR10802863_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802863_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:34 ERR10802864_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802864_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802865_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802865_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:34 ERR10802866_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:34 ERR10802866_R2.fastq.gz\n[...output truncated...]\n\n\n Your Turn: List the files in the data/ref dir. What are the file sizes? (Click for the solution)\n\nls -lh data/ref\ntotal 670M\n-rw-r--r-- 1 jelmer PAS0471 547M Jan 20 22:34 GCF_016801865.2.fna\n-rw-r--r-- 1 jelmer PAS0471 123M Jan 20 22:34 GCF_016801865.2.gtf\nThe .fna file (this is the genome assembly nucleotide FASTA file) is 547 Mb (not bases but bytes!), and the .gtf file (this is the annotation file) is 123 Mb.\n\n\n\n\n\n5.5 A few more general shell tips\n\nCommand history: If you hit the ⇧ (up arrow) once, you’ll retrieve your most recent command, and if you keep hitting it, you’ll go further back. The⇩ (down arrow) will go the other way: towards the present.\nYour cursor can be anywhere on a line (not just at the end) when you press Enter to execute a command!\nIf your prompt is missing, the shell is either still busy executing your command, or you typed an incomplete command. To abort in either of these two scenarios, press Ctrl+C and you’ll get your prompt back.\nAnything that comes after a # is considered a comment instead of code!\n\n# This entire line is a comment - you can run it and nothing will happen\npwd    # 'pwd' will be executed but everything after the '#' is ignored\n/fs/scratch/PAS2250/ENT6703/jelmer\n\n\n\n Your Turn: Move into your personal directory, and then back into the share dir (Click for the solution)\n\ncd /fs/scratch/PAS2250/ENT6703/jelmer\ncd /fs/scratch/PAS2250/ENT6703/share\n\n\n\n Your Turn: Use the command history (arrows) to repeat the previous exercise without typing anything.\n\n\n\n\n\n Your Turn (Bonus): Two periods .. means the directory “one level up” (towards the computer’s root dir): running cd .. will move you one dir level up. Try to make use of this move into your personal dir and back to share again, instead of using the “full paths” like above. (Click for the solution)\n\ncd ../jelmer\ncd ../share\nA little more detail about this, for those that are interested:\n\nPaths that start with a /, i.e. paths that start from the computer’s root directory, are called “absolute” or “full paths” (you can think of them as GPS coordinates, they work regardless of where you are located).\nPaths that do not start with / (are always supposed to) start from your current working directory and are called “relative paths”. We’ve used them above with ls data and ls data/fastq. The .., then, is a mechanism to go “up” in the dir hierarchy when using a relative path! They work more like directions along the lines of “take the second left” in the sense that they depend on your current location.\n\n\n\n\n Your Turn (Bonus): Practice aborting commands (Click for the instructions)\n\nTo simulate a long-running command that we may want to abort, we can use the sleep command, which will make the computer wait for a specified amount of time until giving your prompt back:\nsleep 60s\nRun that command and instead of waiting for the full 60 seconds, press Ctrl + C to get your prompt back sooner!\nOr, an example of an incomplete command (an opening parenthesis ():\n(\nRun the code above, see what happens, and press Ctrl + C to get your prompt back."
  },
  {
    "objectID": "labs/infrastructure.html#appendix-further-learning",
    "href": "labs/infrastructure.html#appendix-further-learning",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "6 Appendix: Further learning",
    "text": "6 Appendix: Further learning\n\nResources for further learning\n\nOSC\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A01_osc.html\nOSC’s online asynchronous courses\nOSC’s new User Resource Guide\n\nVS Code\n\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A02_vscode.html\n\nUnix shell\n\nOSC’s UNIX Basics\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A03_shell1.html\nhttps://mcic-osu.github.io/rnaseq-intro/modules/A04_shell2.html\nhttps://www.learnenough.com/command-line-tutorial\nhttps://cvw.cac.cornell.edu/Linux/\n\nOSU courses\n\nGenome Analytics course (HCS 7004)\nMicrobiome Informatics course (MICRBIO 8161)\nComputing Skills for Omics Data (PLNTPTH 5006, taught as IS in SP24 2nd session as PLNTPTH 6193)\n\nOnline workshop/course material\n\nWorkshop “Command line basics for genomic analysis at OSC” (Mike Sovic & Jelmer Poelstra, 2022)\nCourse “Practical Computing Skills for Biologists” (Jelmer Poelstra, 2021)\n\nBooks\n\nA Primer for Computational Biology (Shawn T. O’ Neil, 2019) (available online!)\nComputing Skills for Biologists: A Toolbox (Wilmes & Allesino, 2019)\nBioinformatics Data Skills (Vince Buffalo, 2015)\nThe Linux Command Line (William Shotts, 2019)"
  },
  {
    "objectID": "labs/infrastructure.html#footnotes",
    "href": "labs/infrastructure.html#footnotes",
    "title": "Week 3 lab — part 1:Computational Infrastructure",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCloud computing is an alternative, but won’t be covered here.↩︎\nIf you were added to another project than PAS2250, you should have at least 3: PAS2250 does not have a “project dir”, but most projects do↩︎\nThough this is not meant for large (&gt;1 GB) transfers. Different methods are available for those but are outside the scope of this introductions.↩︎\nNote that we’ll be kicked off as soon as that amount of time has passed!↩︎\nThis will be your starting location in the file system, we’ll talk more about working dirs in a little bit.↩︎"
  },
  {
    "objectID": "labs/data.html#introduction",
    "href": "labs/data.html#introduction",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "1 Introduction",
    "text": "1 Introduction\n\n1.1 Our dataset\nWe will work with RNA-seq data from the paper “Two avian Plasmodium species trigger different transcriptional responses on their vector Culex pipiens”, published late last year in Molecular Ecology (link):\n\n\n\n\n\nThis paper uses RNA-seq data to study gene expression in Culex pipiens mosquitos infected with malaria-causing Plasmodium protozoans — specifically, it compares mosquitos according to:\n\nInfection status: Plasmodium cathemerium vs. P. relictum vs. control\nTime after infection: 24 h vs. 10 days vs. 21 days\n\n\n\n\n1.2 What we will do\nToday we’ll focus on the general aspects of reference genomes and HTS data — specifically, we will:\n\nSee how you can find a reference genome and the associated files\nExplore the reference genome files\nExplore our HTS reads\nPerform quality-control on some of our reads with a command-line tool, FastQC\n\nNext week, after covering RNA-seq methodology in the lecture, we will run a differential expression analysis.\n\n\n\n\n\n\nWhat we won’t do in either week’s lab\n\n\n\nNext week’s differential expression analysis (in R) will start with a “gene count table”. Several steps are needed to produce that count table from the FASTQ files that we’ll explore today — next week, you’ll learn more about what those steps are, but in the interest of time, we won’t run them ourselves.\n\n\n\n\n\n1.3 Getting your own copy of the files\nThe main data files in a reference-based HTS project are reference genome files and sequence reads. We’ll discuss those files in more detail below — first, let’s get everyone their own copy of the data.\n\nGo to your personal dir in /fs/scratch/PAS2250/ENT6703:\n\n# Replace `jelmer` with your personal dir's name!\ncd /fs/scratch/PAS2250/ENT6703/jelmer\n\nThen, use the Unix copy command cp as follows (yes, there’s a space + period at the end!):\n\ncp -rv ../share/data .\n‘/fs/scratch/PAS2250/ENT6703/share/data’ -&gt; ‘./data’\n‘/fs/scratch/PAS2250/ENT6703/share/data/meta’ -&gt; ‘./data/meta’\n‘/fs/scratch/PAS2250/ENT6703/share/data/meta/metadata.tsv’ -&gt; ‘./data/meta/metadata.tsv’\n‘/fs/scratch/PAS2250/ENT6703/share/data/ref’ -&gt; ‘./data/ref’\n‘/fs/scratch/PAS2250/ENT6703/share/data/ref/GCF_016801865.2.gtf’ -&gt; ‘./data/ref/GCF_016801865.2.gtf’\n‘/fs/scratch/PAS2250/ENT6703/share/data/ref/GCF_016801865.2.fna’ -&gt; ‘./data/ref/GCF_016801865.2.fna’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq’ -&gt; ‘./data/fastq’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802868_R2.fastq.gz’ -&gt; ‘./data/fastq/ERR10802868_R2.fastq.gz’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802863_R1.fastq.gz’ -&gt; ‘./data/fastq/ERR10802863_R1.fastq.gz’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802880_R2.fastq.gz’ -&gt; ‘./data/fastq/ERR10802880_R2.fastq.gz’\n‘/fs/scratch/PAS2250/ENT6703/share/data/fastq/ERR10802880_R1.fastq.gz’ -&gt; ‘./data/fastq/ERR10802880_R1.fastq.gz’\n# [...truncated...]\n\n\n\n\n\n\nIn the command above:\n\n\n\n\nOption -r will enable “recursive” (=dirs, not just files) copying\nOption -v will turn on “verbose” output: it will report what it’s copying\nThe first argument (../share/data) is the source directory, with .. meaning one dir “up”\nThe second argument is the target directory: . means the current working dir\n\n\n\n\nNow, use the tree command (-C to show colors) to recursively list files your newly copied files in a way that gives a nice overview:\n\ntree -C\n# (Unfortunately colors aren't shown in the output on the website)\n.\n└── data\n    ├── fastq\n    │   ├── ERR10802863_R1.fastq.gz\n    │   ├── ERR10802863_R2.fastq.gz\n    │   ├── ERR10802864_R1.fastq.gz\n    │   ├── ERR10802864_R2.fastq.gz\n    │   ├── [...truncated - more FASTQ files...]\n    ├── meta\n    │   └── metadata.tsv\n    └── ref\n        ├── GCF_016801865.2.fna\n        └── GCF_016801865.2.gtf\n4 directories, 47 files\nAs we saw earlier, we have a whole bunch of FASTQ files (.fastq.gz extension, the HTS reads), a metadata file, and two reference genomes files (.fna and .gtf). You’ll take a closer look at each of those below.\n\n\n\n1.4 Viewing the metadata\nYou’ll first look at the “metadata” associated with the samples analyzed in this paper, such as the treatment information for each sample, and a sample ID that can be used to match them to the files with reads.\nThe metadata file metadata.tsv (tsv for “tab-separated values”) is in the folder data/meta:\nls -lh data/meta\n-rw-r--r-- 1 jelmer PAS0471 644 Jan 21 09:15 metadata.tsv\nYou can find this file in the VS Code side bar and click on it to open it in the editor. Alternatively, you could use the cat command to show the file contents in the shell:\ncat data/meta/metadata.tsv\nsample_id    time     treatment\nERR10802882  10_days  cathemerium\nERR10802875  10_days  cathemerium\nERR10802879  10_days  cathemerium\nERR10802883  10_days  cathemerium\nERR10802878  10_days  control\nERR10802884  10_days  control\nERR10802877  10_days  control\nERR10802881  10_days  control\nERR10802876  10_days  relictum\nERR10802880  10_days  relictum\nERR10802885  10_days  relictum\nERR10802886  10_days  relictum\nERR10802864  24_h     cathemerium\nERR10802867  24_h     cathemerium\nERR10802870  24_h     cathemerium\nERR10802866  24_h     control\nERR10802869  24_h     control\nERR10802863  24_h     control\nERR10802871  24_h     relictum\nERR10802874  24_h     relictum\nERR10802865  24_h     relictum\nERR10802868  24_h     relictum\n\n\n Your Turn: Based on this metadata, try to understand the experimental design (Click to see pointers)\n\n\nThe time column contains the amount of time after infection, with “h” short for hours.\nThe treatment column contains the treatment: which Plasmodium species, or “control” (not infected).\nWe have 3 treatments across each of two timepoints, with a number of replicates per treatment-timepoint combination.\n\n\n\n\n Your Turn: How many biological replicates are there? Is a treatment missing relative to what was described above and in the paper? (Click to see the answers)\n\n\nThere are 4 replicates per time x treatment combination, except in two cases (the paper says those two samples were removed from the final analysis).\nThe 21-days timepoint is missing: I removed it to simplify the dataset a bit.\n\n\n\n\n\n\n\n\nSide note: How did I retrieve this paper’s data? (Click to expand)\n\n\n\n\n\nAt the end of the paper, there is a section called “Open Research” with a “Data Availability Statement”, which reads:\n\nRaw sequences generated in this study have been submitted to the European Nucleotide Archive ENA database (https://www.ebi.ac.uk/ena/browser/home) under project accession number PRJEB41609, Study ERP125411. Sample metadata are available at https://doi.org/10.20350/digitalCSIC/15708.\n\nI used the second link above to download the metadata, which I slightly edited to simplify. I used the project accession number PRJEB41609 to directly download the raw sequences (i.e., the FASTQ files we’ll explore below) to OSC using a command-line tool called fastq-dl."
  },
  {
    "objectID": "labs/data.html#reference-genome-files",
    "href": "labs/data.html#reference-genome-files",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "2 Reference genome files",
    "text": "2 Reference genome files\nWe’ll cover the two main types of reference genome files you need in a HTS project like reference-based RNA-seq:\n\nFASTA files: Files with just sequences and their IDs. Your reference genome assembly is in this format.\nGTF (& GFF) files: These contain annotations in a tabular format, e.g. the start & stop position of each gene.\n\n\n2.1 Finding your reference genome\nImagine that you are one of the researchers involved in the Culex study — or alternatively, that you are still you, but you just want to redo their analysis.\nYou’ll want to see if there’s a Cx. pipiens reference genome available, and if so, download the relevant files. The authors state the following in the paper (section 2.3, “Data analysis”):\n\nBecause the reference genome and annotations of Cx. pipiens are not published yet, we used the reference genome and annotations of phylogenetically closest species that were available in Ensembl, Cx. quinquefasciatus.\n\nBut perhaps that genome of Cx. pipiens has been published in the meantime?\nGenerally, the first place to look reference genome data is at NCBI, https://ncbi.nlm.nih.gov, where you can start by simply typing the name of your organism in the search box at the home page — by means of example, let’s first search for the hoverfly Episyrphus balteatus:\n\n\n\n\n\nFor this species, we get the following “card” at the top of the results:\n\n\n\n\n\nIf you next click on “Genomes” in the result page above, you should get the following:\n\n\n\n\n\nSo, NCBI has 3 genomes assemblies for Episyrphus balteatus. The top one has a green check mark next to it (which means that this genome has been designated the primary reference genome for the focal organism), and it is also the only genome with an entry in the Annotation column and with a “Chromosome” (vs. “Scaffold”) assembly Level. Therefore, that top assembly, idEpiBalt1.1, would be the one to go with.\nYou can click on each assembly to get more information, including statistics like the number of scaffolds.\n\n\n Your Turn: Now let’s switch to Culex. How many Culex assemblies are on NCBI (do a genus-wide search)? Are there any for Culex pipiens, and if so, which would you pick? (Click for the answer)\n\nGo through the same process as shown above for Episyrphus balteatus, instead entering “Culex” in the search box.\nYou should find that there are 5 Culex assemblies, 2 of which are Culex pipiens. The first one, TS_CPP_V2, has the reference checkmark next to it and has an entry in the Annotation column, which the second one (TS_CPM_V1) doesn’t:\n\n\n\n\n\n(These two are also from different subspecies, but as far as I could see, the authors of our study don’t specify the focal subspecies – though you could probably figure that out based on geographic range.)\n\nAs shown in the solutions above, there is currently a reference genome for Cx. pipiens available1, and we’ll be “using” (looking at) that one. I have downloaded its files for you, which were among the files you just copied.\n\n\n Your Turn: Take a closer look at our focal genome on the NCBI website. What is the size of the genome assembly? How many chromosomes and scaffolds does it contain? And how many protein-coding genes? (Click for the solutions)\n\nOn the genome’s page at NCBI, some of the information includes the following stats on the assembly and the annotation:\n\n\n\n\n\n\n\n\n\n\nSo:\n\nIt is 566.3 Mb (Megabases)\nIt contains 3 chromosomes and 289 unplaced scaffolds\nIt has 16,297 protein-coding genes\n\n\n\n\n\n\n\n\nSide note: Downloading the reference genome files (Click to expand)\n\n\n\n\n\nIf you wanted to download the reference genome files from the NCBI website, you could either select an assembly in the overview table and click the Download button, or click the Download button at the top of the page for a specific assembly. That should get you the following pop-up window:\n\n\n\n\n\nYou’ll want to select at least the “Genome sequences (FASTA)” and one or both of the “Annotation features” files (GTF is often preferred with RNA-seq).\nThis allows you to download the data to your computer, and you could then upload it OSC. (Though a faster and more reproducible solution would be to use a command in your OSC shell to directly download these — the datasets and curl buttons next to the Download one a genome’s page help with that.)\nFinally, if a “RefSeq” assembly is available, like it is for this genome, you’ll want to select that, as it has been curated and standardized by NCBI (whereas “GenBank” entries are exactly as submitted by researchers). This mostly makes a difference for the annotation rather than the assembly itself.\n\n\n\n\n\n\n\n\n\nSide note: Reference genome complications (Click to expand)\n\n\n\n\n\nOther useful database for reference genomes are Ensembl and the specialized databases that exist for certain organisms, like FlyBase for Drosophila, VectorBase mostly for mosquitos, and JGI Phytozome for plants.\nIn many cases, these databases don’t contain the exact same reference genome files than NCBI. Often, at least the annotation is different (and actually the product of an independent annotation effort), but even the assembly may have small differences including in chromosome/scaffold names, which can make these files completely incompatible. And to make matters even more complicated, it is not always clear which database is the best source for your genome.\n\nInterestingly, the paper with the Cx. pipiens reference genome that we just found was already published in 2021, well before our focal Molecular Ecology paper.\nAnd when we take a closer look at the quote from the paper, they say no genome for Cx. pipiens is “available in Ensembl” — which is in fact still the case. Could it be that the authors preferred the Ensembl genome from Cx. quinquefasciatus over the NCBI genome of Cx. pipiens? Or perhaps they just did their analyses already several years ago?\n\n\n\n\n\n\n2.2 Reference genome files I: FASTA\n\nThe FASTA format\nFASTA files contain one or more DNA or amino acid sequences, with no limits on the number of sequences or the sequence lengths. FASTA is the standard format for, e.g.:\n\nGenome assembly sequences\nTranscriptomes and proteomes (all of an organism’s transcripts & amino acid sequences, respectively)\nSequence downloads from NCBI such as a single gene/protein or other GenBank entry\n\nThe following example FASTA file contains two entries:\n&gt;unique_sequence_ID Optional description\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAAAA\n&gt;unique_sequence_ID2\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAATG\nEach entry consists of a header line and the sequence itself. Header lines start with a &gt; (greater-than sign) and are otherwise “free form”, though the idea is that they provide an identifier for the sequence that follows.2\n\n\n\n\n\n\nFASTA file name extensions are variable: .fa, .fasta, .fna, .faa (Click to expand)\n\n\n\n\n\n\n“Generic” extensions are .fasta and .fa (e.g: culex_assembly.fasta)\nAlso used are extensions that explicitly indicate whether sequences are nucleotides (.fna) or amino acids (.faa)\n\n\n\n\n\n\nYour Culex genome assembly FASTA\nYour reference genome files are in data/ref:\nls -lh data/ref\n-rw------- 1 jelmer PAS0471 547M Jan 22 12:34 GCF_016801865.2.fna\n-rw------- 1 jelmer PAS0471 123M Jan 22 12:34 GCF_016801865.2.gtf\nWhile we can easily open small to medium-size files in the editor pane, “visual editors” like that do not work well for larger files like these.\nA handy command to view text files of any size is less, which opens them up in a “pager” within your shell – you’ll see what that means if you try it with one of the assembly FASTA file:\nless data/ref/GCF_016801865.2.fna\n&gt;NC_068937.1 Culex pipiens pallens isolate TS chromosome 1, TS_CPP_V2, whole genome shotgun sequence\naagcccttttatggtcaaaaatatcgtttaacttgaatatttttccttaaaaaataaataaatttaagcaaacagctgag\ntagatgtcatctactcaaatctacccataagcacacccctgttcaatttttttttcagccataagggcgcctccagtcaa\nattttcatattgagaatttcaatacaattttttaagtcgtaggggcgcctccagtcaaattttcatattgagaatttcaa\ntacatttttttatgtcgtaggggcgcctccagtcaaattttcatattgagaatttcaatacattttttttaagtcgtagg\nggcgcctccagtcaaattttcatattgagaatttcaatacatttttttaagtcttaggggcgcctccagtcaaattttca\ntattgagaatttcaatacatttttttaagtcgtaggggcgcctccagtcaaattttcatattgagaattttaatacaatt\nttttaaatcctaggggcgccttcagacaaacttaatttaaaaaatatcgctcctcgacttggcgactttgcgactgactg\ncgacagcactaccttggaacactgaaatgtttggttgactttccagaaagagtgcatatgacttgaaaaaaaaagagcgc\nttcaaaattgagtcaagaaattggtgaaacttggtgcaagcccttttatggttaaaaatatcgtttaacttgaatatttt\ntccttaaaaaataaataaatttaagcaaacagctgagtagatgtcatctactcaaatctacccataagcacacccctgga\nCCTAATTCATGGAGGTGAATAGAGCATACGTAAATACAAAACTCATGACATTAGCCTGTAAGGATTGTGTaattaatgca\naaaatattgaTAGAATGAAAGATGCAAGTCccaaaaattttaagtaaatgaATAGTAATCATAAAGATAActgatgatga\n\n\n Your Turn: Explore the file with less (Click to see the instructions)\n\nAfter running the command above, the file should have “opened” inside the less pager.\nYou can move around in the file in several ways: by scrolling with your mouse, with up and down arrows, or, if you have them, PgUp and PgDn keys (also, u will move up half a page and d will move down half a page).\nIf you find yourself scrolling down and down to try and reach the end of the file, you can instead press G to go to the very end right away (and g to go back to the top).\nNotice that you are “inside” this pager and won’t have your shell prompt back until you press q to quit less.\n\n\n\n\n\n\n\nSide note: Lowercase vs. uppercase nucleotide letters? (Click to expand)\n\n\n\n\n\nAs you have probably noticed, nucleotide bases are typically typed in uppercase (A, C, G, T). What does the mixture of lowercase and uppercase bases in the Cx. pipiens assembly FASTA mean, then?\nLowercase bases are what is called “soft-masked”: they are repetitive sequences, and bioinformatics programs will treat them differently than non-repetitive sequences, which are in uppercase.\n\n\n\n\n\n\n\n2.3 Reference genome files II: GFF/GTF\n\nThe GFF/GTF format\nThe GTF and GFF formats are very similar tab-delimited tabular files that contain genome annotations, with:\n\nOne row for each annotated “genomic feature” (gene, exon, etc.)\nOne column for each piece of information about a feature, like its genomic coordinates\n\nSee the sample below, with an added header line (not normally present) with column names:\nseqname     source  feature start   end     score  strand  frame    attributes\nNC_000001   RefSeq  gene    11874   14409   .       +       .       gene_id \"DDX11L1\"; transcript_id \"\"; db_xref \"GeneID:100287102\"; db_xref \"HGNC:HGNC:37102\"; description \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; gbkey \"Gene\"; gene \"DDX11L1\"; gene_biotype \"transcribed_pseudogene\"; pseudo \"true\"; \nNC_000001   RefSeq  exon    11874   12227   .       +       .       gene_id \"DDX11L1\"; transcript_id \"NR_046018.2\"; db_xref \"GeneID:100287102\"; gene \"DDX11L1\"; product \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; pseudo \"true\"; \nSome details on the more important/interesting columns:\n\nseqname — Name of the chromosome, scaffold, or contig\nfeature — Name of the feature type, e.g. “gene”, “exon”, “intron”, “CDS”\nstart & end — Start & end position of the feature\nstrand — Whether the feature is on the + (forward) or - (reverse) strand\nattribute — A semicolon-separated list of tag-value pairs with additional information\n\n\n\nYour Culex GTF file\nFor our Cx. pipiens reference genome, we only have a GTF file.3\nTake a look at it, again with less, but now with the -S option:\nless -S data/ref/GCF_016801865.2.gtf\n#gtf-version 2.2\n#!genome-build TS_CPP_V2\n#!genome-build-accession NCBI_Assembly:GCF_016801865.2\n#!annotation-source NCBI RefSeq GCF_016801865.2-RS_2022_12\nNC_068937.1     Gnomon  gene    2046    110808  .       +       .       gene_id \"LOC120427725\"; transcript_id \"\"; db_xref \"GeneID:120427725\"; description \"homeotic protein deformed\"; gbkey \"Gene\"; gene \"LOC120427725\"; gene_biotype \"protein_coding\"; \nNC_068937.1     Gnomon  transcript      2046    110808  .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; \nNC_068937.1     Gnomon  exon    2046    2531    .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1     Gnomon  exon    52113   52136   .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1     Gnomon  exon    70113   70962   .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1     Gnomon  exon    105987  106087  .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1     Gnomon  exon    106551  106734  .       +       .       gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \n\n\n\n\n\n\nAvoid line-wrapping with less -S\n\n\n\nLines in a file may contain too many characters to fit on your screen, as will be the case for this GTF file. less will by default “wrap” such lines onto the next line on your screen, but this is often confusing for files like FASTQ and tabular files like GTF. Therefore, we turned off line-wrapping above by using the -S option to less.\n\n\n\n\n Your Turn: The GTF file is sorted: all entries from the first line of the table, until you again see “gene” in the third column, belong to the first gene. Can you make sense of all these entries for this gene, given what you know of gene structures? How many transcripts does this gene have? (Click to see some pointers)\n\n\nThe first gene (“LOC120427725”) has 3 transcripts.\nEach transcript has 6-7 exons, 5 CDSs, and a start and stop codon.\n\nBelow, I’ve printed all lines belonging to the first gene:\nNC_068937.1 Gnomon  gene    2046    110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"\"; db_xref \"GeneID:120427725\"; description \"homeotic protein deformed\"; gbkey \"Gene\"; gene \"LOC120427725\"; gene_biotype \"protein_coding\"; \nNC_068937.1 Gnomon  transcript  2046    110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; \nNC_068937.1 Gnomon  exon    2046    2531    .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1 Gnomon  exon    52113   52136   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1 Gnomon  exon    70113   70962   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1 Gnomon  exon    105987  106087  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1 Gnomon  exon    106551  106734  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \nNC_068937.1 Gnomon  exon    109296  109660  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"6\"; \nNC_068937.1 Gnomon  exon    109726  110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 25 Proteins\"; product \"homeotic protein deformed, transcript variant X3\"; transcript_biotype \"mRNA\"; exon_number \"7\"; \nNC_068937.1 Gnomon  CDS 70143   70962   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  CDS 105987  106087  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"4\"; \nNC_068937.1 Gnomon  CDS 106551  106734  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"5\"; \nNC_068937.1 Gnomon  CDS 109296  109660  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"6\"; \nNC_068937.1 Gnomon  CDS 109726  110025  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  start_codon 70143   70145   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  stop_codon  110026  110028  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_052707445.1\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_052563405.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  transcript  5979    110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; \nNC_068937.1 Gnomon  exon    5979    6083    .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1 Gnomon  exon    52113   52136   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1 Gnomon  exon    70113   70962   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1 Gnomon  exon    105987  106087  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1 Gnomon  exon    106551  106734  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \nNC_068937.1 Gnomon  exon    109296  109660  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"6\"; \nNC_068937.1 Gnomon  exon    109726  110808  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X2\"; transcript_biotype \"mRNA\"; exon_number \"7\"; \nNC_068937.1 Gnomon  CDS 70143   70962   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  CDS 105987  106087  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"4\"; \nNC_068937.1 Gnomon  CDS 106551  106734  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"5\"; \nNC_068937.1 Gnomon  CDS 109296  109660  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"6\"; \nNC_068937.1 Gnomon  CDS 109726  110025  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  start_codon 70143   70145   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  stop_codon  110026  110028  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592629.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448563.1\"; exon_number \"7\"; \nNC_068937.1 Gnomon  transcript  60854   110807  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"mRNA\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; \nNC_068937.1 Gnomon  exon    60854   61525   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"1\"; \nNC_068937.1 Gnomon  exon    70113   70962   .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"2\"; \nNC_068937.1 Gnomon  exon    105987  106087  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"3\"; \nNC_068937.1 Gnomon  exon    106551  106734  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"4\"; \nNC_068937.1 Gnomon  exon    109296  109660  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"5\"; \nNC_068937.1 Gnomon  exon    109726  110807  .   +   .   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gene \"LOC120427725\"; model_evidence \"Supporting evidence includes similarity to: 24 Proteins\"; product \"homeotic protein deformed, transcript variant X1\"; transcript_biotype \"mRNA\"; exon_number \"6\"; \nNC_068937.1 Gnomon  CDS 70143   70962   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"2\"; \nNC_068937.1 Gnomon  CDS 105987  106087  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"3\"; \nNC_068937.1 Gnomon  CDS 106551  106734  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"4\"; \nNC_068937.1 Gnomon  CDS 109296  109660  .   +   2   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"5\"; \nNC_068937.1 Gnomon  CDS 109726  110025  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"6\"; \nNC_068937.1 Gnomon  start_codon 70143   70145   .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"2\"; \nNC_068937.1 Gnomon  stop_codon  110026  110028  .   +   0   gene_id \"LOC120427725\"; transcript_id \"XM_039592628.2\"; db_xref \"GeneID:120427725\"; gbkey \"CDS\"; gene \"LOC120427725\"; product \"homeotic protein deformed\"; protein_id \"XP_039448562.1\"; exon_number \"6\";"
  },
  {
    "objectID": "labs/data.html#fastq-files",
    "href": "labs/data.html#fastq-files",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "3 FASTQ files",
    "text": "3 FASTQ files\n\n3.1 The FASTQ format\nFASTQ is the standard HTS read data file format. Like the other genomic data files we’ve seen so far, these are plain text files. Each read forms one FASTQ entry and is represented by four lines:\n\nA header that starts with @ and e.g. uniquely identifies the read\nThe sequence itself\nA + (plus sign — yes, that’s all!)\nOne-character quality scores for each base in the sequence\n\n\n\n\n\nOne entry (read) in a FASTQ file covers 4 lines. The header line is annotated, with some of the more useful components highlighted in red. For viewing purposes, this read (at only 56 bp) is shorter than what is typical.\n\n\n\n\n\n\n\n\n\nSide note: FASTQ quality scores (Click to expand)\n\n\n\n\n\nThe quality scores we saw in the read above represent an estimate of the error probability of the base call.\nSpecifically, they correspond to a numeric “Phred” quality score (Q), which is a function of the estimated probability that a base call is erroneous (P):\n\nQ = -10 * log10(P)\n\nFor some specific probabilities and their rough qualitative interpretation for Illumina data:\n\n\n\nPhred quality score\nError probability\nRough interpretation\n\n\n\n\n10\n1 in 10\nterrible\n\n\n20\n1 in 100\nbad\n\n\n30\n1 in 1,000\ngood\n\n\n40\n1 in 10,000\nexcellent\n\n\n\nThis numeric quality score is represented in FASTQ files not by the number itself, but by a corresponding “ASCII character”. This allows for a single-character representation of each possible score — as a consequence, each quality score character can conveniently correspond to (& line up with) a base character in the read.\n\n\n\nPhred quality score\nError probability\nASCII character\n\n\n\n\n10\n1 in 10\n+\n\n\n20\n1 in 100\n5\n\n\n30\n1 in 1,000\n?\n\n\n40\n1 in 10,000\nI\n\n\n\nIn practice, you almost never have to manually check the quality scores of bases in FASTQ files, but if you do, a rule of thumb is that letter characters are good (Phred of 32 and up). For your reference, here is a complete lookup table (look at the top table (BASE=33)).\n\n\n\n\n\n\n3.2 Listing your FASTQ files\nFirst, let’s take another look at your list of FASTQ files:\nls -lh data/fastq\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:36 ERR10802863_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802863_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 21M Jan 21 13:36 ERR10802864_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802864_R2.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802865_R1.fastq.gz\n-rw-r--r-- 1 jelmer PAS0471 22M Jan 21 13:36 ERR10802865_R2.fastq.gz\n[...truncated...]\nIn the file listing above:\n\nFirst, take note of the file sizes. They are “only” about 22 Mb in size, and all have a very similar size. This is because I “subsampled” the FASTQ files to only have 500,000 reads per file. The original files were on average over 1 Gb in size with about 30 million reads.\nSecond, if you look closely at the file names, it looks like we have two FASTQ files per sample: one with _R1 at the end of the file name, and one with _R2.\n\n\n\nYour Turn: What might each of the two files per sample represents/contains? (Click for the solution)\n\nThese contain the forward reads (_R1.fastq.gz) vs. the reverse reads (_R2.fastq.gz).\n\n\n\nYour Turn: Do you have any idea why the file extension ends in .gz? (Click for the solution)\n\nThis means it is gzip-compressed. This saves a lot of space: compressed files can be up to 10 times smaller than uncompressed files. Most bioinformatics tools, including FastQC which we’ll run in a bit, can work with gzipped files directly, so there is no need to unzip them.\n\n\n\n\n3.3 Viewing your FASTQ files\nDespite the gzip-compression, we can simply use the less command as before to view the FASTQ files (!):\nless data/fastq/ERR10802863_R1.fastq.gz\n@ERR10802863.8435456 8435456 length=74\nCAACGAATACATCATGTTTGCGAAACTACTCCTCCTCGCCTTGGTGGGGATCAGTACTGCGTACCAGTATGAGT\n+\nAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n@ERR10802863.27637245 27637245 length=74\nGCCACACTTTTGAAGAACAGCGTCATTGTTCTTAATTTTGTCGGCAACGCCTGCACGAGCCTTCCACGTAAGTT\n+\nAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE&lt;EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n\n\n\n\n\n\nDifferent header lines\n\n\n\nThe header lines (starting with @) are quite different from the earlier example, because these files were downloaded from SRA. When you get files directly from a (Illumina) sequencer, they will have headers much like the earlier example.\n\n\nIn practice, we don’t often have to closely look at the contents of our FASTQ files ourselves. There are simply too many reads to make sense of!\nInstead, we’ll have specialized tools like FastQC summarize them for us: e.g. how many sequences there are, what the quality scores look like, and if there are adapter sequences. We’ll run FastQC below.\n\n\nYour Turn: All of that said, in this case, you should be able to spot some very different-looking reads soon when looking at the file with less. What are they? (Click for the solution)\n\nThe 5th read looks as follows — and if you scroll down you should quickly see several more reads like this:\n@ERR10802863.11918285 11918285 length=35\nNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n+\n###################################\nThese only consists of N bases (and they are also shorter than the other reads), and are therefore completely useless!\nFYI: It not common to run into these kinds of failed reads as easily!"
  },
  {
    "objectID": "labs/data.html#quality-control-with-fastqc",
    "href": "labs/data.html#quality-control-with-fastqc",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "4 Quality control with FastQC",
    "text": "4 Quality control with FastQC\nA good example of a tool with a command-line interface is FastQC, for quality control of FASTQ files. FastQC is ubiquitous: nearly all HTS data comes in FASTQ files, and the first step is always to check the read quality.\n\n4.1 Running FastQC\nTo run FastQC, use the command fastqc.\nIf you want to analyze one of your FASTQ files with default FastQC settings, a complete FastQC command to do so would simply be fastqc followed by the name of the file4:\n# (Don't run this)\nfastqc data/fastq/ERR10802863_R1.fastq.gz\nHowever, an annoying default behavior by FastQC is that it writes its output files in the dir where the input files are — in general, it’s not great practice to directly mix your primary data and results like that!\nTo figure out how we can change that behavior, first consider that many commands and bioinformatics tools alike have an option -h and/or --help to print usage information to the screen.\n\n\nYour Turn: Try to print FastQC’s help info, and figure out which option you can use to specify an output directory of your choice. (Click for the solution)\n\nfastqc -h and fastqc --help will both work to show the help info.\nYou’ll get quite a bit of output printed to screen, including the snippet about output directories that is reproduced below:\nfastqc -h\n  -o --outdir     Create all output files in the specified output directory.\n                    Please note that this directory must exist as the program\n                    will not create it.  If this option is not set then the \n                    output file for each sequence file is created in the same\n                    directory as the sequence file which was processed.\nSo, you can use -o or equivalently, --outdir to specify an output dir.\n\nNow, let’s try to run FastQC and tell it to use the output dir results/fastqc:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nbash: fastqc: command not found...\nHowever, there is a wrinkle, as you can see above. It turns out that FastQC is installed at OSC5, but we have to “load it” before we can use it. Without having time to go into further details about software usage at OSC, please accept that we can load FastQC as follows:\nmodule load fastqc\nNow, let’s try again:\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nSpecified output directory 'results/fastqc' does not exist\n\n\n\n Your Turn: Now what is going on this time? (Or had you perhaps seen this coming given the help text we saw earlier?) Can you try to fix the problem? (Click here for hints)\n\nYou’ll need to create a new directory, which you can do either by using the buttons in the VS Code side bar, or with the mkdir command — here, try it as mkdir -p followed by the name (path) of the directory you want to create.\n\n\n\nExercise solution (Click to expand)\n\n\nThe problem, as the error fairly clearly indicates, is that the output directory that we specified with --outdir does not currently exist. We might have expected FastQC to be smart/flexible enough to create this dir for us (many bioinformatics tools are), but alas. On the other hand, if we had read the help text clearly, it did warn us about this.\nWith the mkdir command, to create “two levels” of dirs at once, like we need to here (both results and then fastqc within there), we need its -p option:\n\nmkdir -p results/fastqc\n\nAnd for our final try before we give up and throw our laptop out the window (make sure to run the code in the exercise solution before you retry!):\nfastqc --outdir results/fastqc data/fastq/ERR10802863_R1.fastq.gz\nStarted analysis of ERR10802863_R1.fastq.gz\nApprox 5% complete for ERR10802863_R1.fastq.gz\nApprox 10% complete for ERR10802863_R1.fastq.gz\nApprox 15% complete for ERR10802863_R1.fastq.gz\n[...truncated...]\nAnalysis complete for ERR10802863_R1.fastq.gz\nSuccess!! (That should have taken just a few seconds with our subsampled FASTQ files.)\n\n\n\n4.2 FastQC output files\nLet’s take a look at the files in the output dir we specified:\nls -lh results/fastqc\n-rw-r--r-- 1 jelmer PAS0471 241K Jan 25 15:50 ERR10802863_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Jan 25 15:50 ERR10802863_R1_fastqc.zip\n\nThere is a .zip file, which contains tables with FastQC’s data summaries\nThere is an .html (HTML) file, which contains plots — this is what we’ll look at next\n\n\n\n Your Turn: Run FastQC for the corresponding R2 file. Would you use the same output dir? (Click for the solution)\n\nYes, it makes sense to use the same output dir, since as you could see above, the output file names have the input file identifiers in them. As such, we don’t need to worry about overwriting files, and it will be easier to have all the results in a single dir.\nTo run FastQC for the R2 (=reverse-read) file:\nfastqc --outdir results/fastqc ERR10802863_R2.fastq.gz\nStarted analysis of ERR10802863_R2.fastq.gz\nApprox 5% complete for ERR10802863_R2.fastq.gz\nApprox 10% complete for ERR10802863_R2.fastq.gz\nApprox 15% complete for ERR10802863_R2.fastq.gz\n[...truncated...]\nAnalysis complete for ERR10802863_2.fastq.gz\nls -lh results/fastqc\n-rw-r--r-- 1 jelmer PAS0471 241K Jan 21 21:50 ERR10802863_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Jan 21 21:50 ERR10802863_R1_fastqc.zip\n-rw-r--r-- 1 jelmer PAS0471 234K Jan 21 21:53 ERR10802863_R2_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 244K Jan 21 21:53 ERR10802863_R2_fastqc.zip\nNow, we have four files: two for each of our preceding successful FastQC runs.\n\n\n\n\n4.3 Interpreting FastQC’s output\nFirst, we’ll unfortunately have to download FastQC’s output HTML files6:\n\nFind the FastQC HTML files in the file explorer in the VS Code side bar.\nRight-click on one of them, click Download... and follow the prompt to download the file somewhere to your computer (doesn’t matter where, just make sure you see where it goes).\nRepeat this for the second file\nThen, open your computer’s file browser, find the downloaded files, and double-click on one. It should be opened in your default web browser.\n\nWe’ll now go through a couple of the FastQC plots/modules, with first some example plots with good/bad results for reference.\n\n\nOverview of module results\nFastQC has “pass” (checkmark in green), “warning” (exclamation mark in orange), and “fail” (cross in red) assessments for each module, as you can see below.\nThese are handy and typically at least somewhat meaningful, but it is important to realize that a “warning” or a “fail” is not necessarily the bad news that it may appear to be, because, e.g.:\n\nSome of these modules could perhaps be called overly strict.\nSome warnings and fails are easily remedied or simply not a very big deal.\nFastQC assumes that your data is derived from whole-genome shotgun sequencing — some other types of data like RNA-seq data will always trigger a couple of warnings and files based on expected differences.\n\n\n\n\n\n\n\nBasic statistics\nThis shows, for example, the number of sequences (reads) and the read length range for your file:\n\n\n\n\n\n\nPer base quality sequence quality\nThis figure visualize the mean per-base quality score (y-axis) along the length of the reads (x-axis). Note that:\n\nA decrease in sequence quality along the reads is normal.\nR2 (reverse) reads are usually worse than R1 (forward) reads.\n\n\n\nGood / acceptable:\n\n\n\n\nBad:\n\n\n\n\n\nTo interpret the quality scores along the y-axis, note the color scaling in the graphs (green is good, etc.), and see this table for details:\n\n\n\nPhred quality score\nError probability\nRough interpretation\n\n\n\n\n10\n1 in 10\nterrible\n\n\n20\n1 in 100\nbad\n\n\n30\n1 in 1,000\ngood\n\n\n40\n1 in 10,000\nexcellent\n\n\n\n\n\n\nPer sequence quality scores\nThis shows the same quality scores we saw above, but now simply as a density plot of per-read averages, with the quality score now along the x-axis, and the number of reads with that quality score along the y-axis:\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\n\nSequence length distribution\nWill throw a warning as soon as not all sequences are of the same length (like below), but this is quite normal.\n\n\n\n\n\n\nAdapter content\nChecks for known adapter sequences. When some of the insert sizes are shorter than the read length, adapters can end up in the sequence – these should be removed!\n\n\nGood:\n\n\n\n\nBad:\n\n\n\n\n\n\n\n\n\n4.4 Interpreting our FastQC output\n\n\nYour Turn: Open the HTML file for the R1 FASTQ file and go through the modules we discussed above. Can you make sense of it? Does the data look good to you, overall?\n\n\n\n\nYour Turn: Now open the HTML file for the R2 FASTQ file and take a look just at the quality scores. Does it look any worse than the R1?"
  },
  {
    "objectID": "labs/data.html#in-closing",
    "href": "labs/data.html#in-closing",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "5 In closing",
    "text": "5 In closing\nIn today’s lab, you were introduced to:\n\nWorking at the Ohio Supercomputer Center\nUsing the VS Code text editor\nUsing the Unix shell\nReference genome FASTA & GTF files & where to find these\nHTS read FASTQ files and how to quality-control these\nHow to run a command-line bioinformatics tool\n\nTaking a step back, I’ve shown you the main pieces of the computational infrastructure for what we may call “command-line genomics”: genomics analysis using command-line tools. And we’ve seen a basic example of loading and running a command-line tool at OSC.\n\n\n\n\n\n\nSide note: scaling the analysis & next steps for real projects (Click to expand)\n\n\n\n\n\nThe missing pieces for a typical, fuller example of how such tools are run in the context of an actual genomics project are (if we stay with FastQC):\n\nPutting the command to run FastQC in a “shell script”.\nSubmitting the script to the SLURM scheduler queue as a “batch job”.\nTo make speed things, using the OSC’s capabilities, we can submit multiple jobs in parallel using a loop.\n\nIf it seems that speed and computing power may not be an issue, given how fast FastQC ran, keep in mind that:\n\nWe here worked with subsampled (much smaller than usual) FASTQ files\nWe only ran FastQC for one of our 23 samples, and your experiment may have 50+ samples\nWe need to run a bunch more tools, and some of those take much longer to run or need lots of RAM memory.\n\nAll that said, those missing pieces mentioned above are outside the scope of this short introduction — but if you managed today, it should not be hard to learn those skills either."
  },
  {
    "objectID": "labs/data.html#appendix",
    "href": "labs/data.html#appendix",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "6 Appendix",
    "text": "6 Appendix\n\nBonus exercises\n\n\n Your Turn (Bonus): Explore the assembly FASTA file with grep (Click to see the instructions)\n\ngrep is an incredibly useful Unix command with which you can search files for specific text. By default, it will print lines that match your search in their entirety.\nFor example, we could search the genome for the short sequence ACCGATACGACG:\ngrep \"ACCGATACGACG\" data/ref/GCF_016801865.2.fna\naaaatcgaaaaacgcgTTTACCTTACATTGACAAAGTTGACCGATACGACGGCTCGATGTGCCAAACCGGTCACAAAGTC\nAATATTGACATTTCTTTTGCATTCTTCAGGTTCAGTGACCACAAACGGGACCGATACGACGGCTACCATCGGAATGCACC\nTCAAAATGTGTCAATTAACGTAACTAGATTTTTACGATCATAATAAGTAGATACCGATACGACGGGGCGGCATTTATGCT\nTAAGTAGATACCGATACGACGGGGCGGCATTCATGCTGCTACAGGGCTCAGCGGACCGACAAGCGACTGTGAAACGCAGC\n(Matches should be highlighted in red, but that doesn’t show here, unfortunately)\nOr count the number of times the much shorter sequence GGACC occurs:\ngrep -c \"GGACC\" data/ref/GCF_016801865.2.fna\n120492\nTry to adapt the above example to:\n\nPrint all entry headers in the assembly FASTA file\nCount the number of entry header (= the number of entries) in the assembly FASTA file\n\nDoes the number of entries make sense given how many chromosomes and scaffolds the assembly consists of according to NCBI?\n\n\n\n Bonus exercise solutions (Click to expand)\n\nTo print all FASTA entry headers, simply search for &gt; with grep (since &gt; should not occur in the sequences themselves, which can only be bases or N). Make sure to uses quotes (\"&gt;\")!\ngrep \"&gt;\" data/ref/GCF_016801865.2.fna\n&gt;NC_068937.1 Culex pipiens pallens isolate TS chromosome 1, TS_CPP_V2, whole genome shotgun sequence\n&gt;NC_068938.1 Culex pipiens pallens isolate TS chromosome 2, TS_CPP_V2, whole genome shotgun sequence\n&gt;NC_068939.1 Culex pipiens pallens isolate TS chromosome 3, TS_CPP_V2, whole genome shotgun sequence\n&gt;NW_026292818.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0001, whole genome shotgun sequence\n&gt;NW_026292819.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0002, whole genome shotgun sequence\n&gt;NW_026292820.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0003, whole genome shotgun sequence\n&gt;NW_026292821.1 Culex pipiens pallens isolate TS unplaced genomic scaffold, TS_CPP_V2 Cpp_Un0004, whole genome shotgun sequence\n[...truncated...]\nWe can count the number of header lines by modifying our above command only with the addition of the -c option:\ngrep -c \"&gt;\" data/ref/GCF_016801865.2.fna\n290\n\n\n\nAttribution\n\nSome of the FastQC example plots were taken from here."
  },
  {
    "objectID": "labs/data.html#footnotes",
    "href": "labs/data.html#footnotes",
    "title": "Week 3 lab — part 2:Working with genome and HTS data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBut see the box below for more info/context↩︎\nNote that because individual sequence entries are commonly spread across multiple lines, FASTA entries do not necessarily cover 2 lines (cf. FASTQ).↩︎\nA GFF file would contain the same information but in a slightly different format. For programs used in RNA-seq analysis, GTF files tend to be the preferred format.↩︎\nNote that this is very similar to running, say, the ls command!↩︎\nFor a full list of installed software at OSC: https://www.osc.edu/resources/available_software/software_list↩︎\nThe installed version of VS Code does not allow us to view HTML files↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this website",
    "section": "",
    "text": "This website contains the lecture slides and lab material for the guest lectures by Jelmer Poelstra (MCIC Wooster, Ohio State University) in the graduate-level ENTMLGY 6703 Spring 2024 course “Molecular Techniques & Data Analysis Syllabus” taught by Peter Piermarini and Larry Phelan at OSU.\nThe source code for this website can be found at https://github.com/jelmerp/ENTMLGY6703.\n\n\n\n Back to top"
  },
  {
    "objectID": "lectures/sequencing.html#what-does-sequencing-refer-to",
    "href": "lectures/sequencing.html#what-does-sequencing-refer-to",
    "title": "High-throughput sequencing  and genomes",
    "section": "What does sequencing refer to?",
    "text": "What does sequencing refer to?\nThe shorthand sequencing, like in “high-throughput sequencing” in the title of this presentation, generally refers to determining the nucleotide sequence of fragments of DNA.\n\n\n\n\n\n\n\n\nWhat about RNA or proteins?\n\n\n\nRNA is usually reverse transcribed to DNA (cDNA) prior to sequencing, as in nearly all “RNA-seq”.\nDirect RNA sequencing is possible with one of the sequencing technologies we’ll discuss, but this is under development and not yet widely used.\n\n\n\nProtein sequencing requires different technology altogether, such as mass spectrometry."
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-technologies-overview",
    "href": "lectures/sequencing.html#sequencing-technologies-overview",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing technologies: overview",
    "text": "Sequencing technologies: overview\n\nSanger sequencing (since 1977)\nSequences a single, typically PCR-amplified, short-ish (≤900 bp) DNA fragment at a time\n\n\n\nHigh-throughput sequencing (HTS)\nSequences 105-109, usually randomly selected, DNA fragments (“reads”) at a time — two types:\n\n\n\n\n\n\nShort-read HTS\n\nAKA Next-Generation Sequencing (NGS)\nProduces up to billions of 50-300 bp reads\nMarket dominated by Illumina\nSince 2005 — technology stable"
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-technologies-overview-1",
    "href": "lectures/sequencing.html#sequencing-technologies-overview-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing technologies: overview",
    "text": "Sequencing technologies: overview\n\nSanger sequencing (since 1977)\nSequences a single, typically PCR-amplified, short-ish (≤900 bp) DNA fragment at a time\n\n\nHigh-throughput sequencing (HTS)\nSequences 105-109, usually randomly selected, DNA fragments (“reads”) at a time — two types:\n\n\n\n\nShort-read HTS\n\nAKA Next-Generation Sequencing (NGS)\nProduces up to billions of 50-300 bp reads\nMarket dominated by Illumina\nSince 2005 — technology stable\n\n\n\n\nLong-read HTS\n\nReads much longer than in NGS but fewer, less accurate, and more costly per base\nTwo main companies: Oxford Nanopore Technologies (ONT) and Pacific Biosciences (PacBio)\nSince 2011 — remains under rapid development"
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-technology-development-timeline",
    "href": "lectures/sequencing.html#sequencing-technology-development-timeline",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing technology development timeline",
    "text": "Sequencing technology development timeline\n\n\nModified after Pereira et al. 2020"
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-technology-development-timeline-1",
    "href": "lectures/sequencing.html#sequencing-technology-development-timeline-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing technology development timeline",
    "text": "Sequencing technology development timeline\n\n\nModified after Pereira et al. 2020"
  },
  {
    "objectID": "lectures/sequencing.html#sanger-sequencing",
    "href": "lectures/sequencing.html#sanger-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sanger sequencing",
    "text": "Sanger sequencing\nSequences a single, typically PCR-amplified, short-ish (≤900 bp) DNA fragment at a time.\nSequencing is performed by synthesizing a new DNA strand in part with fluorescently-labeled nucleotides — a different color for each base (A, C, G, T).\n\n\nThe final result is a chromatogram that can be base-called:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe entire human genome (3 Gbp) was sequenced with Sanger technology!\n\n\nAnyone want to hazard a guess how much this cost, approximately?"
  },
  {
    "objectID": "lectures/sequencing.html#sequencing-cost-through-time",
    "href": "lectures/sequencing.html#sequencing-cost-through-time",
    "title": "High-throughput sequencing  and genomes",
    "section": "Sequencing cost through time",
    "text": "Sequencing cost through time\n\nhttps://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost"
  },
  {
    "objectID": "lectures/sequencing.html#present-day-sanger-applications",
    "href": "lectures/sequencing.html#present-day-sanger-applications",
    "title": "High-throughput sequencing  and genomes",
    "section": "Present-day Sanger applications",
    "text": "Present-day Sanger applications\nWith the advent of NGS, Sanger sequencing has become much less common but is not obsolete.\n\nSome present-day applications of Sanger sequencing include:\n\nExamining variation among individuals or populations in one or more candidate or marker genes (for population genetics, phylogenetics, functional inferences, etc.)\nTaxonomic identification of samples"
  },
  {
    "objectID": "lectures/sequencing.html#high-throughput-sequencing-applications",
    "href": "lectures/sequencing.html#high-throughput-sequencing-applications",
    "title": "High-throughput sequencing  and genomes",
    "section": "High-throughput sequencing applications",
    "text": "High-throughput sequencing applications\n\nWhole-genome assembly\n\n\n\nVariant analysis (for population genetics/genomics, molecular evolution, GWAS, etc.):\n\nWhole-genome “resequencing”\nReduced-representation libraries (e.g. RADseq, GBS)\n\n\n\n\n\nRNA-seq (transcriptome analysis)\nOther functional sequencing methods like methylation sequencing, ChIP-seq, etc.\n\n\n\n\nMicrobial community characterization\n\nMetabarcoding\nShotgun metagenomics"
  },
  {
    "objectID": "lectures/sequencing.html#two-important-variables-in-high-throughput-sequencing-read-lengths-error-rates",
    "href": "lectures/sequencing.html#two-important-variables-in-high-throughput-sequencing-read-lengths-error-rates",
    "title": "High-throughput sequencing  and genomes",
    "section": "Two important variables in high-throughput sequencing:  read lengths & error rates",
    "text": "Two important variables in high-throughput sequencing:  read lengths & error rates"
  },
  {
    "objectID": "lectures/sequencing.html#read-lengths",
    "href": "lectures/sequencing.html#read-lengths",
    "title": "High-throughput sequencing  and genomes",
    "section": "Read lengths",
    "text": "Read lengths\n\nShort-read (Illumina) HTS: 50-300 bp reads\nLong-read HTS: longer & more variable read lengths (PacBio: 10-50 kbp, ONT: 10-100 kbp)\n\n\n\n\n\nWhen are longer reads useful?\n\n\nGenome assembly\nHaplotype and large structural variant calling\nTranscript isoform identification\nTaxonomic identification of single reads (microbial metabarcoding)\n\n\n\n\n\n\n\nWhen does read length not matter (as much)?\n\n\nSNP variant analysis\nRead-as-a-tag: the goal is just to know a read’s origin in a reference genome, like in counting applications such as RNA-seq"
  },
  {
    "objectID": "lectures/sequencing.html#error-rates",
    "href": "lectures/sequencing.html#error-rates",
    "title": "High-throughput sequencing  and genomes",
    "section": "Error rates",
    "text": "Error rates\nCurrently, no sequencing technology is error-free, and several types of errors can occur:\n\n\nBase call errors, e.g. a base that was called as an A may instead be a G.\nInsertion or deletion (indel) errors\nWhen the base calling software is not confident at all, it can also return Ns (= undetermined).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuality scores in sequence data\n\n\nWhen you get sequences from a high-throughput sequencer, base calls have typically already been made. Every base is also accompanied by a quality score (inversely related to the estimated error probability)."
  },
  {
    "objectID": "lectures/sequencing.html#overcoming-sequencing-errors",
    "href": "lectures/sequencing.html#overcoming-sequencing-errors",
    "title": "High-throughput sequencing  and genomes",
    "section": "Overcoming sequencing errors",
    "text": "Overcoming sequencing errors\n\nSequencing every bases multiple times, i.e. having a &gt;1x so-called “depth of coverage” allows to infer the correct sequence\n\n\n\n\n\nBut overcoming sequencing errors is made more challenging by natural genetic variation among and within (heterozygosity due to diploid genomes) individuals\nTypical depths of coverage: at least 50-100x for genome assembly; 10-30x for resequencing."
  },
  {
    "objectID": "lectures/sequencing.html#illumina-short-read-hts-ngs",
    "href": "lectures/sequencing.html#illumina-short-read-hts-ngs",
    "title": "High-throughput sequencing  and genomes",
    "section": "Illumina (short-read HTS / NGS)",
    "text": "Illumina (short-read HTS / NGS)\n\n100-300 bp reads with 0.1-0.2% error rates\nMore reads, lower per-base cost, and lower error rates than long-read sequencing1.\n\n\n\nMachines differ in throughput, read length, cost per Gb:\n\n\n\n\n\n\n\nBut the error rate difference is disappearing: long-read technologies keep improving and Illumina does not."
  },
  {
    "objectID": "lectures/sequencing.html#libraries-and-library-prep",
    "href": "lectures/sequencing.html#libraries-and-library-prep",
    "title": "High-throughput sequencing  and genomes",
    "section": "Libraries and library prep",
    "text": "Libraries and library prep\nIn a sequencing context, a “library” is a collection of nucleic acid fragments ready for sequencing.\n\nIn Illumina and other HTS libraries, these fragments number in the millions or billions and are often randomly generated from input such as genomic DNA:\n\n\n\n\n\n\n\n\nThis procedure is called library prep, and is typically done for you by a sequencing facility or company.\n\n\n\n\n\n\nDifferent library prep procedures are used depending on the type of sequencing (WGS, RAD-seq, RNA-seq, etc.) and HTS technology — and some include more specific fragment generation or selection.\nWe’ll see the specific library prep steps for RNA-seq next week."
  },
  {
    "objectID": "lectures/sequencing.html#libraries-and-library-prep-cont.",
    "href": "lectures/sequencing.html#libraries-and-library-prep-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "Libraries and library prep (cont.)",
    "text": "Libraries and library prep (cont.)\nAfter library prep (here, for Illumina sequencing), each DNA fragment is flanked by several types of short sequences that together make up the “adapters”:\n\n\n\n\n\n\n\n\n\n\nAdapter components?\n\n\nAfter talking about paired-end vs. single-end sequencing and the way Illumina sequencing works, we’ll take a closer look at the individual components of adapters."
  },
  {
    "objectID": "lectures/sequencing.html#paired-end-vs.-single-end-sequencing",
    "href": "lectures/sequencing.html#paired-end-vs.-single-end-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Paired-end vs. single-end sequencing",
    "text": "Paired-end vs. single-end sequencing\nIn Illumina sequencing, DNA fragments can be sequenced from both ends as shown below —\nthis is called “paired-end” (PE) sequencing:\n\n\n\n\n\n\n\nWhen sequencing is instead single-end (SE), no reverse read is produced:"
  },
  {
    "objectID": "lectures/sequencing.html#paired-end-sequencing",
    "href": "lectures/sequencing.html#paired-end-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Paired-end sequencing",
    "text": "Paired-end sequencing\n\nPaired-end sequencing is a way to effectively increase the read length. (In the resulting sequence files, the two reads in each pair are separate, but they can be matched thanks to shared read IDs.)\nEarlier, we saw that the maximum read length of Illumina is 300 bp but in paired-end sequencing, this becomes “2 x 300 bp”, etc.\n\n\n\nThe total size of the biological DNA fragment (without adapters) is often called the insert size:"
  },
  {
    "objectID": "lectures/sequencing.html#insert-size-variation",
    "href": "lectures/sequencing.html#insert-size-variation",
    "title": "High-throughput sequencing  and genomes",
    "section": "Insert size variation",
    "text": "Insert size variation\nInsert size varies — because the library prep protocol can aim for various sizes, and because of variation due to limited precision in size selection. In some case, the insert size can be:\n\nShorter than the combined read length, leading to overlapping reads (this can be useful):\n\n\n\n\n\n\n\n\nShorter than the single read length, leading to “adapter read-through”\n(i.e., the ends of the resulting reads will consist of adapter sequence, which should be removed):"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works",
    "text": "How Illumina sequencing works\nFirst, library fragments bind to a surface thanks to the adapters, and the DNA templates (the biological sequences) are then PCR-amplified to form “clusters” of identical fragments:\n\n\n\n\n\n\n\n\nIn the diagram above, for illustrative purposes:\n\n\n\nOnly a few nucleotides are shown (1 block = 1 nucleotide) — in reality, fragments are much longer\nOnly two templates =&gt; clusters are shown — in reality, there are millions"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-cont.",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works (cont.)",
    "text": "How Illumina sequencing works (cont.)\nThen, sequencing is performed by synthesizing a new strand using fluorescently-labeled bases and taking a picture each time a new nucleotide is incorporated:"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-cont.-1",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-cont.-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works (cont.)",
    "text": "How Illumina sequencing works (cont.)"
  },
  {
    "objectID": "lectures/sequencing.html#how-errors-come-about-in-illumina",
    "href": "lectures/sequencing.html#how-errors-come-about-in-illumina",
    "title": "High-throughput sequencing  and genomes",
    "section": "How errors come about in Illumina",
    "text": "How errors come about in Illumina\n\n\n\nThe different templates within a cluster get out of sync because occasionally:\n\nThey miss a base incorporation\nThey incorporate two bases at once\n\n\n\n\nBase incorporation may also terminate before the end of the template is reached\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis error profile is why, for Illumina:\n\n\n\nThere are hard limits on read lengths\nBase quality scores typically decrease along the read"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works: Zooming out",
    "text": "How Illumina sequencing works: Zooming out"
  },
  {
    "objectID": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out-1",
    "href": "lectures/sequencing.html#how-illumina-sequencing-works-zooming-out-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "How Illumina sequencing works: Zooming out",
    "text": "How Illumina sequencing works: Zooming out"
  },
  {
    "objectID": "lectures/sequencing.html#a-closer-look-at-the-adapter-components",
    "href": "lectures/sequencing.html#a-closer-look-at-the-adapter-components",
    "title": "High-throughput sequencing  and genomes",
    "section": "A closer look at the adapter components",
    "text": "A closer look at the adapter components\nNow that you have a better idea of how Illumina sequencing works, let’s briefly revisit the adapters flanking the DNA, and see their different components:\n\n\n\nModified after http://nextgen.mgh.harvard.edu/IlluminaChemistry.html"
  },
  {
    "objectID": "lectures/sequencing.html#a-closer-look-at-the-adapter-components-1",
    "href": "lectures/sequencing.html#a-closer-look-at-the-adapter-components-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "A closer look at the adapter components",
    "text": "A closer look at the adapter components\nNow that you have a better idea of how Illumina sequencing works, let’s briefly revisit the adapters flanking the DNA, and see their different components:\n\n\n\nModified after http://nextgen.mgh.harvard.edu/IlluminaChemistry.html\n\n\n\n\n\n\n\nMultiplexing!\n\n\nUsing the indices/barcodes in adapters, up to 96 samples can be multiplexed into a single library."
  },
  {
    "objectID": "lectures/sequencing.html#long-read-hts-1",
    "href": "lectures/sequencing.html#long-read-hts-1",
    "title": "High-throughput sequencing  and genomes",
    "section": "Long-read HTS",
    "text": "Long-read HTS\nThe technologies underlying the two main long-read HTS technologies are very different, but have some commonalities beyond long reads — they:\n\n\n\nPerform “single-molecule” sequencing (no PCR amplification of library fragments)\nTherefore require higher quality & quantity of DNA\nCan detect some base modifications, like methyl groups\n\n\n\n\n\n\n\n\n\n\nError rates are changing\n\n\nAs a shorthand that was universally true until recently, I mentioned earlier that long-read HTS has higher error rate than short-read (Illumina) HTS.\n\nHowever, error rates in one type of PacBio sequencing where individual fragments are sequenced multiple times (“HiFi”) are now lower than in Illumina."
  },
  {
    "objectID": "lectures/sequencing.html#nanopore-sequencing",
    "href": "lectures/sequencing.html#nanopore-sequencing",
    "title": "High-throughput sequencing  and genomes",
    "section": "Nanopore sequencing",
    "text": "Nanopore sequencing\nA single strand of DNA passes through a nanopore —\nthe electrical current is measured, which depends on the combination of bases passes in the pore:\n\n\n\n\n\n\nhttps://www.genome.gov/genetics-glossary/Nanopore-DNA-Sequencing\nSee also this short video: https://www.youtube.com/watch?v=RcP85JHLmnI"
  },
  {
    "objectID": "lectures/sequencing.html#ont-nanopore-sequencers",
    "href": "lectures/sequencing.html#ont-nanopore-sequencers",
    "title": "High-throughput sequencing  and genomes",
    "section": "ONT (Nanopore) sequencers",
    "text": "ONT (Nanopore) sequencers\n\n\n\n\n\n\n\n\nUnder development!\n\n\nONT constantly releases new flow cells with updated technology, which have led to large decreases in error rates over the past decade — and even over the past two or so years.\nThere is also a lot of development in ONT base-calling software so it is useful to receive and keep pre-basecall files: re-basecalling a few years later with updated software can make a difference."
  },
  {
    "objectID": "lectures/sequencing.html#ont-vs.-pacbio",
    "href": "lectures/sequencing.html#ont-vs.-pacbio",
    "title": "High-throughput sequencing  and genomes",
    "section": "ONT vs. PacBIO",
    "text": "ONT vs. PacBIO\nAdvantages of ONT:\n\nLow capital cost, portability (in-the-field sequencing!)\nRead length not inherently limited, some extremely long reads\nLower cost per base\nCan sequence RNA directly (but still under development)\n\n\n\nDisadvantages of ONT:\n\nHigher error rates\nSome systematic errors (e.g. homopolymers)"
  },
  {
    "objectID": "lectures/sequencing.html#genomes",
    "href": "lectures/sequencing.html#genomes",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genomes",
    "text": "Genomes\nAs methods facilitating genomics and transcriptomics research, genomes loom large in HTS. Specifically, most HTS applications either require a “reference genome” or involve its production.\n\n\nWhat exactly does “reference genome” refer to? We’ll discuss three components to this phrase:\n\nAssembly\nIt includes a representation of most of the genome DNA sequence: the genome assembly\n\n\n\n\nAnnotation\nIt (preferably) includes an “annotation” that provides the locations of genes and other genomic features, as well as functional information on these features\n\n\n\n\nTaxonomic identity\nTypically considered at the species level, so then it should involve the focal species. But:\n\nIf necessary, it is often possible to work with reference genomes of closely related species\nConversely, multiple reference genomes may exist, e.g. for different subspecies/populations"
  },
  {
    "objectID": "lectures/sequencing.html#genome-size-variation",
    "href": "lectures/sequencing.html#genome-size-variation",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome size variation",
    "text": "Genome size variation\n\n\n\nhttps://en.wikipedia.org/wiki/Genome_size"
  },
  {
    "objectID": "lectures/sequencing.html#genome-structure",
    "href": "lectures/sequencing.html#genome-structure",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome structure",
    "text": "Genome structure\n\n\n\n\n\n\n\n\nhttps://en.wikipedi.org/wiki/Karyotype\n\n\n   \nKey features:\n\nNumber of distinct chromosomes\nPloidy"
  },
  {
    "objectID": "lectures/sequencing.html#growth-of-genome-databases",
    "href": "lectures/sequencing.html#growth-of-genome-databases",
    "title": "High-throughput sequencing  and genomes",
    "section": "Growth of genome databases",
    "text": "Growth of genome databases\n\nKonkel & Slot 2023"
  },
  {
    "objectID": "lectures/sequencing.html#genome-assemblies",
    "href": "lectures/sequencing.html#genome-assemblies",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome assemblies",
    "text": "Genome assemblies\n\n\nWith increasing usage & quality of long-read HTS, we are generating better assemblies\nFor chromosome-level assemblies, i.e. with one contiguous sequence for each chromosome, additional technologies than sequencing are often needed (e.g. Hi-C, optical mapping)\nMany assemblies are not “chromosome-level”, but consist of –often 1000s of– contigs and scaffolds.\nEven chromosome-level assemblies are not 100% complete (and contain “unplaced” scaffolds)\n\n\n\n\n\n\nQuestion: Contigs vs. scaffolds?\n\nContigs are contiguous, known stretches of DNA created by the assembly process, basically by overlapping reads.\nOften, the order and orientation of two or more contigs is known, but there is a gap of unknown size between them. Such contigs are connected into scaffolds with a stretch of Ns in between."
  },
  {
    "objectID": "lectures/sequencing.html#genome-annotations",
    "href": "lectures/sequencing.html#genome-annotations",
    "title": "High-throughput sequencing  and genomes",
    "section": "Genome annotations",
    "text": "Genome annotations\n\n\nAnnotating a genome consists of two main steps:\n\nStructural annotation\nThe identification of genes and other genomic features within the genome sequence\nFunctional annotation\nGiving names & assigning functions to (mostly) genes\n\nGenome annotation heavily relies on information from other organisms’ genomes, lifting over annotations based on the concept of sequence homology.\n\n\n\n\n\n\n\n\n\n\nHow is this data stored?\n\n\nBoth genome assemblies and annotations are typically saved in a single text file each — more on that soon."
  },
  {
    "objectID": "lectures/sequencing.html#overview",
    "href": "lectures/sequencing.html#overview",
    "title": "High-throughput sequencing  and genomes",
    "section": "Overview",
    "text": "Overview\nAll common genetic/genomic data files are plain-text, meaning that they can be opened by any text editor. However, they are often compressed to save space. The main types are:\n\nFASTA\nSimple sequence files, where each entry contains a header and a DNA/AA sequence.\nVersatile, anything from a genome assemblies, proteomes, and single sequence fragments to alignments can be in this format.\n\n\n\n\nFASTQ\nThe standard format for HTS reads — contains a quality score for each nucleotide.\nSAM/BAM\nAn alignment format for HTS reads\n\n\n\n\n\nGTF/GFF\nTables (tab-delimited) with information such as genomic coordinates on “genomic features” such as genes and exons. The files contain reference genome annotations."
  },
  {
    "objectID": "lectures/sequencing.html#fasta-files",
    "href": "lectures/sequencing.html#fasta-files",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTA files",
    "text": "FASTA files\nFASTA files contain one or more (sometimes called multi-FASTA) DNA or amino acid sequences, with no limits on the number of sequences or the sequence lengths.\n\n\nAs mentioned, they are versatile, and are the standard format for:\n\nGenome assembly sequences\nTranscriptomes and proteomes (all of an organism’s transcripts & amino acid sequences, resp.)\nSequence downloads from NCBI such as a single gene/protein or other GenBank entry\nSequence alignments (but not from HTS reads)"
  },
  {
    "objectID": "lectures/sequencing.html#fasta-files-cont.",
    "href": "lectures/sequencing.html#fasta-files-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTA files (cont.)",
    "text": "FASTA files (cont.)\nThe following example FASTA file contains two entries:\n&gt;unique_sequence_ID Optional description\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAAAA\n&gt;unique_sequence_ID2\nATTCATTAAAGCAGTTTATTGGCTTAATGTACATCAGTGAAATCATAAATGCTAAATG\n\n\nEach entry contains a header and the sequence itself, and:\n\nHeader lines start with a &gt; and are otherwise “free form” but usually provide an identifier (and sometimes metadata) for the sequence\nA single sequence is often not on a single line, but spread across multiple lines with a fixed width\n\n\n\n\nFASTA file name extensions are variable:\n\nGeneric extensions are .fasta and .fa\nAlso used are extensions that explicitly indicate whether sequences are nucleotide (.fna) or amino acids (.faa)"
  },
  {
    "objectID": "lectures/sequencing.html#fastq",
    "href": "lectures/sequencing.html#fastq",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ",
    "text": "FASTQ\nFASTQ is the standard format for HTS reads.\nEach read forms one FASTQ entry and is represented by four lines, which contain, respectively:\n\n\nA header that starts with @ and e.g. uniquely identifies the read\nThe sequence itself\nA + (plus sign)\nOne-character quality scores for each base (hence FASTQ as in “Q” for “quality”)"
  },
  {
    "objectID": "lectures/sequencing.html#fastq-quality-scores",
    "href": "lectures/sequencing.html#fastq-quality-scores",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ quality scores",
    "text": "FASTQ quality scores\nThe quality scores we saw in the read on the previous slide represent an estimate of the error probability of the base call.\nSpecifically, they correspond to a numeric “Phred” quality score (Q), which is a function of the estimated probability that a base call is erroneous (P):\n\nQ = -10 * log10(P)\n\n\n\nFor some specific probabilities and their rough qualitative interpretation for Illumina data:\n\n\n\nPhred quality score\nError probability\nRough interpretation\n\n\n\n\n10\n1 in 10\nterrible\n\n\n20\n1 in 100\nbad\n\n\n30\n1 in 1,000\ngood\n\n\n40\n1 in 10,000\nexcellent"
  },
  {
    "objectID": "lectures/sequencing.html#fastq-quality-scores-cont.",
    "href": "lectures/sequencing.html#fastq-quality-scores-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ quality scores (cont.)",
    "text": "FASTQ quality scores (cont.)\nThis numeric quality score is represented in FASTQ files not by the number itself, but by a corresponding “ASCII character”.\nThis allows for a single-character representation of each possible score — as a consequence, each quality score character can conveniently correspond to (& line up with) a base character in the read.\n\n\n\n\nPhred quality score\nError probability\nASCII character\n\n\n\n\n10\n1 in 10\n+\n\n\n20\n1 in 100\n5\n\n\n30\n1 in 1,000\n?\n\n\n40\n1 in 10,000\nI\n\n\n\n\n\n\n\n\n\nA rule of thumb\n\n\nIn practice, you almost never have to manually check the quality scores of bases in FASTQ files, but if you do, a rule of thumb is that letter characters are good (Phred of 32 and up)."
  },
  {
    "objectID": "lectures/sequencing.html#fastq-cont.",
    "href": "lectures/sequencing.html#fastq-cont.",
    "title": "High-throughput sequencing  and genomes",
    "section": "FASTQ (cont.)",
    "text": "FASTQ (cont.)\nFASTQ files have no size limit, so you may receive a single file per sample, although:\n\n\nWith paired-end (PE) sequencing, forward and reverse reads are split into two files:\nforward reads contain R1 and reverse reads contain R2 in the file name.\nIf sequencing was done on multiple lanes, you get one (SE) or two (PE) files per lane per sample.1\n\n\n\n\nFASTQ files have the extension .fastq or .fq (but are commonly compressed, leading to fastq.gz etc.). All in all, having paired-end FASTQ files for 2 samples could look like this:\n# A listing of (unusually simple) file names:\nsample1_R1.fastq.gz\nsample1_R2.fastq.gz\nsample2_R1.fastq.gz\nsample2_R1.fastq.gz\n\nNote that libraries usually consist of a mixture of all samples (though standard multiplexing is up to 96 samples). As such, if you need more data than a single Illumina lane can produce, the same library is sequenced on multiple lanes, rather than creating libraries with fewer samples."
  },
  {
    "objectID": "lectures/sequencing.html#gtfgff",
    "href": "lectures/sequencing.html#gtfgff",
    "title": "High-throughput sequencing  and genomes",
    "section": "GTF/GFF",
    "text": "GTF/GFF\nThe GTF and GFF formats are tab-delimited tabular files that contain genome annotations, with:\n\nOne row for each annotated “genomic feature” (gene, exon, etc.)\nOne column for each piece of information about a feature, like its genomic coordinates\n\n\nSee the sample below, with an added header line (not normally present) with column names:\nseqname     source  feature start   end     score  strand  frame    attributes\nNC_000001   RefSeq  gene    11874   14409   .       +       .       gene_id \"DDX11L1\"; transcript_id \"\"; db_xref \"GeneID:100287102\"; db_xref \"HGNC:HGNC:37102\"; description \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; gbkey \"Gene\"; gene \"DDX11L1\"; gene_biotype \"transcribed_pseudogene\"; pseudo \"true\"; \nNC_000001   RefSeq  exon    11874   12227   .       +       .       gene_id \"DDX11L1\"; transcript_id \"NR_046018.2\"; db_xref \"GeneID:100287102\"; gene \"DDX11L1\"; product \"DEAD/H-box helicase 11 like 1 (pseudogene)\"; pseudo \"true\"; \n\n\n\n\n\n\n\n\nSome details on the more important/interesting columns:\n\n\n\nseqname — Name of the chromosome, scaffold, or contig\nfeature — Name of the feature type, e.g. “gene”, “exon”, “intron”, “CDS”\nstart & end— Start & end position of the feature\nstrand — Whether the feature is on the + (forward) or - (reverse) strand\nattribute — A semicolon-separated list of tag-value pairs with additional information"
  },
  {
    "objectID": "lectures/sequencing.html#sambam",
    "href": "lectures/sequencing.html#sambam",
    "title": "High-throughput sequencing  and genomes",
    "section": "SAM/BAM",
    "text": "SAM/BAM\nUsing specialized bioinformatics tools, you can align HTS reads (in FASTQ files) to a reference genome assembly (in a FASTA file).\nThe resulting alignments are stored in the SAM (uncompressed) / BAM (compressed) format.\n\n\nSAM/BAM are tabular files with one line per alignment, each of which includes:\n\nThe position in the genome that the read aligned to\nA mapping score based on the length of the alignment and the number of mismatches\nThe sequence of aligned the read itself\n\n\n\n\n\n\n\n\n\n\nFile conversions\n\n\n\nFASTQ files can be converted to FASTA files (losing quality information) but not vice versa\nSAM/BAM files can be converted to FASTQ files (losing alignment information) but not vice versa\nProteome FASTA files can be produced from the combination of a FASTA genome assembly and a GFF/GTF genome annotation"
  }
]