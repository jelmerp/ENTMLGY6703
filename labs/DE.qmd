---
title: "Week 4 lab: RNA-seq differential expression analysis"
author: Jelmer Poelstra
date: 2024-02-02
editor: visual
execute: 
  eval: true
  cache: false
knitr:
  opts_chunk:
    out.width: "85%"
    class-output: styled-output
number-depth: 3
project:
  execute-dir: project
editor_options: 
  chunk_output_type: console
---

<br>

## Introduction

#### Recap

**[Last week](data.qmd)**, you explored the RNA-seq reads from the 2023 Molecular Ecology paper
"*Two avian Plasmodium species trigger different transcriptional responses on their vector Culex pipiens*" ([link](https://doi.org/10.1111/mec.17240)),
as well as the _Culex pipiens_ reference genome files.

In **[yesterday's lecture](../lectures/rnaseq.qmd)**, you learned about the steps to generate a gene count table
from this input data:

1.  **Read preprocessing**: QC, trimming, and optionally rRNA removal
2.  **Alignment** of reads to a reference genome (+ alignment QC)
3.  **Quantification** of expression levels

<hr style="height:1pt; visibility:hidden;" />

#### Today

You will not go through the above steps yourselves,
but will start from the output of step 3: a **gene count table**.
Today, with that gene count table, you will:

- Create an R object that also incorporates the metadata
- Perform exploratory data analysis including a PCA
- Run a Differential Expression (DE) analysis
- Extract and visualize the DE results


<br>

## Getting set up

### Start an RStudio session at OSC

1. Log in to OSC at <https://ondemand.osc.edu>

2. Click on **`Interactive Apps`** (top bar) and then **`RStudio Server`** (all the way at the bottom)

3. Fill out the form as follows:
   - Cluster: **`Pitzer`**
   - R version: **`4.3.0`**
   - Project: **`PAS2250`**
   - Number of hours: **`4`**
   - Node type: **`any`**
   - Number of cores: **`2`**

<details><summary>_Click to see a screenshot_</summary>

![](img_de/rstudio_form.png){fig-align="center" width="50%"}

</details>
   
4. Click the big blue **`Launch`** button at the bottom

5. Now, you should be sent to a new page with a box at the top for your RStudio
   Server "job", which should initially be "Queued" (waiting to start).

<details><summary>_Click to see a screenshot_</summary>

![](img_de/rstudio_queued.png){fig-align="center" width="70%"}

</details>

6. Your job should start running very soon,
   with the top bar of the box turning green and saying "Running".

<details><summary>_Click to see a screenshot_</summary>

![](img_de/rstudio_running.png){fig-align="center" width="70%"}

</details>

7. Click **`Connect to RStudio Server`** at the bottom of the box,
   and an RStudio Server instance will open in a new browser tab.
   You're ready to go!

<hr style="height:1pt; visibility:hidden;" />

### Change two settings

_First_, we'll prevent R from saving your **"Workspace"**:

1. Click **`Tools`** (top bar, below your browser's address bar) > **`Global Options`**
2. In the pop-up window (stay on the `General` tab), change the settings under the
   "Workspace" heading to:
   
![](img_de/workspace.png){fig-align="center" width="45%"}

::: {.callout-note collapse="true"}
#### Why are we doing this? _(Click to expand)_
In short, the default behavior of saving and restoring your "Workspace", which are all the
items (objects) that you create during an R session, is bad practice.
Instead, you should recreate your environment from a script and/or saved files
with individual pieces of data, as we'll do today.
:::

<hr style="height:1pt; visibility:hidden;" />

_Second_, we'll "update" our **pipe symbol** from **`%>%`** ^[An older pipe, which requires
loading an R package to work] to **`|>`** ^[The new base R pipe that does not require a package]:

1. Again click **`Tools`** > **`Global Options`** (you may still be there)
2. Now go to **`Code`** tab in the side panel on the left,
   and check the box for `Use native pipe operator, |> (requires R 4.1+)`
3. Click **`OK`** at the bottom of the pop-up window

![](img_de/rstudio_pipe.png){fig-align="center" width="70%"}

<hr style="height:1pt; visibility:hidden;" />

### Create a new RStudio Project

Using an "RStudio Project" will most of all help to make sure your working
directory in R is correct.
To create a new RStudio Project inside your personal dir in `/fs/scratch/PAS2250/ENT6703`:

1. Click **`File`** (top bar, below your browser's address bar) > **`New Project`**
2. In the popup window, click **`Existing Directory`**.

<details><summary>_Click to see a screenshot_</summary>

![](img_de/rstudio_proj_existingdir.png){fig-align="center" width="40%"}

</details>

3. Click **`Browse...`** to select your personal dir.

<details><summary>_Click to see a screenshot_</summary>

![](img_de/rstudio_proj_browse.png){fig-align="center" width="40%"}

</details>

4. In the next window, you should be in your Home directory (abbreviated as **`~`**),
   from which you can't click your way to `/fs/scratch`!
   Instead, you'll first have to click on the (very small!) **`...`** highlighted in the screenshot below:

![](img_de/rstudio_proj_dotdotdot_ed.png){fig-align="center" width="50%"}

5. Type at least part of the path to your personal dir (which is in `/fs/scratch/PAS2250/ENT6703`),
   e.g. as shown below, and click **`OK`**:

![](img_de/rstudio_proj_path.png){fig-align="center" width="35%"}

6. Now you should be able to browse/click the rest of the way to your personal directory.
5. Click **`Choose`** to pick your selected directory.
6. Click **`Create Project`**.

<hr style="height:1pt; visibility:hidden;" />

### Create an R script

We're going to write all our code in an R script instead of typing it directly in the console.
This helps us to **keep track of what we've been doing**, especially in the longer run,
and to be able to **re-run our code** after modifying input data or one of the lines of code.

Create and open a new R script by clicking
**`File`** (top menu bar) > **`New File`** > **`R Script`**.

Save this new script right away by clicking **`File`** > **`Save As`**,
then click **`New Folder`** and create a folder named "scripts".
Inside that folder, save the script with a name like **`lab4_DE.R`**
(the extension for R scripts is `.R`).

::: callout-important
#### Make sure to type all the R code below inside your script, and then send it to the console from there.
You can send code to the console by pressing <kbd>**Ctrl**</kbd> **+** <kbd>**Enter**</kbd>
on Windows, or <kbd>Cmd</kbd> + <kbd>Return</kbd> on a Mac.
:::

<hr style="height:1pt; visibility:hidden;" />

### Load the necessary packages

In R, we need to install and then use "packages" (basically, add-ons) to perform specialized tasks
like differential expression analysis^[And even for more basic tasks, it is common to use packages that are preferred over the functionality that is by default available in R, like in the case of plotting.].
Installing packages is quite straightforward in principle, but in RStudio Server at OSC, there can be some hickups.

I have therefore created a "**library**" (a directory with a collection of packages) for you ---
you can load the packages from that library, without needing to install them yourself.
Copy the code below into your R script and then send it to the R console:

```{r, eval=FALSE}
# First, we define the dir that has the custom library:
custom_library <- "/fs/scratch/PAS2250/ENT6703/share/rlib"

# Then, we load all needed R packages from that library:
library(tidyverse, lib.loc = custom_library)       # Misc. data manipulation and plotting
library(pheatmap, lib.loc = custom_library)        # Heatmap plot
library(EnhancedVolcano, lib.loc = custom_library) # Volcano plot
library(DESeq2, lib.loc = custom_library)          # Differential expression analysis
```

<details><summary>There should be a lot of output in the R console, some of it in orange, but all should be good unless you see explicit errors at the bottom (_Click to see expected output_)</summary>

<hr style="height:1pt; visibility:hidden;" />

```{r}
library(tidyverse)
```

```{r}
library(pheatmap)
```

```{r}
library(EnhancedVolcano)
```

```{r}
library(DESeq2)
```

</details>

<hr style="height:1pt; visibility:hidden;" />

### Define our input files

For the differential expression analysis, we have the following input files:

- **Metadata table** --- The metadata we saw last week, to enable between-treatment comparisons
- **Gene counts table** --- Produced by running the [nf-core rnaseq workflow](https://nf-co.re/rnaseq) on the input data we saw last week

```{r, eval=FALSE}
# We'll save the paths to our input files for later use
# ('..' goes up one dir in the dir hierarchy - same as in the Unix shell) 
count_table_file <- "../share/results/counts/salmon.merged.gene_counts_length_scaled.tsv"
metadata_file <- "../share/data/meta/metadata.tsv"
```

```{r, echo=FALSE}
count_table_file <- here::here("results/counts/salmon.merged.gene_counts_length_scaled.tsv")
metadata_file <- here::here("data/meta/metadata.tsv")
```

<br>

## Create a DESeq2 object

Today, we will perform differential expression (DE) analysis using the popular **DESeq2** package
([paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8),
[website](https://bioconductor.org/packages/release/bioc/html/DESeq2.html)).

The DESeq2 package has its own "object type" (basically, a format in R) and
before we can do anything else, we need to create a DESeq2 object from three components:

1. **Metadata**  
   Our independent variables should be in the metadata, allowing DESeq2 to compare groups of samples.
2. **Count table**  
   A matrix (table) with one row per gene, and one column per sample.
3. **A statistical design**  
   A statistical design formula (basically, which groups to compare) will tell DESEq2 _how_ to analyze the data

<hr style="height:1pt; visibility:hidden;" />

### Metadata

First, we'll load the metadata file and take a look at the resulting dataframe:

```{r}
# Read in the count table
meta_raw <- read_tsv(metadata_file, show_col_types = FALSE)
```

```{r}
# Take a look at the first 6 rows
head(meta_raw)
```

We'll make sure the data frame is sorted by sample ID,
and that the sample IDs are contained in "row names":

```{r}
meta <- meta_raw |>
  # 1. Sort by the 'sample_id' column
  arrange(sample_id) |>
  # 2. Turn the 'sample_id' column into row names:
  column_to_rownames("sample_id") |>
  # 3. Turn the 'time' and 'treatment' columns into "factors":
  mutate(time = factor(time, levels = c("24hpi", "10dpi")),
         treatment = factor(treatment, levels = c("control", "cathemerium", "relictum")))
```

```{r}
# Take a look at the first 6 rows
head(meta)
```

::: {.callout-tip appearance="minimal"}
_Note the difference between having the sample IDs as a separate column versus having them as row names._
:::

::: {.callout-note collapse="true"}
### Factors are a common R data type for categorical variables _(Click to expand)_

We changed the two independent variable columns (`time` and `treatment`) into factors,
because DESEq2 wants this --- this also allowed us to use a custom,
non-alphanumeric ordering where `24hpi` comes before `10dpi`:

```{r}
head(meta$time)
```
:::

<hr style="height:1pt; visibility:hidden;" />

### Count table

Second, we will load the count table into R:

```{r}
# Read in the count table
count_df <- read_tsv(count_table_file, show_col_types = FALSE)
```

```{r}
# Take a look at the first 6 rows
head(count_df)
```

We next have to make several modifications, because DESeq2 expects an all-numeric matrix
with whole numbers (integers) and gene IDs are "row names" rather than as a separate
column:

```{r}
# Prepare the count table so it can be loaded into DESeq2
count_mat <- count_df |>
  # 1. Turn the 'gene_id' column into row names:
  column_to_rownames("gene_id") |>
  # 2. Remove a remaining non-numeric column, with gene names:
  select(-gene_name) |>
  # 3. We should round everything to whole numbers:
  round() |>
  # 4. We should convert it to a formal matrix format:
  as.matrix()
```

```{r}
# Take a look at the first 6 rows
head(count_mat)
```

#### Check that the sample IDs match

When creating the DESeq2 object, DESeq2 assumes that sample IDs in both tables match and 
are provided in the same order. Let's make sure this is indeed the case:

```{r}
all(row.names(meta) == colnames(count_mat))
```

<hr style="height:1pt; visibility:hidden;" />

### Create the DESeq2 object

We will create the DESeq2 object using the function `DESeqDataSetFromMatrix()`,
which we will provide with three arguments corresponding to the components
discussed above:

- The metadata with argument **`colData`**.
- The count data with argument **`countData`**.
- The statistical design for the DE analysis with argument **`design`**.
  For now, we will specify **`~1`**, which effectively means "no design" ---
  we will change this before the actual DE analysis.

```{r}
# (`dds` is a name commonly used for DESeq2 objects, short for "DESeq Data Set")
dds <- DESeqDataSetFromMatrix(
  colData = meta,
  countData = count_mat,
  design = ~ 1
  )
```

Before we will run the differential expression analysis, though, we will do
a bit of exploratory data analysis using our `dds` object.

<br>

## Exploratory Data Analysis

### Our count matrix

What are number of rows (=number of genes) and columns (=number of samples) of our count matrix?

```{r}
dim(count_mat)
```

How many genes have total (= across all samples) counts that are non-zero?

```{r}
nrow(count_mat[rowSums(count_mat) > 0, ])
```

::: exercise
#### {{< fa user-edit >}} Your Turn

- How many genes have total counts of at least 10?

<details><summary> _Click to see the solution_</summary>

```{r}
nrow(count_mat[rowSums(count_mat) >= 10, ])
```

</details>

- _Bonus_: How many genes have _mean_ counts of at least 10?

<details><summary> _Click to see the solution_</summary>

```{r}
# Now we need to divide by the number of samples, which is the number of columns,
# which we can get with 'ncol'
nrow(count_mat[rowSums(count_mat) / ncol(count_mat) >= 10, ])
```

</details>

:::

How do the "library sizes", i.e. the summed per-sample gene counts, compare across samples?

```{r}
colSums(count_mat)
```

::: exercise
#### {{< fa user-edit >}} Your Turn (Bonus)
That's not so easy to read / interpret. Can you instead get these numbers in millions, rounded to whole numbers, and sorted from low to high?

<details><summary> _Click to see the solution_</summary>

```{r}
sort(round(colSums(count_mat) / 1000000))
```

</details>

:::

<br>

### Principal Component Analysis (PCA) 

We will now run a PCA to look for overall patterns of (dis)similarity among samples.
This will help us answer questions like:

- Do the samples cluster by treatment (infection status) and/or time point?
- Which of these two variables has a greater effect on overall patterns of gene expression?
- Is there an overall _interaction_ between these two variables?
  
First, we have to normalize the count data to account for differences in library size among samples and "stabilize" the variance among genes^[Specifically, the point is to remove the dependence of the expression level variance on the expression level mean among genes]:

```{r}
dds_vst <- varianceStabilizingTransformation(dds)
```

::: callout-note
#### The authors of the study did this as well:
> _We carried out a Variance Stabilizing Transformation (VST) of the counts to represent the samples on a PCA plot._ 
:::

<hr style="height:1pt; visibility:hidden;" />

Next, we can run and plot the PCA with a single function call, `plotPCA` from DESeq2:

```{r, eval=FALSE}
# With 'intgroup' we specify the variables (columns) to color samples by
plotPCA(dds_vst, intgroup = c("time", "treatment"))
```

<details><summary>_Click to see the plot_</summary>

```{r, eval=TRUE, echo=FALSE}
plotPCA(dds_vst, ntop = 500, intgroup = c("time", "treatment"))
```

</details>

::: exercise
#### {{< fa user-edit >}} Your Turn

- Based on our PCA plot,
  try to answer the three questions asked at the beginning of this PCA section.
  
- How does our plot compare to the PCA plot in the paper (Figure 1),
  in terms of the conclusions you just drew in the previous exercise.

<details><summary>_Click to see the paper's Figure 1_</summary>

![](img_de/garrigo_PCA.jpeg)

</details>

<hr style="height:1pt; visibility:hidden;" />

--------

- _Bonus_: Compare the PCA plot with different numbers of included genes
  (Hint: figure out how to do so by looking at the help by running `?plotPCA`)

- _Bonus_: Customize the PCA plot --- e.g. can you "separate" treatment and time
  point, like Fig. 1 of the paper did?

<details><summary> _Click to see some hints for PCA plot customization_</summary>

The biggest issue (I think) with the above plot is that each combination of 
time point and treatment has a distinct color ---
it would be better to use **point color** only to distinguish one of the variables,
and **point shape** to distinguish the other variable
(as it was also done in the paper's Fig. 1).

To be able to customize the plot properly, we best build it from scratch ourselves,
rather than using the `plotPCA` function. But then how do we get the input data in
the right shape?

A nice trick is that we can use `returnData = TRUE` in the `plotPCA`
function, to get plot-ready formatted data instead of an actual plot: 

```{r}
pca_df <- plotPCA(dds_vst, ntop = 500,
                  intgroup = c("time", "treatment"), returnData = TRUE)
```

</details>

<details><summary> _Click to see a possible solution_</summary>

```{r}
pca_df <- plotPCA(dds_vst, ntop = 500,
                  intgroup = c("time", "treatment"), returnData = TRUE)
```

We'll extract the percentage of variance explained by different principal components,
so we can later add this information to the plot:

```{r}
pct_var <- round(100 * attr(pca_df, "percentVar"), 1)
pct_var
```

```{r}
ggplot(pca_df,
       aes(x = PC1, y = PC2, color = treatment, shape = time)) +
  geom_point(size = 5) +
  labs(x = paste0("PC1 (", pct_var[1], "%)"),
       y = paste0("PC2 (", pct_var[2], "%)")) +
  scale_color_brewer(palette = "Dark2", name = "Infection status") +
  scale_shape(name = "Time points") +
  theme_bw() +
  theme(panel.grid.minor = element_blank())
```

</details>

:::

<br>

## Differential Expression (DE) analysis

### Figuring out how to do the analysis

First, let's see how the DE analysis was done in the paper:

> _Then, we used the DESeq2 package (Love et al., 2014) to perform the differential gene expression analysis comparing: (i) P. relictum-infected mosquitoes vs. controls, (ii) P. cathemerium-infected mosquitoes vs. controls, and (iii) P. relictum-infected mosquitoes vs. P. cathemerium-infected mosquitoes._

This is not terribly detailed and could be interpreted in a couple of different ways.
For example, they may have compared infection statuses by _ignoring_ time points **_or_**
by _controlling for_ time points (and their are different ways to do the latter).

Ignoring time would mean analyzing the full dataset (all time points) while only
using the infection status as an independent variable, i.e. the design `~treatment`.

::: exercise
#### {{< fa user-edit >}} Your turn
Given the PCA results, do you think that ignoring the `time` variable is a good idea?
:::

Controlling for time can additionally be done in two ways:

- A two-factor analysis: `~ time + treatment`
- Pairwise comparisons between each combination of time and treatment
  (we'll see below _how_ we can do that)

If we take a look at Table 1 with the DE results, it will become clearer how
they did their analysis:

![](img_de/paper_table1.png){fig-align="center" width="80%"}

::: exercise
#### {{< fa user-edit >}} Your Turn
How do you interpret this: did they run pairwise comparisons or a two-factor model?

<details><summary> _Click to see the answer_ </summary>
It looks like they performed pairwise comparisons between each combination of time and treatment.
</details>
:::

Pairwise comparisons with multiple independent variables can (also!) be done in two ways:

- After **subsetting** the dataset to each combination of time and treatment.
- After creating a single, **combined independent variable** that is a combination of time and treatment.

The latter method is the more common one, and is what we will do below^[I can't tell from the paper which method they used].

<hr style="height:1pt; visibility:hidden;" />

### Setting the statistical design

We will now create a new variable that is a combination of `treatment` and `time`,
and call it `group`:

```{r}
# Create a combined variable called 'group':
dds$group <- factor(paste(dds$treatment, dds$time, sep = "_"))

# Which unique values does 'group' have, and how many samples are in each?
table(dds$group)
```

Next, we set the analysis design:

```{r}
design(dds) <- ~ group
```

Now we're ready to run the DE analysis!

<hr style="height:1pt; visibility:hidden;" />

### Running the DE analysis

While we had to do a lot of prep to get here, actually running the DE analysis is very simple:

```{r}
# We are assigning the output back to the same `dds` object - the DE results are added to it
dds <- DESeq(dds)
```

The `DESeq()` function is a wrapper that performs three steps (functions) consecutively:
  
- `estimateSizeFactors()` --- "Normalization" by library size and composition.
- `estimateDispersions()` --- Estimate gene-wise dispersion (variance in counts).
- `nbinomWaldTest(ddsObj)` --- Fit the negative binomial GLM and calculate test statistics

A key thing to understand is that above, DESeq2 automatically performed **pairwise**
comparisons between **each of the (6) levels** of the `group` variable.
This means that for any individual gene, it tested whether the gene is differentially
expressed _separately for each of these pairwise comparisons_.

<br>

## Extracting the DE results

DESeq2 stores the results as a separate table for each pairwise comparison,
and now, we'll extract one of these.

### The results table

We can extract the results for one pairwise comparison
(which DESeq2 refers to as a **contrast**) at a time,
by specifying it with the `contrast` argument as a vector of length 3:

1. The focal independent variable (here, `group`)
2. The first (reference) level of the independent variable (in the example below, `relictum_24hpi`)
3. The second level of the independent variable (in the example below, `control_24hpi`)

```{r}
focal_contrast <- c("group", "relictum_24hpi", "control_24hpi")
res_rc24 <- results(dds, contrast = focal_contrast)

head(res_rc24)
```

What do the columns in this table contain?

- **`baseMean`**: Mean expression level across all samples.
- **`log2FoldChange`**: The "log2-fold change" of gene counts between the compared levels.
- **`lfcSE`**: The uncertainty in terms of the standard error (SE) of the log2-fold change estimate.
- **`stat`**: The value for the Wald test's test statistic.
- **`pvalue`**: The *uncorrected* p-value from the Wald test.
- **`padj`**: The multiple-testing corrected p-value (i.e., adjusted p-value).

::: callout-note
#### Multiple testing correction
Because we are testing significance for *many* genes,
we need to correct for multiple testing.
DESeq2 uses the Benjamini-Hochberg False Discovery Rate (FDR) correction.
For more info, see this [StatQuest video](https://www.youtube.com/watch?v=K8LQSvtjcEo).
:::

::: callout-note
#### Log2-fold changes (LFCs)
In RNA-seq, log2-fold changes (LFCs) are the standard way of representing the
**magnitude  (*effect size*) of expression level differences** between two groups of interest.
With A and B being the compared sample groups, the LFC is calculated as:

``` bash-out-solo
log2(mean of A / mean of B)
```

Due the log-transformation, the LFC also increase more slowly than a raw fold-change:

- An LFC of **`1`** indicates a 2-fold difference
- An LFC of **`2`** indicates a 4-fold difference
- An LFC of **`3`** indicates a 8-fold difference

A nice property of LFC is that decreases and increases in expression are expressed symmetrically:

- An LFC of **`1`** means that group A has a **two-fold higher** expression that group B
- An LFC of **`-1`** means that group A has a **two-fold lower** expression that group B

:::

::: exercise
#### {{< fa user-edit >}} Your Turn (bonus)

Based on the above, or your knowledge of log-transformations,
what do you expect the following to return:

```{r, eval=FALSE}
# In the context of a LFC, these 2 numbers would be mean expression levels in 2 groups
log2(8 / 2)
log2(2 / 8)
```

<details><summary>_Click to see the solution_</summary>

```{r}
log2(8 / 2)    # Fold-change of 4
```

```{r}
log2(2 / 8)    # Fold-change of 0.25
```

</details>

:::

<hr style="height:1pt; visibility:hidden;" />

### Numbers of DEGs

How many adjusted p-values were less than 0.05 (i.e., significant)?

```{r}
sum(res_rc24$padj < 0.05, na.rm = TRUE)
```

So, we have `r sum(res_rc24$padj < 0.05, na.rm = TRUE)` Differentially Expressed
Genes (**DEG**s) for this specific pairwise comparison.

::: exercise
#### {{< fa user-edit >}} Your Turn

The paper's Table 1 (which we saw above) reports the number of DEGs for a variety
of comparisons.

- How does the number of DEGs we just got compare to what they found in the paper for this comparison?

- The table also reports numbers of **up- and downregulated genes separately**. Can you find this out for our DEGs?

<details><summary>_Click to see the solution_</summary>

- **Solution using tidyverse/dplyr:**

```{r, eval=TRUE}
# First we need to convert the results table into a regular data frame
as.data.frame(res_rc24) |>
  # Then we only select the rows/genes that are significant
  filter(padj < 0.05) |>
  # If we run count() on a logical test, we get the nrs. that are FALSE v. TRUE
  dplyr::count(log2FoldChange > 0)
```

- **Solution using base R:**

```{r}
# Down-regulated (relictum < control):
sum(res_rc24$log2FoldChange < 0 & res_rc24$padj < 0.05, na.rm = TRUE)

# Up-regulated (relictum > control):
sum(res_rc24$log2FoldChange > 0 & res_rc24$padj < 0.05, na.rm = TRUE)
```

</details>

<hr style="height:1pt; visibility:hidden;" />

--------

- _Bonus_: The table also reports the number of DEGs with an **absolute LFC > 1**.
  Can you find this out for our DEGs?

<details><summary> _Click to see the solution_</summary>

- **Solution using tidyverse/dplyr:**

```{r, eval=TRUE}
# First we need to convert the results table into a regular data frame
as.data.frame(res_rc24) |>
  # Then we only select the rows/genes that are significant
  filter(padj < 0.05, abs(log2FoldChange) > 1) |>
  # If we run count() on a logical test, we get the nrs. that are FALSE v. TRUE
  dplyr::count(log2FoldChange > 0)
```

- **Solution using base R:**

```{r}
# Down-regulated (relictum < control):
sum(res_rc24$log2FoldChange < -1 & res_rc24$padj < 0.05, na.rm = TRUE)

# Up-regulated (relictum > control):
sum(res_rc24$log2FoldChange > 1 & res_rc24$padj < 0.05, na.rm = TRUE)
```

</details>

- _Bonus_: Extract the results for one or more **other contrasts** in the table, and compare the results.</summary>

:::

<br>

## Visualizing the DE results

We will create a few plots for the results for the `relictum_24hpi` vs. `control_24hpi`
comparison, which we extracted above.

### Volcano plot

For a nice overview of the results, we can plot a so-called "volcano plot"
using the `EnhancedVolcano()` function from the package of the same name
([see here for a "vignette" / tutorial](https://bioconductor.org/packages/release/bioc/vignettes/EnhancedVolcano/inst/doc/EnhancedVolcano.html)):

```{r, fig.height=6.5, eval=FALSE}
EnhancedVolcano(
  toptable = res_rc24,      # DESeq2 results to plot   
  title = "relictum vs. control at 24 hpi",
  x = "log2FoldChange",     # Plot the log2-fold change along the x-axis
  y = "padj",               # Plot the p-value along the y-axis
  lab = rownames(res_rc24), # Use the rownames for the gene labels (though see below)
  labSize = 0               # Omit gene labels for now
  )
```

<details><summary> _Click to see the plot_</summary>

```{r, fig.height=6.5, echo=FALSE}
EnhancedVolcano(
  toptable = res_rc24,      # DESeq2 results to plot   
  title = "relictum vs. control at 24 hpi",
  x = "log2FoldChange",     # Plot the log2-fold change along the x-axis
  y = "padj",               # Plot the p-value along the y-axis
  lab = rownames(res_rc24), # Use the rownames for the gene labels (though see below)
  labSize = 0               # Omit gene labels for now
  )
```

</details>

::: exercise
#### {{< fa user-edit >}} Your Turn

Above, we turned off gene name labeling by setting `labSize = 0`.
I did this because the default p-value cut-off for point labeling is `1e-5` 
and in this case, that would make the plot quite busy with gene labels.
We might want to try a plot with a stricter p-value cut-off that does show the gene labels.

- **Play around with the p-value cut-off and the labeling to create a plot you like.**  
  _Check [the vignette](https://bioconductor.org/packages/release/bioc/vignettes/EnhancedVolcano/inst/doc/EnhancedVolcano.html), or the help page (access by running `?EnhancedVolcano`) to see how you can do this._
  
<details><summary> _Click for an example_</summary>

```{r, fig.height=6.5}
EnhancedVolcano(
  toptable = res_rc24,      
  title = "relictum vs. control at 24 hpi",
  x = "log2FoldChange",     
  y = "padj",             
  lab = rownames(res_rc24), 
  labSize = 4,               # Now we will show the gene labels
  pCutoff = 10e-10,          # Modify the p-value cut-off
  subtitle = NULL,           # I'll also remove the silly subtitle
  caption = NULL,            # ... and the caption
  )
```

</details>

<hr style="height:1pt; visibility:hidden;" />

- **Figure out the identity of the abovementioned log2-fold change outlier**
  (either by labeling it in the plot, or by filtering the `res_rc24` table)

<details><summary>_Click for the solution for how to lab it in the plot_ </summary>

<hr style="height:1pt; visibility:hidden;" />

```{r, fig.height=6.5}
EnhancedVolcano(
  toptable = res_rc24,      
  title = "relictum vs. control at 24 hpi",
  x = "log2FoldChange",     
  y = "padj",             
  lab = rownames(res_rc24), 
  labSize = 4,               
  pCutoff = 0.05,            # Modify the p-value cut-off
  FCcutoff = 20,             # Modify the LFC cut-off
  )
```

</details>

<details><summary>_Click for the solution for how to find it in the results table_ </summary>

<hr style="height:1pt; visibility:hidden;" />

```{r}
as.data.frame(res_rc24) |> filter(log2FoldChange > 20)
```

(Interestingly, there's a second gene with a LFC > 20 that we hadn't seen in the plot,
because it has `NA` as the `pvalue` and `padj`.
See the section "Extra info: `NA` values in the results table" in the
[Appendix](#appendix-the-de-results) above for why p-values can be set to `NA`.)

</details>

:::

<hr style="height:1pt; visibility:hidden;" />

### Plot specific genes

We can also create plots of expression levels for individual genes.
That is especially interesting for genes with highly significant differential
expression. So let's plot the most highly significant DEG.

First, let's create a vector with most highly significant DEGs,
which we'll use again for the heatmap below.

```{r}
top25_DE <- row.names(res_rc24[order(res_rc24$padj)[1:25], ])

top25_DE
```

DESeq2 has a plotting function but the plot is not very good.
We will still use that function but just to quickly extract the counts for our gene of interest
in the right format for plotting, using `returnData = TRUE`:

```{r}
focal_gene_counts <- plotCounts(
  dds,
  gene = top25_DE[1],
  intgroup = c("time", "treatment"),
  returnData = TRUE
  )

head(focal_gene_counts)
```

Now, we can make the plot:

```{r, eval=FALSE}
ggplot(focal_gene_counts,
       # Treatment along the x-axis, gene counts along the y, color by treatment:
       aes(x = treatment, y = count, fill = treatment)) +
  # Plot separate "facets" with the different time points
  facet_wrap(vars(time)) +
  # Add a boxplot with a partly transparaent (alpha) color:
  geom_boxplot(alpha = 0.5, outlier.shape = NA) +
  # _And_ add individual points:
  geom_point(size = 4, shape = 21,
             position = position_jitter(w = 0.1, h = 0)) +
  # Plot styling (e.g., we don't need a legend)
  theme_bw() +
  theme(legend.position = "none")
```

<details><summary> _Click to see the plot_</summary>

```{r, echo=FALSE}
ggplot(focal_gene_counts,
       aes(x = treatment, y = count, fill = treatment)) +
  facet_wrap(vars(time)) +
  geom_boxplot(alpha = 0.5, outlier.shape = NA) +
  geom_point(size = 4, shape = 21,
             position = position_jitter(w = 0.1, h = 0)) +
  theme_bw() +
  theme(legend.position = "none")
```

</details>

::: exercise
#### {{< fa user-edit >}} Your turn

- Plot the gene with the very high LFC value that we saw when making the volcano plot.
  How would you interpret this?

<details><summary>_Click for the solution_</summary>

```{r}
focal_gene_counts <- plotCounts(
  dds,
  gene = "LOC120431476",
  intgroup = c("time", "treatment"),
  returnData = TRUE
  )

ggplot(focal_gene_counts, aes(x = treatment, y = count, fill = treatment)) +
  geom_boxplot(alpha = 0.5, outlier.shape = NA) +
  geom_point(size = 4, shape = 21, position = position_jitter(w = 0.1, h = 0)) +
  facet_wrap(vars(time)) +
  theme_bw() +
  theme(legend.position = "none")
```

Wow! It looks like in every single time + treatment combinations,
all but one (or in one case, two) of the samples have zero expression,
but there are several extreme outliers.

Our focal comparison at `24hpi` (left panel/facet), and comparing
`control` vs `relictum`: so it looks like the difference between these two groups
is solely due to the one outlier in `relictum`.
Nevertheless, even the multiple-testing corrected p-value (`padj`) is significant for this gene:

```{r}
as.data.frame(res_rc24) |>
  rownames_to_column("gene") |>
  filter(gene == "LOC120431476")
```

So, we have to be careful with talking our statistical results at face value,
and need to visualize important genes!

</details>

::: {.callout-important}
#### Outliers!
Make sure to check out the solution to the previous exercise,
even if you don't get around to doing it yourself.
:::

- _Bonus_: Plot one or a few more of the top-DE genes.
  Do they have similar expression patterns across treatment and time points as the first one?

:::

<br>

## In Closing

Today, you have performed several steps in the analysis of gene counts that result
from a typical RNA-seq workflow. Specifically, you have:

- Created a DESEq2 object from the gene count data and the experiment's metadata
- Performed exploratory data analysis including a PCA
- Ran a Differential Expression (DE) analysis with DESeq2
- Extracted, interpreted, and visualized the DE results

#### Next steps

Typical next steps in such an analysis include:

- Extracting, comparing, and synthesizing DE results across **all pairwise comparisons**
  (this would for example allow us to make the upset plot in _Figure 2 of the paper_)

- **Functional enrichment analysis** with Gene Ontology (GO) terms, as done in the paper,
  and/or with KEGG pathways.

<br>

## Appendix

::: {.callout-note collapse="true"}
#### `NA` values in the results table _(Click to expand)_
Some values in the results table can be set to `NA` for one of the following reasons:

- If a gene contains a sample with a count **outlier**,
  both the p-value and adjusted p-value will be set to `NA`.
  (DESeq2 performs outlier detection using Cook's distance.)
  
- If all samples have **zero counts** for a given gene,
  the `baseMean` column will be zero,
  and the log2-fold change estimates,
  p-value and adjusted p-value will all be set to `NA`.

- DESeq2 also automatically filters genes with a **low mean count**
  in the sense that it does not include them in the multiple testing correction.
  Therefore, in such cases, the p-value will not be `NA`,
  but the *adjusted* p-value will be.
  
  Because we have very low power to detect differential expression for such
  low-count genes, it is beneficial to remove them prior to the multiple testing
  correction: that way, the correction becomes less severe for the remaining genes.

Let's see how many genes have `NA` p-values:

```{r}
# Number of genes with NA p-value:
sum(is.na(res_rc24$pvalue))

# As a proportion of the total number of genes in the test:
sum(is.na(res_rc24$pvalue)) / nrow(res_rc24)
```

And `NA` adjusted p-values:

```{r}
# Number of genes with NA p-value:
sum(is.na(res_rc24$padj))

# As a proportion of the total number of genes in the test:
sum(is.na(res_rc24$padj)) / nrow(res_rc24)
```

:::

::: {.callout-note collapse="true"}
#### Exporting the results _(Click to expand)_

You may be wondering how we can save the DE results tables:

```{r, eval=FALSE}
# Create the output directory, if necessary:
dir.create("results/DE", recursive = TRUE, showWarnings = FALSE)

# Write the 
write_tsv(as.data.frame(res_rc24), "results/DE/resultsres_rc24.tsv")
```

:::

### Heatmaps

Rather than plotting expression levels for many individual genes,
we can create "heatmap" plots to plot dozens (possibly even hundreds) of genes
at once.

We will create heatmaps with the `pheatmap` function,
and let's make a heatmap for the top-25 most highly significant DEGs for our focal contrast.

Unlike with some of the functions we used before, we unfortunately can't directly
use our DESeq2 object, but we have to extract and subset the count matrix,
and also pass the metadata to the heatmap function:

```{r}
# We need a normalized count matrix, like for the PCA
# We can simply extract the matrix from the normalized dds object we created for the PCA
norm_mat <- assay(dds_vst)

# In the normalized count matrix, select only the genes of interest
# We'll reuse the 'top25_DE' vector that we created for the individual gene plots
norm_mat_sel <- norm_mat[match(top25_DE, rownames(norm_mat)), ]

# Sort the metadata
meta_sort <- meta |>
  arrange(treatment, time) |>
  select(treatment, time)
```

Now we can create the plot:

```{r, eval=FALSE}
pheatmap(
  norm_mat_sel,
  annotation_col = meta_sort,  # Add the metadata
  cluster_cols = FALSE,        # Don't cluster samples (=columns, cols)
  show_rownames = FALSE,       # Don't show gene names
  scale = "row",               # Perform z-scaling for each gene
  )
```

::: {.callout-tip appearance="minimal"}
- The z-scaling with `scale =` will make sure we can compare genes with very
  different expression levels: after all, we're interested in relative expression levels
  across samples/sample groups
  
- `pheatmap` will by default perform hierarchical clustering both at the sample (`col`)
   and gene (`row`) level, such that more similar samples and genes will appear closer
   to each other. Above, turned clustering off for samples, since we want to keep
   them in their by-group order.
:::

<details><summary> _Click to see the plot_</summary>

```{r, echo=FALSE}
pheatmap(
  norm_mat_sel,
  annotation_col = meta_sort,
  cluster_cols = FALSE,
  show_rownames = FALSE,
  scale = "row"
  )
```

</details>

::: exercise
#### {{< fa user-edit >}} Your turn

Make a heatmap with the top-25 **most-highly expressed** genes
(i.e., genes with the highest mean expression levels across all samples).

<details><summary> _Click for a hint: how to get that top-25_</summary>

```{r}
top25_hi <- names(sort(rowMeans(norm_mat), decreasing = TRUE)[1:25])
```

</details>

<details><summary> _Click for the solution_</summary>

```{r}
# In the normalized count matrix, select only the genes of interest
norm_mat_sel <- norm_mat[match(top25_hi, rownames(norm_mat)), ]

# Sort the metadata
meta_sort <- meta |>
  arrange(treatment, time) |>
  select(treatment, time)

# Create the heatmap
pheatmap(
  norm_mat_sel,
  annotation_col = meta_sort,
  cluster_cols = FALSE,
  show_rownames = FALSE,
  scale = "row"
  )
```

</details>

:::
